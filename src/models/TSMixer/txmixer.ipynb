{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 10:20:56.686796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-01 10:20:56.686877: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-01 10:20:56.688629: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-01 10:20:59.647225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "############ tsmixer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')  # Assuming the module is in the parent directory\n",
    "import benchmarks\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from src.tsmixer_load.data_loader import DataLoader\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# first sort, then do placebo test\n",
    "def custom_sort_key(s):\n",
    "    parts = s.split('_')\n",
    "    return int(parts[1])\n",
    "\n",
    "def sMAPE_tf(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "    smape_values = tf.abs(y_pred - y_true) / (tf.abs(y_pred) + tf.abs(y_true)) * 2\n",
    "    smape_per_series = tf.reduce_mean(smape_values, axis=1)\n",
    "    mean_smape = tf.reduce_mean(smape_per_series)\n",
    "\n",
    "    return mean_smape  # Convert TensorFlow tensor to NumPy array for compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tsmixer_eval(dataset_name,dataset_type, forecast_horizon):\n",
    "    if dataset_type == \"sim\":\n",
    "        y_true_df_A = pd.read_csv(\"../datasets/text_data/\" + dataset_type +  \\\n",
    "                \"/\" + dataset_name + \"_test_actual.csv\")\n",
    "        # Reading the original data to calculate the MASE errors\n",
    "        y_true_df_B = pd.read_csv(\"../datasets/text_data/\" + dataset_type +  \\\n",
    "                \"/\" + dataset_name + \"_train.csv\")\n",
    "        data_row_A = y_true_df_A.pivot(index='time', columns='series_id', values='value')\n",
    "        data_row_B = y_true_df_B.pivot(index='time', columns='series_id', values='value')\n",
    "        data_row_A = data_row_A.loc[:,sorted(data_row_A.columns, key=custom_sort_key)]\n",
    "        data_row_B = data_row_B.loc[:,sorted(data_row_B.columns, key=custom_sort_key)]\n",
    "        data_row = pd.concat([data_row_B, data_row_A],ignore_index=True)\n",
    "        data_row = data_row.loc[:,sorted(data_row.columns, key=custom_sort_key)]\n",
    "        data_row.to_csv(\"../datasets/text_data/sim/\"+dataset_name+\".csv\", index=False)\n",
    "        length_of_series = len(data_row.index)\n",
    "\n",
    "        # The columns of data_row need to be rename\n",
    "        # Define the pattern to replace\n",
    "        linear_to_l = r'_linear'\n",
    "        nonlinear_to_nl = r'_nonlinear'\n",
    "        heterogeneous_to_he = r'_heterogeneous'\n",
    "        homogeneous_to_ho = r'_homogeneous'\n",
    "\n",
    "        # Use regular expression to replace the part in column names\n",
    "        data_row.columns = data_row.columns.str.replace(linear_to_l, '_l')\n",
    "        data_row.columns = data_row.columns.str.replace(nonlinear_to_nl, '_nl')\n",
    "        data_row.columns = data_row.columns.str.replace(heterogeneous_to_he, '_he')\n",
    "        data_row.columns = data_row.columns.str.replace(homogeneous_to_ho, '_ho')\n",
    "\n",
    "        data_true_counterfactual = pd.read_csv(\"../datasets/text_data/sim/\"+dataset_name+'_true_counterfactual.csv')\n",
    "        data_true_counterfactual['time'] = data_true_counterfactual['time']+length_of_series-forecast_horizon-1\n",
    "        data_true_counterfactual = data_true_counterfactual.pivot(index='time', columns='series_id')['value']\n",
    "        data_true_counterfactual = data_true_counterfactual.loc[:,sorted(data_true_counterfactual.columns, key=custom_sort_key)]\n",
    "        # Replace values in data_row using the mapping\n",
    "        data_row_for_errors = data_row.copy()\n",
    "        data_row_for_errors.loc[data_true_counterfactual.index, data_true_counterfactual.columns] = data_true_counterfactual\n",
    "        data_row_for_errors.to_csv(\"../datasets/text_data/sim/\"+dataset_name+\"_for_errors.csv\")\n",
    "\n",
    "        data_row_A = data_row_for_errors.iloc[length_of_series-forecast_horizon:, :].T\n",
    "        data_row_B = data_row_for_errors.iloc[:length_of_series-forecast_horizon, :].T\n",
    "        # print(data_row_B.shape)\n",
    "        \n",
    "    if dataset_type == \"calls911\":\n",
    "        control = [\"BRIDGEPORT\", \"BRYN ATHYN\", \"DOUGLASS\", \"HATBORO\", \"HATFIELD BORO\",\n",
    "                      \"LOWER FREDERICK\", \"NEW HANOVER\", \"NORRISTOWN\", \"NORTH WALES\", \"SALFORD\",\n",
    "                      \"SPRINGFIELD\", \"TRAPPE\"]\n",
    "        data_row = pd.read_csv('../datasets/text_data/' + dataset_type\\\n",
    "                            + '/'+dataset_name+'.csv').iloc[:, 1:]\n",
    "        data_row_cols = data_row.columns\n",
    "        data_row_for_errors = data_row.loc[:,control]\n",
    "        data_row_for_errors.to_csv(\"../datasets/text_data/calls911/\"+dataset_name+\"_for_errors.csv\")\n",
    "        length_of_series = len(data_row.index)\n",
    "        y_true_df_A = data_row_for_errors.iloc[length_of_series-forecast_horizon:, :].T\n",
    "        y_true_df_B = data_row_for_errors.iloc[:length_of_series-forecast_horizon, :].T\n",
    "        data_row_A = y_true_df_A\n",
    "        # print(data_row_A)\n",
    "        data_row_B = y_true_df_B\n",
    "    \n",
    "    feature_type='M'\n",
    "    norm_type = 'B'\n",
    "    activation = 'relu'\n",
    "    dropout = 0.05\n",
    "    n_block=2\n",
    "    batch_size=31\n",
    "    no_of_series = len(data_row_B.index) \n",
    "    patience = 5\n",
    "    train_epochs = 100\n",
    "    learning_rate = 0.01\n",
    "    seasonality_period = 12\n",
    "    \n",
    "    input_size = int(seasonality_period * 1.25)\n",
    "    checkpoint_dir = '../checkpoints/'\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        data=dataset_name,\n",
    "        batch_size=batch_size,\n",
    "        seq_len=input_size,\n",
    "        pred_len=forecast_horizon,\n",
    "        feature_type=feature_type,\n",
    "        dt_type=dataset_type\n",
    "    )\n",
    "    train_data = data_loader.get_train()\n",
    "    # print(train_data)\n",
    "    val_data = data_loader.get_val()\n",
    "    test_data = data_loader.get_test()\n",
    "    # print(test_data)\n",
    "    build_model = getattr(benchmarks, 'tsmixer').build_model\n",
    "    model = build_model(\n",
    "        input_shape=(input_size, data_loader.n_feature),\n",
    "        pred_len=forecast_horizon,\n",
    "        norm_type=norm_type,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        n_block=n_block,\n",
    "        ff_dim=no_of_series,\n",
    "        target_slice=data_loader.target_slice,\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=sMAPE_tf, metrics=[sMAPE_tf])\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'{dataset_name}_best')\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience\n",
    "    )\n",
    "    start_training_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=train_epochs,\n",
    "        validation_data=val_data,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    )\n",
    "    end_training_time = time.time()\n",
    "    elasped_training_time = end_training_time - start_training_time\n",
    "    print(f'Training finished in {elasped_training_time} secconds')\n",
    "\n",
    "    # evaluate best model\n",
    "    best_epoch = np.argmin(history.history['val_loss'])\n",
    "    model.load_weights(checkpoint_path)\n",
    "    test_result = model.evaluate(test_data)\n",
    "    test_smape = test_result[1]\n",
    "    print(test_smape)\n",
    "\n",
    "    for f in glob.glob(checkpoint_path + '*'):\n",
    "        os.remove(f)\n",
    "    \n",
    "    prediction = model.predict(test_data)\n",
    "    y_pred = data_loader.inverse_transform(prediction[0])\n",
    "\n",
    "    output = '../results/benchmarks/predicted/' + dataset_name +\\\n",
    "            '_tsmixer.csv'\n",
    "    y_pred_df = pd.DataFrame(y_pred.T)\n",
    "    # print(y_pred_df)\n",
    "    y_pred_df.to_csv(output, index=False, header=False)\n",
    "    y_pred_for_errors = y_pred_df.copy()\n",
    "    if dataset_type == \"calls911\":\n",
    "        y_pred_for_errors['names'] = data_row_cols\n",
    "        y_pred_for_errors.set_index('names', inplace=True)\n",
    "        y_pred_for_errors = y_pred_for_errors.loc[control,:]\n",
    "\n",
    "    errors_directory = '../results/benchmarks/errors/'\n",
    "\n",
    "    errors_file_name_mean_median = 'mean_median_' + dataset_name + '_tsmixer'\n",
    "    SMAPE_file_name_all_errors = 'all_smape_errors_' + dataset_name + '_tsmixer'\n",
    "    MASE_file_name_all_errors = 'all_mase_errors_' + dataset_name + '_tsmixer'\n",
    "\n",
    "    errors_file_full_name_mean_median = errors_directory + errors_file_name_mean_median+'.txt'\n",
    "    SMAPE_file_full_name_all_errors = errors_directory + SMAPE_file_name_all_errors\n",
    "    MASE_file_full_name_all_errors = errors_directory + MASE_file_name_all_errors\n",
    "\n",
    "    # SMAPE\n",
    "    # print(y_pred_for_errors)\n",
    "    # print(data_row_A)\n",
    "    time_series_wise_SMAPE = 2 * np.abs(np.array(y_pred_for_errors) - np.array(data_row_A)) /\\\n",
    "        (np.abs(np.array(y_pred_for_errors)) + np.abs(np.array(data_row_A)))\n",
    "    SMAPEPerSeries = np.mean(time_series_wise_SMAPE, axis=1)\n",
    "    mean_SMAPE = np.mean(SMAPEPerSeries)\n",
    "    mean_SMAPE_str = f\"mean_SMAPE:{mean_SMAPE}\"\n",
    "    print(mean_SMAPE_str)\n",
    "    np.savetxt(SMAPE_file_full_name_all_errors+'.txt', SMAPEPerSeries, delimiter=\",\", fmt='%f')\n",
    "    mase_vector = []\n",
    "    for i in range(no_of_series):\n",
    "        lagged_diff = [data_row_B.iloc[i,j] - \\\n",
    "                   data_row_B.iloc[i,j - seasonality_period]\\\n",
    "                      for j in range(seasonality_period,\\\n",
    "                        len(data_row_B.columns))]\n",
    "        mase_vector.append(np.mean(np.abs(np.array(data_row_A.iloc[i])\\\n",
    "                 - np.array(y_pred_for_errors.iloc[i])) / np.mean(np.abs(lagged_diff))))\n",
    "\n",
    "    mean_MASE = np.mean(mase_vector)\n",
    "    mean_MASE_str = f\"mean_MASE:{mean_MASE}\"\n",
    "    print(mean_MASE_str)\n",
    "\n",
    "    np.savetxt(MASE_file_full_name_all_errors+'.txt', mase_vector, delimiter=\",\", fmt='%f')\n",
    "\n",
    "    # Writing the SMAPE results to file\n",
    "    with open(errors_file_full_name_mean_median, 'w') as f:\n",
    "        # f.write('\\n'.join([mean_SMAPE_str, median_SMAPE_str, std_SMAPE_str]))\n",
    "        f.write('\\n'.join([mean_SMAPE_str]))\n",
    "\n",
    "    # Writing the MASE results to file\n",
    "    with open(errors_file_full_name_mean_median, 'a') as f:\n",
    "        # f.write('\\n'.join([mean_MASE_str, median_MASE_str, std_MASE_str]))\n",
    "        f.write('\\n'.join([mean_MASE_str]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 22 22\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4862 - sMAPE_tf: 1.4862\n",
      "Epoch 1: val_loss improved from inf to 1.55433, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4862 - sMAPE_tf: 1.4862 - val_loss: 1.5543 - val_sMAPE_tf: 1.5543\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4645 - sMAPE_tf: 1.4645\n",
      "Epoch 2: val_loss improved from 1.55433 to 1.52753, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 1.4645 - sMAPE_tf: 1.4645 - val_loss: 1.5275 - val_sMAPE_tf: 1.5275\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4555 - sMAPE_tf: 1.4555\n",
      "Epoch 3: val_loss did not improve from 1.52753\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.4555 - sMAPE_tf: 1.4555 - val_loss: 1.5380 - val_sMAPE_tf: 1.5380\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4490 - sMAPE_tf: 1.4490\n",
      "Epoch 4: val_loss did not improve from 1.52753\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.4490 - sMAPE_tf: 1.4490 - val_loss: 1.5421 - val_sMAPE_tf: 1.5421\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4370 - sMAPE_tf: 1.4370\n",
      "Epoch 5: val_loss did not improve from 1.52753\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.4370 - sMAPE_tf: 1.4370 - val_loss: 1.5321 - val_sMAPE_tf: 1.5321\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4316 - sMAPE_tf: 1.4316\n",
      "Epoch 6: val_loss improved from 1.52753 to 1.51976, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4316 - sMAPE_tf: 1.4316 - val_loss: 1.5198 - val_sMAPE_tf: 1.5198\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4167 - sMAPE_tf: 1.4167\n",
      "Epoch 7: val_loss improved from 1.51976 to 1.51818, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.4167 - sMAPE_tf: 1.4167 - val_loss: 1.5182 - val_sMAPE_tf: 1.5182\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4139 - sMAPE_tf: 1.4139\n",
      "Epoch 8: val_loss improved from 1.51818 to 1.51256, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1.4139 - sMAPE_tf: 1.4139 - val_loss: 1.5126 - val_sMAPE_tf: 1.5126\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4102 - sMAPE_tf: 1.4102\n",
      "Epoch 9: val_loss improved from 1.51256 to 1.50103, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.4102 - sMAPE_tf: 1.4102 - val_loss: 1.5010 - val_sMAPE_tf: 1.5010\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3977 - sMAPE_tf: 1.3977\n",
      "Epoch 10: val_loss improved from 1.50103 to 1.49316, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.3977 - sMAPE_tf: 1.3977 - val_loss: 1.4932 - val_sMAPE_tf: 1.4932\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3955 - sMAPE_tf: 1.3955\n",
      "Epoch 11: val_loss improved from 1.49316 to 1.48495, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.3955 - sMAPE_tf: 1.3955 - val_loss: 1.4850 - val_sMAPE_tf: 1.4850\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3787 - sMAPE_tf: 1.3787\n",
      "Epoch 12: val_loss improved from 1.48495 to 1.47282, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.3787 - sMAPE_tf: 1.3787 - val_loss: 1.4728 - val_sMAPE_tf: 1.4728\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3747 - sMAPE_tf: 1.3747\n",
      "Epoch 13: val_loss improved from 1.47282 to 1.46461, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.3747 - sMAPE_tf: 1.3747 - val_loss: 1.4646 - val_sMAPE_tf: 1.4646\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3794 - sMAPE_tf: 1.3794\n",
      "Epoch 14: val_loss improved from 1.46461 to 1.44866, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.3794 - sMAPE_tf: 1.3794 - val_loss: 1.4487 - val_sMAPE_tf: 1.4487\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3703 - sMAPE_tf: 1.3703\n",
      "Epoch 15: val_loss improved from 1.44866 to 1.44228, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.3703 - sMAPE_tf: 1.3703 - val_loss: 1.4423 - val_sMAPE_tf: 1.4423\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3625 - sMAPE_tf: 1.3625\n",
      "Epoch 16: val_loss improved from 1.44228 to 1.43585, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.3625 - sMAPE_tf: 1.3625 - val_loss: 1.4358 - val_sMAPE_tf: 1.4358\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3540 - sMAPE_tf: 1.3540\n",
      "Epoch 17: val_loss improved from 1.43585 to 1.42657, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.3540 - sMAPE_tf: 1.3540 - val_loss: 1.4266 - val_sMAPE_tf: 1.4266\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3592 - sMAPE_tf: 1.3592\n",
      "Epoch 18: val_loss improved from 1.42657 to 1.40846, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 1.3592 - sMAPE_tf: 1.3592 - val_loss: 1.4085 - val_sMAPE_tf: 1.4085\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3424 - sMAPE_tf: 1.3424\n",
      "Epoch 19: val_loss improved from 1.40846 to 1.38800, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.3424 - sMAPE_tf: 1.3424 - val_loss: 1.3880 - val_sMAPE_tf: 1.3880\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3461 - sMAPE_tf: 1.3461\n",
      "Epoch 20: val_loss improved from 1.38800 to 1.38206, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 1.3461 - sMAPE_tf: 1.3461 - val_loss: 1.3821 - val_sMAPE_tf: 1.3821\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3389 - sMAPE_tf: 1.3389\n",
      "Epoch 21: val_loss improved from 1.38206 to 1.38100, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 1.3389 - sMAPE_tf: 1.3389 - val_loss: 1.3810 - val_sMAPE_tf: 1.3810\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3332 - sMAPE_tf: 1.3332\n",
      "Epoch 22: val_loss did not improve from 1.38100\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.3332 - sMAPE_tf: 1.3332 - val_loss: 1.3870 - val_sMAPE_tf: 1.3870\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3275 - sMAPE_tf: 1.3275\n",
      "Epoch 23: val_loss did not improve from 1.38100\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.3275 - sMAPE_tf: 1.3275 - val_loss: 1.3813 - val_sMAPE_tf: 1.3813\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3262 - sMAPE_tf: 1.3262\n",
      "Epoch 24: val_loss improved from 1.38100 to 1.37538, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.3262 - sMAPE_tf: 1.3262 - val_loss: 1.3754 - val_sMAPE_tf: 1.3754\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3195 - sMAPE_tf: 1.3195\n",
      "Epoch 25: val_loss did not improve from 1.37538\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.3195 - sMAPE_tf: 1.3195 - val_loss: 1.3809 - val_sMAPE_tf: 1.3809\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3177 - sMAPE_tf: 1.3177\n",
      "Epoch 26: val_loss did not improve from 1.37538\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.3177 - sMAPE_tf: 1.3177 - val_loss: 1.3790 - val_sMAPE_tf: 1.3790\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3132 - sMAPE_tf: 1.3132\n",
      "Epoch 27: val_loss did not improve from 1.37538\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.3132 - sMAPE_tf: 1.3132 - val_loss: 1.3756 - val_sMAPE_tf: 1.3756\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3079 - sMAPE_tf: 1.3079\n",
      "Epoch 28: val_loss improved from 1.37538 to 1.36750, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.3079 - sMAPE_tf: 1.3079 - val_loss: 1.3675 - val_sMAPE_tf: 1.3675\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3068 - sMAPE_tf: 1.3068\n",
      "Epoch 29: val_loss improved from 1.36750 to 1.36129, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 1.3068 - sMAPE_tf: 1.3068 - val_loss: 1.3613 - val_sMAPE_tf: 1.3613\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2969 - sMAPE_tf: 1.2969\n",
      "Epoch 30: val_loss did not improve from 1.36129\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.2969 - sMAPE_tf: 1.2969 - val_loss: 1.3617 - val_sMAPE_tf: 1.3617\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2935 - sMAPE_tf: 1.2935\n",
      "Epoch 31: val_loss did not improve from 1.36129\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.2935 - sMAPE_tf: 1.2935 - val_loss: 1.3652 - val_sMAPE_tf: 1.3652\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2858 - sMAPE_tf: 1.2858\n",
      "Epoch 32: val_loss did not improve from 1.36129\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.2858 - sMAPE_tf: 1.2858 - val_loss: 1.3695 - val_sMAPE_tf: 1.3695\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2850 - sMAPE_tf: 1.2850\n",
      "Epoch 33: val_loss did not improve from 1.36129\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.2850 - sMAPE_tf: 1.2850 - val_loss: 1.3737 - val_sMAPE_tf: 1.3737\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2869 - sMAPE_tf: 1.2869\n",
      "Epoch 34: val_loss did not improve from 1.36129\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.2869 - sMAPE_tf: 1.2869 - val_loss: 1.3746 - val_sMAPE_tf: 1.3746\n",
      "Training finished in 11.972004890441895 secconds\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.5715 - sMAPE_tf: 1.5715\n",
      "1.5714871883392334\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "mean_SMAPE:0.2574144658856225\n",
      "mean_MASE:1.1874566492618108\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'calls911_benchmarks'\n",
    "dataset_type = 'calls911'\n",
    "forecast_horizon=7\n",
    "\n",
    "tsmixer_eval(dataset_name,dataset_type,forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_10_60_l_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4879 - sMAPE_tf: 1.4879\n",
      "Epoch 1: val_loss improved from inf to 1.57394, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4879 - sMAPE_tf: 1.4879 - val_loss: 1.5739 - val_sMAPE_tf: 1.5739\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4645 - sMAPE_tf: 1.4645\n",
      "Epoch 2: val_loss improved from 1.57394 to 1.55414, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 1.4645 - sMAPE_tf: 1.4645 - val_loss: 1.5541 - val_sMAPE_tf: 1.5541\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4289 - sMAPE_tf: 1.4289\n",
      "Epoch 3: val_loss improved from 1.55414 to 1.53777, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.4289 - sMAPE_tf: 1.4289 - val_loss: 1.5378 - val_sMAPE_tf: 1.5378\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4248 - sMAPE_tf: 1.4248\n",
      "Epoch 4: val_loss improved from 1.53777 to 1.53337, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.4248 - sMAPE_tf: 1.4248 - val_loss: 1.5334 - val_sMAPE_tf: 1.5334\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4036 - sMAPE_tf: 1.4036\n",
      "Epoch 5: val_loss did not improve from 1.53337\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.4036 - sMAPE_tf: 1.4036 - val_loss: 1.5453 - val_sMAPE_tf: 1.5453\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3752 - sMAPE_tf: 1.3752\n",
      "Epoch 6: val_loss did not improve from 1.53337\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.3752 - sMAPE_tf: 1.3752 - val_loss: 1.5401 - val_sMAPE_tf: 1.5401\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3894 - sMAPE_tf: 1.3894\n",
      "Epoch 7: val_loss improved from 1.53337 to 1.52791, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.3894 - sMAPE_tf: 1.3894 - val_loss: 1.5279 - val_sMAPE_tf: 1.5279\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3496 - sMAPE_tf: 1.3496\n",
      "Epoch 8: val_loss improved from 1.52791 to 1.51829, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.3496 - sMAPE_tf: 1.3496 - val_loss: 1.5183 - val_sMAPE_tf: 1.5183\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3753 - sMAPE_tf: 1.3753\n",
      "Epoch 9: val_loss improved from 1.51829 to 1.51299, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.3753 - sMAPE_tf: 1.3753 - val_loss: 1.5130 - val_sMAPE_tf: 1.5130\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3292 - sMAPE_tf: 1.3292\n",
      "Epoch 10: val_loss improved from 1.51299 to 1.50630, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.3292 - sMAPE_tf: 1.3292 - val_loss: 1.5063 - val_sMAPE_tf: 1.5063\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3402 - sMAPE_tf: 1.3402\n",
      "Epoch 11: val_loss improved from 1.50630 to 1.48985, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.3402 - sMAPE_tf: 1.3402 - val_loss: 1.4898 - val_sMAPE_tf: 1.4898\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3146 - sMAPE_tf: 1.3146\n",
      "Epoch 12: val_loss improved from 1.48985 to 1.46406, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.3146 - sMAPE_tf: 1.3146 - val_loss: 1.4641 - val_sMAPE_tf: 1.4641\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3187 - sMAPE_tf: 1.3187\n",
      "Epoch 13: val_loss improved from 1.46406 to 1.43968, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 1.3187 - sMAPE_tf: 1.3187 - val_loss: 1.4397 - val_sMAPE_tf: 1.4397\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3057 - sMAPE_tf: 1.3057\n",
      "Epoch 14: val_loss improved from 1.43968 to 1.43332, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.3057 - sMAPE_tf: 1.3057 - val_loss: 1.4333 - val_sMAPE_tf: 1.4333\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2794 - sMAPE_tf: 1.2794\n",
      "Epoch 15: val_loss improved from 1.43332 to 1.42975, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.2794 - sMAPE_tf: 1.2794 - val_loss: 1.4297 - val_sMAPE_tf: 1.4297\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2757 - sMAPE_tf: 1.2757\n",
      "Epoch 16: val_loss improved from 1.42975 to 1.42733, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.2757 - sMAPE_tf: 1.2757 - val_loss: 1.4273 - val_sMAPE_tf: 1.4273\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2590 - sMAPE_tf: 1.2590\n",
      "Epoch 17: val_loss did not improve from 1.42733\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.2590 - sMAPE_tf: 1.2590 - val_loss: 1.4340 - val_sMAPE_tf: 1.4340\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2570 - sMAPE_tf: 1.2570\n",
      "Epoch 18: val_loss did not improve from 1.42733\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.2570 - sMAPE_tf: 1.2570 - val_loss: 1.4403 - val_sMAPE_tf: 1.4403\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2149 - sMAPE_tf: 1.2149\n",
      "Epoch 19: val_loss did not improve from 1.42733\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.2149 - sMAPE_tf: 1.2149 - val_loss: 1.4401 - val_sMAPE_tf: 1.4401\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1950 - sMAPE_tf: 1.1950\n",
      "Epoch 20: val_loss did not improve from 1.42733\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.1950 - sMAPE_tf: 1.1950 - val_loss: 1.4329 - val_sMAPE_tf: 1.4329\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2032 - sMAPE_tf: 1.2032\n",
      "Epoch 21: val_loss did not improve from 1.42733\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.2032 - sMAPE_tf: 1.2032 - val_loss: 1.4301 - val_sMAPE_tf: 1.4301\n",
      "Training finished in 8.170550107955933 secconds\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5772 - sMAPE_tf: 1.5772\n",
      "1.5771735906600952\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "mean_SMAPE:0.5353005418400689\n",
      "mean_MASE:1.7135728166900193\n",
      "sim_10_60_l_ho\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4260 - sMAPE_tf: 1.4260\n",
      "Epoch 1: val_loss improved from inf to 1.54168, saving model to ../checkpoints/sim_10_60_l_ho_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4260 - sMAPE_tf: 1.4260 - val_loss: 1.5417 - val_sMAPE_tf: 1.5417\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3908 - sMAPE_tf: 1.3908\n",
      "Epoch 2: val_loss improved from 1.54168 to 1.51485, saving model to ../checkpoints/sim_10_60_l_ho_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.3908 - sMAPE_tf: 1.3908 - val_loss: 1.5148 - val_sMAPE_tf: 1.5148\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3854 - sMAPE_tf: 1.3854\n",
      "Epoch 3: val_loss improved from 1.51485 to 1.49034, saving model to ../checkpoints/sim_10_60_l_ho_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.3854 - sMAPE_tf: 1.3854 - val_loss: 1.4903 - val_sMAPE_tf: 1.4903\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3634 - sMAPE_tf: 1.3634\n",
      "Epoch 4: val_loss did not improve from 1.49034\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.3634 - sMAPE_tf: 1.3634 - val_loss: 1.4967 - val_sMAPE_tf: 1.4967\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3613 - sMAPE_tf: 1.3613\n",
      "Epoch 5: val_loss did not improve from 1.49034\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.3613 - sMAPE_tf: 1.3613 - val_loss: 1.5103 - val_sMAPE_tf: 1.5103\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3249 - sMAPE_tf: 1.3249\n",
      "Epoch 6: val_loss did not improve from 1.49034\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.3249 - sMAPE_tf: 1.3249 - val_loss: 1.5239 - val_sMAPE_tf: 1.5239\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3378 - sMAPE_tf: 1.3378\n",
      "Epoch 7: val_loss did not improve from 1.49034\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.3378 - sMAPE_tf: 1.3378 - val_loss: 1.5153 - val_sMAPE_tf: 1.5153\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3244 - sMAPE_tf: 1.3244\n",
      "Epoch 8: val_loss did not improve from 1.49034\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.3244 - sMAPE_tf: 1.3244 - val_loss: 1.5036 - val_sMAPE_tf: 1.5036\n",
      "Training finished in 4.907898187637329 secconds\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4693 - sMAPE_tf: 1.4693\n",
      "1.46933913230896\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "mean_SMAPE:0.6155365289780661\n",
      "mean_MASE:2.1078267130045396\n",
      "sim_10_60_nl_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4604 - sMAPE_tf: 1.4604\n",
      "Epoch 1: val_loss improved from inf to 1.45983, saving model to ../checkpoints/sim_10_60_nl_he_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4604 - sMAPE_tf: 1.4604 - val_loss: 1.4598 - val_sMAPE_tf: 1.4598\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4366 - sMAPE_tf: 1.4366\n",
      "Epoch 2: val_loss improved from 1.45983 to 1.44044, saving model to ../checkpoints/sim_10_60_nl_he_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.4366 - sMAPE_tf: 1.4366 - val_loss: 1.4404 - val_sMAPE_tf: 1.4404\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4342 - sMAPE_tf: 1.4342\n",
      "Epoch 3: val_loss improved from 1.44044 to 1.40141, saving model to ../checkpoints/sim_10_60_nl_he_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.4342 - sMAPE_tf: 1.4342 - val_loss: 1.4014 - val_sMAPE_tf: 1.4014\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4141 - sMAPE_tf: 1.4141\n",
      "Epoch 4: val_loss improved from 1.40141 to 1.39085, saving model to ../checkpoints/sim_10_60_nl_he_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.4141 - sMAPE_tf: 1.4141 - val_loss: 1.3908 - val_sMAPE_tf: 1.3908\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3891 - sMAPE_tf: 1.3891\n",
      "Epoch 5: val_loss did not improve from 1.39085\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.3891 - sMAPE_tf: 1.3891 - val_loss: 1.3962 - val_sMAPE_tf: 1.3962\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3746 - sMAPE_tf: 1.3746\n",
      "Epoch 6: val_loss did not improve from 1.39085\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.3746 - sMAPE_tf: 1.3746 - val_loss: 1.4185 - val_sMAPE_tf: 1.4185\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3685 - sMAPE_tf: 1.3685\n",
      "Epoch 7: val_loss did not improve from 1.39085\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.3685 - sMAPE_tf: 1.3685 - val_loss: 1.4364 - val_sMAPE_tf: 1.4364\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3625 - sMAPE_tf: 1.3625\n",
      "Epoch 8: val_loss did not improve from 1.39085\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.3625 - sMAPE_tf: 1.3625 - val_loss: 1.4183 - val_sMAPE_tf: 1.4183\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3307 - sMAPE_tf: 1.3307\n",
      "Epoch 9: val_loss did not improve from 1.39085\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.3307 - sMAPE_tf: 1.3307 - val_loss: 1.4028 - val_sMAPE_tf: 1.4028\n",
      "Training finished in 5.128064393997192 secconds\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4505 - sMAPE_tf: 1.4505\n",
      "1.450477957725525\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "mean_SMAPE:0.8756821471026903\n",
      "mean_MASE:1.9791175250141557\n",
      "sim_10_60_nl_ho\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4539 - sMAPE_tf: 1.4539\n",
      "Epoch 1: val_loss improved from inf to 1.41418, saving model to ../checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4539 - sMAPE_tf: 1.4539 - val_loss: 1.4142 - val_sMAPE_tf: 1.4142\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4527 - sMAPE_tf: 1.4527\n",
      "Epoch 2: val_loss improved from 1.41418 to 1.41104, saving model to ../checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.4527 - sMAPE_tf: 1.4527 - val_loss: 1.4110 - val_sMAPE_tf: 1.4110\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4539 - sMAPE_tf: 1.4539\n",
      "Epoch 3: val_loss did not improve from 1.41104\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.4539 - sMAPE_tf: 1.4539 - val_loss: 1.4187 - val_sMAPE_tf: 1.4187\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4215 - sMAPE_tf: 1.4215\n",
      "Epoch 4: val_loss did not improve from 1.41104\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.4215 - sMAPE_tf: 1.4215 - val_loss: 1.4267 - val_sMAPE_tf: 1.4267\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4350 - sMAPE_tf: 1.4350\n",
      "Epoch 5: val_loss did not improve from 1.41104\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.4350 - sMAPE_tf: 1.4350 - val_loss: 1.4360 - val_sMAPE_tf: 1.4360\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4080 - sMAPE_tf: 1.4080\n",
      "Epoch 6: val_loss did not improve from 1.41104\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.4080 - sMAPE_tf: 1.4080 - val_loss: 1.4120 - val_sMAPE_tf: 1.4120\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4281 - sMAPE_tf: 1.4281\n",
      "Epoch 7: val_loss improved from 1.41104 to 1.40648, saving model to ../checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.4281 - sMAPE_tf: 1.4281 - val_loss: 1.4065 - val_sMAPE_tf: 1.4065\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3946 - sMAPE_tf: 1.3946\n",
      "Epoch 8: val_loss improved from 1.40648 to 1.39709, saving model to ../checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.3946 - sMAPE_tf: 1.3946 - val_loss: 1.3971 - val_sMAPE_tf: 1.3971\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4034 - sMAPE_tf: 1.4034\n",
      "Epoch 9: val_loss improved from 1.39709 to 1.38549, saving model to ../checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.4034 - sMAPE_tf: 1.4034 - val_loss: 1.3855 - val_sMAPE_tf: 1.3855\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3744 - sMAPE_tf: 1.3744\n",
      "Epoch 10: val_loss improved from 1.38549 to 1.38192, saving model to ../checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.3744 - sMAPE_tf: 1.3744 - val_loss: 1.3819 - val_sMAPE_tf: 1.3819\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4013 - sMAPE_tf: 1.4013\n",
      "Epoch 11: val_loss did not improve from 1.38192\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.4013 - sMAPE_tf: 1.4013 - val_loss: 1.3842 - val_sMAPE_tf: 1.3842\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3594 - sMAPE_tf: 1.3594\n",
      "Epoch 12: val_loss did not improve from 1.38192\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.3594 - sMAPE_tf: 1.3594 - val_loss: 1.3914 - val_sMAPE_tf: 1.3914\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3663 - sMAPE_tf: 1.3663\n",
      "Epoch 13: val_loss did not improve from 1.38192\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.3663 - sMAPE_tf: 1.3663 - val_loss: 1.4024 - val_sMAPE_tf: 1.4024\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3580 - sMAPE_tf: 1.3580\n",
      "Epoch 14: val_loss did not improve from 1.38192\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.3580 - sMAPE_tf: 1.3580 - val_loss: 1.4118 - val_sMAPE_tf: 1.4118\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3744 - sMAPE_tf: 1.3744\n",
      "Epoch 15: val_loss did not improve from 1.38192\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.3744 - sMAPE_tf: 1.3744 - val_loss: 1.4114 - val_sMAPE_tf: 1.4114\n",
      "Training finished in 6.3444976806640625 secconds\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4493 - sMAPE_tf: 1.4493\n",
      "1.4493162631988525\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fddc83b5000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "mean_SMAPE:1.1417902469160843\n",
      "mean_MASE:2.413781141333774\n",
      "sim_10_222_l_he\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "1/6 [====>.........................] - ETA: 14s - loss: 1.4397 - sMAPE_tf: 1.4397\n",
      "Epoch 1: val_loss improved from inf to 1.43397, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 4s 123ms/step - loss: 1.4200 - sMAPE_tf: 1.4180 - val_loss: 1.4340 - val_sMAPE_tf: 1.4340\n",
      "Epoch 2/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3663 - sMAPE_tf: 1.3663\n",
      "Epoch 2: val_loss improved from 1.43397 to 1.37043, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.3317 - sMAPE_tf: 1.3275 - val_loss: 1.3704 - val_sMAPE_tf: 1.3704\n",
      "Epoch 3/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2635 - sMAPE_tf: 1.2635\n",
      "Epoch 3: val_loss improved from 1.37043 to 1.25823, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.2511 - sMAPE_tf: 1.2481 - val_loss: 1.2582 - val_sMAPE_tf: 1.2582\n",
      "Epoch 4/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2435 - sMAPE_tf: 1.2435\n",
      "Epoch 4: val_loss improved from 1.25823 to 1.21332, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.2122 - sMAPE_tf: 1.2126 - val_loss: 1.2133 - val_sMAPE_tf: 1.2133\n",
      "Epoch 5/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1615 - sMAPE_tf: 1.1615\n",
      "Epoch 5: val_loss improved from 1.21332 to 1.15770, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.1623 - sMAPE_tf: 1.1625 - val_loss: 1.1577 - val_sMAPE_tf: 1.1577\n",
      "Epoch 6/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1341 - sMAPE_tf: 1.1341\n",
      "Epoch 6: val_loss improved from 1.15770 to 1.12778, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.1140 - sMAPE_tf: 1.1148 - val_loss: 1.1278 - val_sMAPE_tf: 1.1278\n",
      "Epoch 7/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0719 - sMAPE_tf: 1.0719\n",
      "Epoch 7: val_loss improved from 1.12778 to 1.03519, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.0782 - sMAPE_tf: 1.0773 - val_loss: 1.0352 - val_sMAPE_tf: 1.0352\n",
      "Epoch 8/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0526 - sMAPE_tf: 1.0526\n",
      "Epoch 8: val_loss improved from 1.03519 to 0.93487, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.0460 - sMAPE_tf: 1.0450 - val_loss: 0.9349 - val_sMAPE_tf: 0.9349\n",
      "Epoch 9/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9960 - sMAPE_tf: 0.9960\n",
      "Epoch 9: val_loss improved from 0.93487 to 0.92475, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 1.0105 - sMAPE_tf: 1.0088 - val_loss: 0.9247 - val_sMAPE_tf: 0.9247\n",
      "Epoch 10/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9768 - sMAPE_tf: 0.9768\n",
      "Epoch 10: val_loss did not improve from 0.92475\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9810 - sMAPE_tf: 0.9797 - val_loss: 0.9448 - val_sMAPE_tf: 0.9448\n",
      "Epoch 11/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9739 - sMAPE_tf: 0.9739\n",
      "Epoch 11: val_loss improved from 0.92475 to 0.92296, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.9638 - sMAPE_tf: 0.9665 - val_loss: 0.9230 - val_sMAPE_tf: 0.9230\n",
      "Epoch 12/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9823 - sMAPE_tf: 0.9823\n",
      "Epoch 12: val_loss improved from 0.92296 to 0.87950, saving model to ../checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.9419 - sMAPE_tf: 0.9377 - val_loss: 0.8795 - val_sMAPE_tf: 0.8795\n",
      "Epoch 13/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9125 - sMAPE_tf: 0.9125\n",
      "Epoch 13: val_loss did not improve from 0.87950\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9202 - sMAPE_tf: 0.9188 - val_loss: 0.8818 - val_sMAPE_tf: 0.8818\n",
      "Epoch 14/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8996 - sMAPE_tf: 0.8996\n",
      "Epoch 14: val_loss did not improve from 0.87950\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9247 - sMAPE_tf: 0.9239 - val_loss: 0.9460 - val_sMAPE_tf: 0.9460\n",
      "Epoch 15/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9613 - sMAPE_tf: 0.9613\n",
      "Epoch 15: val_loss did not improve from 0.87950\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9154 - sMAPE_tf: 0.9136 - val_loss: 0.9018 - val_sMAPE_tf: 0.9018\n",
      "Epoch 16/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8852 - sMAPE_tf: 0.8852\n",
      "Epoch 16: val_loss did not improve from 0.87950\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8941 - sMAPE_tf: 0.8935 - val_loss: 0.9228 - val_sMAPE_tf: 0.9228\n",
      "Epoch 17/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8656 - sMAPE_tf: 0.8656\n",
      "Epoch 17: val_loss did not improve from 0.87950\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8852 - sMAPE_tf: 0.8829 - val_loss: 0.9713 - val_sMAPE_tf: 0.9713\n",
      "Training finished in 7.751647710800171 secconds\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6490 - sMAPE_tf: 0.6490\n",
      "0.6490389108657837\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdda814c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "mean_SMAPE:0.18428284439114548\n",
      "mean_MASE:0.6973379737472275\n",
      "sim_10_222_l_ho\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "1/6 [====>.........................] - ETA: 17s - loss: 1.4455 - sMAPE_tf: 1.4455\n",
      "Epoch 1: val_loss improved from inf to 1.29392, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 4s 121ms/step - loss: 1.4188 - sMAPE_tf: 1.4148 - val_loss: 1.2939 - val_sMAPE_tf: 1.2939\n",
      "Epoch 2/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3971 - sMAPE_tf: 1.3971\n",
      "Epoch 2: val_loss improved from 1.29392 to 1.09704, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.3391 - sMAPE_tf: 1.3368 - val_loss: 1.0970 - val_sMAPE_tf: 1.0970\n",
      "Epoch 3/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2811 - sMAPE_tf: 1.2811\n",
      "Epoch 3: val_loss improved from 1.09704 to 0.95772, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 1.2572 - sMAPE_tf: 1.2534 - val_loss: 0.9577 - val_sMAPE_tf: 0.9577\n",
      "Epoch 4/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2051 - sMAPE_tf: 1.2051\n",
      "Epoch 4: val_loss did not improve from 0.95772\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.1990 - sMAPE_tf: 1.1960 - val_loss: 0.9691 - val_sMAPE_tf: 0.9691\n",
      "Epoch 5/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1989 - sMAPE_tf: 1.1989\n",
      "Epoch 5: val_loss improved from 0.95772 to 0.94545, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 1.1721 - sMAPE_tf: 1.1699 - val_loss: 0.9455 - val_sMAPE_tf: 0.9455\n",
      "Epoch 6/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1346 - sMAPE_tf: 1.1346\n",
      "Epoch 6: val_loss improved from 0.94545 to 0.92946, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 1.1274 - sMAPE_tf: 1.1256 - val_loss: 0.9295 - val_sMAPE_tf: 0.9295\n",
      "Epoch 7/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1228 - sMAPE_tf: 1.1228\n",
      "Epoch 7: val_loss improved from 0.92946 to 0.91170, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.0949 - sMAPE_tf: 1.0907 - val_loss: 0.9117 - val_sMAPE_tf: 0.9117\n",
      "Epoch 8/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0566 - sMAPE_tf: 1.0566\n",
      "Epoch 8: val_loss improved from 0.91170 to 0.85353, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.0522 - sMAPE_tf: 1.0514 - val_loss: 0.8535 - val_sMAPE_tf: 0.8535\n",
      "Epoch 9/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0246 - sMAPE_tf: 1.0246\n",
      "Epoch 9: val_loss improved from 0.85353 to 0.79825, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.0293 - sMAPE_tf: 1.0273 - val_loss: 0.7982 - val_sMAPE_tf: 0.7982\n",
      "Epoch 10/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0285 - sMAPE_tf: 1.0285\n",
      "Epoch 10: val_loss improved from 0.79825 to 0.78700, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.0040 - sMAPE_tf: 1.0000 - val_loss: 0.7870 - val_sMAPE_tf: 0.7870\n",
      "Epoch 11/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9782 - sMAPE_tf: 0.9782\n",
      "Epoch 11: val_loss did not improve from 0.78700\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9899 - sMAPE_tf: 0.9906 - val_loss: 0.8142 - val_sMAPE_tf: 0.8142\n",
      "Epoch 12/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9812 - sMAPE_tf: 0.9812\n",
      "Epoch 12: val_loss did not improve from 0.78700\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9650 - sMAPE_tf: 0.9665 - val_loss: 0.7892 - val_sMAPE_tf: 0.7892\n",
      "Epoch 13/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9542 - sMAPE_tf: 0.9542\n",
      "Epoch 13: val_loss improved from 0.78700 to 0.76215, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.9486 - sMAPE_tf: 0.9483 - val_loss: 0.7621 - val_sMAPE_tf: 0.7621\n",
      "Epoch 14/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9424 - sMAPE_tf: 0.9424\n",
      "Epoch 14: val_loss improved from 0.76215 to 0.72016, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.9331 - sMAPE_tf: 0.9343 - val_loss: 0.7202 - val_sMAPE_tf: 0.7202\n",
      "Epoch 15/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9040 - sMAPE_tf: 0.9040\n",
      "Epoch 15: val_loss did not improve from 0.72016\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9145 - sMAPE_tf: 0.9164 - val_loss: 0.7524 - val_sMAPE_tf: 0.7524\n",
      "Epoch 16/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8982 - sMAPE_tf: 0.8982\n",
      "Epoch 16: val_loss did not improve from 0.72016\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.9082 - sMAPE_tf: 0.9074 - val_loss: 0.7352 - val_sMAPE_tf: 0.7352\n",
      "Epoch 17/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8985 - sMAPE_tf: 0.8985\n",
      "Epoch 17: val_loss improved from 0.72016 to 0.69616, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.8958 - sMAPE_tf: 0.8973 - val_loss: 0.6962 - val_sMAPE_tf: 0.6962\n",
      "Epoch 18/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8872 - sMAPE_tf: 0.8872\n",
      "Epoch 18: val_loss did not improve from 0.69616\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.8806 - sMAPE_tf: 0.8823 - val_loss: 0.7068 - val_sMAPE_tf: 0.7068\n",
      "Epoch 19/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8358 - sMAPE_tf: 0.8358\n",
      "Epoch 19: val_loss did not improve from 0.69616\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8792 - sMAPE_tf: 0.8793 - val_loss: 0.6985 - val_sMAPE_tf: 0.6985\n",
      "Epoch 20/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8749 - sMAPE_tf: 0.8749\n",
      "Epoch 20: val_loss improved from 0.69616 to 0.69477, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.8678 - sMAPE_tf: 0.8691 - val_loss: 0.6948 - val_sMAPE_tf: 0.6948\n",
      "Epoch 21/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8673 - sMAPE_tf: 0.8673\n",
      "Epoch 21: val_loss did not improve from 0.69477\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8520 - sMAPE_tf: 0.8524 - val_loss: 0.7184 - val_sMAPE_tf: 0.7184\n",
      "Epoch 22/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8325 - sMAPE_tf: 0.8325\n",
      "Epoch 22: val_loss did not improve from 0.69477\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8450 - sMAPE_tf: 0.8430 - val_loss: 0.7143 - val_sMAPE_tf: 0.7143\n",
      "Epoch 23/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8490 - sMAPE_tf: 0.8490\n",
      "Epoch 23: val_loss improved from 0.69477 to 0.67873, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.8426 - sMAPE_tf: 0.8425 - val_loss: 0.6787 - val_sMAPE_tf: 0.6787\n",
      "Epoch 24/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.7939 - sMAPE_tf: 0.7939\n",
      "Epoch 24: val_loss did not improve from 0.67873\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8301 - sMAPE_tf: 0.8324 - val_loss: 0.6864 - val_sMAPE_tf: 0.6864\n",
      "Epoch 25/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8065 - sMAPE_tf: 0.8065\n",
      "Epoch 25: val_loss improved from 0.67873 to 0.67586, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.8225 - sMAPE_tf: 0.8207 - val_loss: 0.6759 - val_sMAPE_tf: 0.6759\n",
      "Epoch 26/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8449 - sMAPE_tf: 0.8449\n",
      "Epoch 26: val_loss improved from 0.67586 to 0.66952, saving model to ../checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.8292 - sMAPE_tf: 0.8258 - val_loss: 0.6695 - val_sMAPE_tf: 0.6695\n",
      "Epoch 27/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8038 - sMAPE_tf: 0.8038\n",
      "Epoch 27: val_loss did not improve from 0.66952\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.8341 - sMAPE_tf: 0.8351 - val_loss: 0.6769 - val_sMAPE_tf: 0.6769\n",
      "Epoch 28/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8223 - sMAPE_tf: 0.8223\n",
      "Epoch 28: val_loss did not improve from 0.66952\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8205 - sMAPE_tf: 0.8234 - val_loss: 0.7128 - val_sMAPE_tf: 0.7128\n",
      "Epoch 29/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8454 - sMAPE_tf: 0.8454\n",
      "Epoch 29: val_loss did not improve from 0.66952\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8190 - sMAPE_tf: 0.8237 - val_loss: 0.7079 - val_sMAPE_tf: 0.7079\n",
      "Epoch 30/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8184 - sMAPE_tf: 0.8184\n",
      "Epoch 30: val_loss did not improve from 0.66952\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8008 - sMAPE_tf: 0.8020 - val_loss: 0.7579 - val_sMAPE_tf: 0.7579\n",
      "Epoch 31/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.7914 - sMAPE_tf: 0.7914\n",
      "Epoch 31: val_loss did not improve from 0.66952\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.7866 - sMAPE_tf: 0.7884 - val_loss: 0.7098 - val_sMAPE_tf: 0.7098\n",
      "Training finished in 12.061492204666138 secconds\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.9659 - sMAPE_tf: 0.9659\n",
      "0.9659355282783508\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "mean_SMAPE:0.4159102916976759\n",
      "mean_MASE:1.3947149303493478\n",
      "sim_10_222_nl_he\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "1/6 [====>.........................] - ETA: 14s - loss: 1.4668 - sMAPE_tf: 1.4668\n",
      "Epoch 1: val_loss improved from inf to 1.41029, saving model to ../checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 4s 125ms/step - loss: 1.4321 - sMAPE_tf: 1.4308 - val_loss: 1.4103 - val_sMAPE_tf: 1.4103\n",
      "Epoch 2/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.4069 - sMAPE_tf: 1.4069\n",
      "Epoch 2: val_loss improved from 1.41029 to 1.37494, saving model to ../checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.3906 - sMAPE_tf: 1.3898 - val_loss: 1.3749 - val_sMAPE_tf: 1.3749\n",
      "Epoch 3/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3734 - sMAPE_tf: 1.3734\n",
      "Epoch 3: val_loss improved from 1.37494 to 1.35839, saving model to ../checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.3605 - sMAPE_tf: 1.3573 - val_loss: 1.3584 - val_sMAPE_tf: 1.3584\n",
      "Epoch 4/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3585 - sMAPE_tf: 1.3585\n",
      "Epoch 4: val_loss improved from 1.35839 to 1.32791, saving model to ../checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.3402 - sMAPE_tf: 1.3393 - val_loss: 1.3279 - val_sMAPE_tf: 1.3279\n",
      "Epoch 5/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3078 - sMAPE_tf: 1.3078\n",
      "Epoch 5: val_loss improved from 1.32791 to 1.29147, saving model to ../checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.3172 - sMAPE_tf: 1.3193 - val_loss: 1.2915 - val_sMAPE_tf: 1.2915\n",
      "Epoch 6/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2832 - sMAPE_tf: 1.2832\n",
      "Epoch 6: val_loss improved from 1.29147 to 1.27401, saving model to ../checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.2910 - sMAPE_tf: 1.2940 - val_loss: 1.2740 - val_sMAPE_tf: 1.2740\n",
      "Epoch 7/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2861 - sMAPE_tf: 1.2861\n",
      "Epoch 7: val_loss did not improve from 1.27401\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2724 - sMAPE_tf: 1.2697 - val_loss: 1.2997 - val_sMAPE_tf: 1.2997\n",
      "Epoch 8/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2530 - sMAPE_tf: 1.2530\n",
      "Epoch 8: val_loss did not improve from 1.27401\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.2487 - sMAPE_tf: 1.2493 - val_loss: 1.2884 - val_sMAPE_tf: 1.2884\n",
      "Epoch 9/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2433 - sMAPE_tf: 1.2433\n",
      "Epoch 9: val_loss did not improve from 1.27401\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.2306 - sMAPE_tf: 1.2277 - val_loss: 1.2921 - val_sMAPE_tf: 1.2921\n",
      "Epoch 10/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2077 - sMAPE_tf: 1.2077\n",
      "Epoch 10: val_loss did not improve from 1.27401\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2216 - sMAPE_tf: 1.2205 - val_loss: 1.3235 - val_sMAPE_tf: 1.3235\n",
      "Epoch 11/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2036 - sMAPE_tf: 1.2036\n",
      "Epoch 11: val_loss did not improve from 1.27401\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1976 - sMAPE_tf: 1.1982 - val_loss: 1.3591 - val_sMAPE_tf: 1.3591\n",
      "Training finished in 6.205814838409424 secconds\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2398 - sMAPE_tf: 1.2398\n",
      "1.2398459911346436\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "mean_SMAPE:0.5876188535131116\n",
      "mean_MASE:1.085468119994182\n",
      "sim_10_222_nl_ho\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "1/6 [====>.........................] - ETA: 14s - loss: 1.4438 - sMAPE_tf: 1.4438\n",
      "Epoch 1: val_loss improved from inf to 1.32793, saving model to ../checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 4s 127ms/step - loss: 1.4375 - sMAPE_tf: 1.4353 - val_loss: 1.3279 - val_sMAPE_tf: 1.3279\n",
      "Epoch 2/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3826 - sMAPE_tf: 1.3826\n",
      "Epoch 2: val_loss improved from 1.32793 to 1.26707, saving model to ../checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.3778 - sMAPE_tf: 1.3778 - val_loss: 1.2671 - val_sMAPE_tf: 1.2671\n",
      "Epoch 3/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3543 - sMAPE_tf: 1.3543\n",
      "Epoch 3: val_loss did not improve from 1.26707\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3465 - sMAPE_tf: 1.3442 - val_loss: 1.3311 - val_sMAPE_tf: 1.3311\n",
      "Epoch 4/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3264 - sMAPE_tf: 1.3264\n",
      "Epoch 4: val_loss did not improve from 1.26707\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.3053 - sMAPE_tf: 1.3032 - val_loss: 1.3395 - val_sMAPE_tf: 1.3395\n",
      "Epoch 5/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2524 - sMAPE_tf: 1.2524\n",
      "Epoch 5: val_loss did not improve from 1.26707\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2708 - sMAPE_tf: 1.2712 - val_loss: 1.2795 - val_sMAPE_tf: 1.2795\n",
      "Epoch 6/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2435 - sMAPE_tf: 1.2435\n",
      "Epoch 6: val_loss improved from 1.26707 to 1.25074, saving model to ../checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.2517 - sMAPE_tf: 1.2498 - val_loss: 1.2507 - val_sMAPE_tf: 1.2507\n",
      "Epoch 7/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2135 - sMAPE_tf: 1.2135\n",
      "Epoch 7: val_loss improved from 1.25074 to 1.20961, saving model to ../checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 1.2230 - sMAPE_tf: 1.2232 - val_loss: 1.2096 - val_sMAPE_tf: 1.2096\n",
      "Epoch 8/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2127 - sMAPE_tf: 1.2127\n",
      "Epoch 8: val_loss did not improve from 1.20961\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.2028 - sMAPE_tf: 1.1996 - val_loss: 1.2215 - val_sMAPE_tf: 1.2215\n",
      "Epoch 9/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1875 - sMAPE_tf: 1.1875\n",
      "Epoch 9: val_loss did not improve from 1.20961\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1785 - sMAPE_tf: 1.1768 - val_loss: 1.2652 - val_sMAPE_tf: 1.2652\n",
      "Epoch 10/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1637 - sMAPE_tf: 1.1637\n",
      "Epoch 10: val_loss did not improve from 1.20961\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1578 - sMAPE_tf: 1.1577 - val_loss: 1.2305 - val_sMAPE_tf: 1.2305\n",
      "Epoch 11/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1666 - sMAPE_tf: 1.1666\n",
      "Epoch 11: val_loss did not improve from 1.20961\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1469 - sMAPE_tf: 1.1439 - val_loss: 1.2279 - val_sMAPE_tf: 1.2279\n",
      "Epoch 12/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1437 - sMAPE_tf: 1.1437\n",
      "Epoch 12: val_loss did not improve from 1.20961\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.1299 - sMAPE_tf: 1.1277 - val_loss: 1.2406 - val_sMAPE_tf: 1.2406\n",
      "Training finished in 6.249974489212036 secconds\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.4700 - sMAPE_tf: 1.4700\n",
      "1.4700441360473633\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "mean_SMAPE:0.6894926875562248\n",
      "mean_MASE:1.1466570731417558\n",
      "sim_101_60_l_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4835 - sMAPE_tf: 1.4835\n",
      "Epoch 1: val_loss improved from inf to 1.48245, saving model to ../checkpoints/sim_101_60_l_he_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4835 - sMAPE_tf: 1.4835 - val_loss: 1.4825 - val_sMAPE_tf: 1.4825\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4688 - sMAPE_tf: 1.4688\n",
      "Epoch 2: val_loss did not improve from 1.48245\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.4688 - sMAPE_tf: 1.4688 - val_loss: 1.4935 - val_sMAPE_tf: 1.4935\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4418 - sMAPE_tf: 1.4418\n",
      "Epoch 3: val_loss did not improve from 1.48245\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.4418 - sMAPE_tf: 1.4418 - val_loss: 1.4946 - val_sMAPE_tf: 1.4946\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4284 - sMAPE_tf: 1.4284\n",
      "Epoch 4: val_loss did not improve from 1.48245\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.4284 - sMAPE_tf: 1.4284 - val_loss: 1.4918 - val_sMAPE_tf: 1.4918\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4306 - sMAPE_tf: 1.4306\n",
      "Epoch 5: val_loss did not improve from 1.48245\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.4306 - sMAPE_tf: 1.4306 - val_loss: 1.4883 - val_sMAPE_tf: 1.4883\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4202 - sMAPE_tf: 1.4202\n",
      "Epoch 6: val_loss did not improve from 1.48245\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.4202 - sMAPE_tf: 1.4202 - val_loss: 1.4859 - val_sMAPE_tf: 1.4859\n",
      "Training finished in 4.561772584915161 secconds\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5110 - sMAPE_tf: 1.5110\n",
      "1.5109823942184448\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "mean_SMAPE:0.7805612718487569\n",
      "mean_MASE:2.7484059192408066\n",
      "sim_101_60_l_ho\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4654 - sMAPE_tf: 1.4654\n",
      "Epoch 1: val_loss improved from inf to 1.46686, saving model to ../checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4654 - sMAPE_tf: 1.4654 - val_loss: 1.4669 - val_sMAPE_tf: 1.4669\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4402 - sMAPE_tf: 1.4402\n",
      "Epoch 2: val_loss did not improve from 1.46686\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.4402 - sMAPE_tf: 1.4402 - val_loss: 1.4832 - val_sMAPE_tf: 1.4832\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4165 - sMAPE_tf: 1.4165\n",
      "Epoch 3: val_loss did not improve from 1.46686\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.4165 - sMAPE_tf: 1.4165 - val_loss: 1.4815 - val_sMAPE_tf: 1.4815\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4054 - sMAPE_tf: 1.4054\n",
      "Epoch 4: val_loss did not improve from 1.46686\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.4054 - sMAPE_tf: 1.4054 - val_loss: 1.4777 - val_sMAPE_tf: 1.4777\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3872 - sMAPE_tf: 1.3872\n",
      "Epoch 5: val_loss did not improve from 1.46686\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.3872 - sMAPE_tf: 1.3872 - val_loss: 1.4736 - val_sMAPE_tf: 1.4736\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3817 - sMAPE_tf: 1.3817\n",
      "Epoch 6: val_loss did not improve from 1.46686\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.3817 - sMAPE_tf: 1.3817 - val_loss: 1.4807 - val_sMAPE_tf: 1.4807\n",
      "Training finished in 4.3999762535095215 secconds\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4372 - sMAPE_tf: 1.4372\n",
      "1.4371925592422485\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "mean_SMAPE:0.5554795265746459\n",
      "mean_MASE:1.8793517456715298\n",
      "sim_101_60_nl_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4695 - sMAPE_tf: 1.4695\n",
      "Epoch 1: val_loss improved from inf to 1.48758, saving model to ../checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4695 - sMAPE_tf: 1.4695 - val_loss: 1.4876 - val_sMAPE_tf: 1.4876\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4512 - sMAPE_tf: 1.4512\n",
      "Epoch 2: val_loss improved from 1.48758 to 1.47019, saving model to ../checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.4512 - sMAPE_tf: 1.4512 - val_loss: 1.4702 - val_sMAPE_tf: 1.4702\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4496 - sMAPE_tf: 1.4496\n",
      "Epoch 3: val_loss improved from 1.47019 to 1.45738, saving model to ../checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.4496 - sMAPE_tf: 1.4496 - val_loss: 1.4574 - val_sMAPE_tf: 1.4574\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4287 - sMAPE_tf: 1.4287\n",
      "Epoch 4: val_loss did not improve from 1.45738\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.4287 - sMAPE_tf: 1.4287 - val_loss: 1.4646 - val_sMAPE_tf: 1.4646\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4215 - sMAPE_tf: 1.4215\n",
      "Epoch 5: val_loss did not improve from 1.45738\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.4215 - sMAPE_tf: 1.4215 - val_loss: 1.4641 - val_sMAPE_tf: 1.4641\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4094 - sMAPE_tf: 1.4094\n",
      "Epoch 6: val_loss improved from 1.45738 to 1.44631, saving model to ../checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.4094 - sMAPE_tf: 1.4094 - val_loss: 1.4463 - val_sMAPE_tf: 1.4463\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4056 - sMAPE_tf: 1.4056\n",
      "Epoch 7: val_loss did not improve from 1.44631\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.4056 - sMAPE_tf: 1.4056 - val_loss: 1.4511 - val_sMAPE_tf: 1.4511\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3972 - sMAPE_tf: 1.3972\n",
      "Epoch 8: val_loss did not improve from 1.44631\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.3972 - sMAPE_tf: 1.3972 - val_loss: 1.4536 - val_sMAPE_tf: 1.4536\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3902 - sMAPE_tf: 1.3902\n",
      "Epoch 9: val_loss did not improve from 1.44631\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.3902 - sMAPE_tf: 1.3902 - val_loss: 1.4609 - val_sMAPE_tf: 1.4609\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3805 - sMAPE_tf: 1.3805\n",
      "Epoch 10: val_loss did not improve from 1.44631\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.3805 - sMAPE_tf: 1.3805 - val_loss: 1.4591 - val_sMAPE_tf: 1.4591\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3704 - sMAPE_tf: 1.3704\n",
      "Epoch 11: val_loss did not improve from 1.44631\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.3704 - sMAPE_tf: 1.3704 - val_loss: 1.4515 - val_sMAPE_tf: 1.4515\n",
      "Training finished in 5.713821172714233 secconds\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.4921 - sMAPE_tf: 1.4921\n",
      "1.4921009540557861\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "mean_SMAPE:0.9085553952706615\n",
      "mean_MASE:2.0762436891252363\n",
      "sim_101_60_nl_ho\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4791 - sMAPE_tf: 1.4791\n",
      "Epoch 1: val_loss improved from inf to 1.48588, saving model to ../checkpoints/sim_101_60_nl_ho_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4791 - sMAPE_tf: 1.4791 - val_loss: 1.4859 - val_sMAPE_tf: 1.4859\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4553 - sMAPE_tf: 1.4553\n",
      "Epoch 2: val_loss did not improve from 1.48588\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.4553 - sMAPE_tf: 1.4553 - val_loss: 1.4976 - val_sMAPE_tf: 1.4976\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4447 - sMAPE_tf: 1.4447\n",
      "Epoch 3: val_loss did not improve from 1.48588\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.4447 - sMAPE_tf: 1.4447 - val_loss: 1.5099 - val_sMAPE_tf: 1.5099\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4310 - sMAPE_tf: 1.4310\n",
      "Epoch 4: val_loss did not improve from 1.48588\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.4310 - sMAPE_tf: 1.4310 - val_loss: 1.5229 - val_sMAPE_tf: 1.5229\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4142 - sMAPE_tf: 1.4142\n",
      "Epoch 5: val_loss did not improve from 1.48588\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.4142 - sMAPE_tf: 1.4142 - val_loss: 1.5240 - val_sMAPE_tf: 1.5240\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4157 - sMAPE_tf: 1.4157\n",
      "Epoch 6: val_loss did not improve from 1.48588\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.4157 - sMAPE_tf: 1.4157 - val_loss: 1.5178 - val_sMAPE_tf: 1.5178\n",
      "Training finished in 4.529765844345093 secconds\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.5233 - sMAPE_tf: 1.5233\n",
      "1.5233455896377563\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mean_SMAPE:1.0816958509768377\n",
      "mean_MASE:2.5555583681783016\n",
      "sim_101_222_l_he\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4630 - sMAPE_tf: 1.4630\n",
      "Epoch 1: val_loss improved from inf to 1.38101, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 4s 149ms/step - loss: 1.4593 - sMAPE_tf: 1.4568 - val_loss: 1.3810 - val_sMAPE_tf: 1.3810\n",
      "Epoch 2/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3812 - sMAPE_tf: 1.3812\n",
      "Epoch 2: val_loss improved from 1.38101 to 1.27842, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 1.3668 - sMAPE_tf: 1.3616 - val_loss: 1.2784 - val_sMAPE_tf: 1.2784\n",
      "Epoch 3/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.2555 - sMAPE_tf: 1.2555\n",
      "Epoch 3: val_loss improved from 1.27842 to 1.21812, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.2396 - sMAPE_tf: 1.2357 - val_loss: 1.2181 - val_sMAPE_tf: 1.2181\n",
      "Epoch 4/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1434 - sMAPE_tf: 1.1434\n",
      "Epoch 4: val_loss improved from 1.21812 to 1.02252, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 1.1299 - sMAPE_tf: 1.1280 - val_loss: 1.0225 - val_sMAPE_tf: 1.0225\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0463 - sMAPE_tf: 1.0455\n",
      "Epoch 5: val_loss improved from 1.02252 to 0.94164, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 1.0463 - sMAPE_tf: 1.0455 - val_loss: 0.9416 - val_sMAPE_tf: 0.9416\n",
      "Epoch 6/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9722 - sMAPE_tf: 0.9722\n",
      "Epoch 6: val_loss improved from 0.94164 to 0.87420, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 0.9674 - sMAPE_tf: 0.9665 - val_loss: 0.8742 - val_sMAPE_tf: 0.8742\n",
      "Epoch 7/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9111 - sMAPE_tf: 0.9111\n",
      "Epoch 7: val_loss did not improve from 0.87420\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.9029 - sMAPE_tf: 0.9033 - val_loss: 0.8762 - val_sMAPE_tf: 0.8762\n",
      "Epoch 8/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8537 - sMAPE_tf: 0.8537\n",
      "Epoch 8: val_loss improved from 0.87420 to 0.83418, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.8470 - sMAPE_tf: 0.8453 - val_loss: 0.8342 - val_sMAPE_tf: 0.8342\n",
      "Epoch 9/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8202 - sMAPE_tf: 0.8202\n",
      "Epoch 9: val_loss improved from 0.83418 to 0.82513, saving model to ../checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.8090 - sMAPE_tf: 0.8054 - val_loss: 0.8251 - val_sMAPE_tf: 0.8251\n",
      "Epoch 10/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.7751 - sMAPE_tf: 0.7751\n",
      "Epoch 10: val_loss did not improve from 0.82513\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.7702 - sMAPE_tf: 0.7688 - val_loss: 0.8274 - val_sMAPE_tf: 0.8274\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7329 - sMAPE_tf: 0.7320\n",
      "Epoch 11: val_loss did not improve from 0.82513\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.7329 - sMAPE_tf: 0.7320 - val_loss: 0.8333 - val_sMAPE_tf: 0.8333\n",
      "Epoch 12/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.6990 - sMAPE_tf: 0.6990\n",
      "Epoch 12: val_loss did not improve from 0.82513\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.6966 - sMAPE_tf: 0.6976 - val_loss: 0.8476 - val_sMAPE_tf: 0.8476\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6694 - sMAPE_tf: 0.6727\n",
      "Epoch 13: val_loss did not improve from 0.82513\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.6694 - sMAPE_tf: 0.6727 - val_loss: 0.8354 - val_sMAPE_tf: 0.8354\n",
      "Epoch 14/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.6469 - sMAPE_tf: 0.6469\n",
      "Epoch 14: val_loss did not improve from 0.82513\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.6484 - sMAPE_tf: 0.6482 - val_loss: 0.8577 - val_sMAPE_tf: 0.8577\n",
      "Training finished in 8.39517593383789 secconds\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.0132 - sMAPE_tf: 1.0132\n",
      "1.0131572484970093\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "mean_SMAPE:0.265000986176095\n",
      "mean_MASE:1.0804394601908898\n",
      "sim_101_222_l_ho\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4763 - sMAPE_tf: 1.4736\n",
      "Epoch 1: val_loss improved from inf to 1.46277, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 4s 144ms/step - loss: 1.4763 - sMAPE_tf: 1.4736 - val_loss: 1.4628 - val_sMAPE_tf: 1.4628\n",
      "Epoch 2/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.4275 - sMAPE_tf: 1.4275\n",
      "Epoch 2: val_loss improved from 1.46277 to 1.43062, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 1.4202 - sMAPE_tf: 1.4188 - val_loss: 1.4306 - val_sMAPE_tf: 1.4306\n",
      "Epoch 3/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3527 - sMAPE_tf: 1.3527\n",
      "Epoch 3: val_loss improved from 1.43062 to 1.29712, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 1.3413 - sMAPE_tf: 1.3368 - val_loss: 1.2971 - val_sMAPE_tf: 1.2971\n",
      "Epoch 4/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.2423 - sMAPE_tf: 1.2423\n",
      "Epoch 4: val_loss improved from 1.29712 to 1.21046, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 1.2310 - sMAPE_tf: 1.2288 - val_loss: 1.2105 - val_sMAPE_tf: 1.2105\n",
      "Epoch 5/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1504 - sMAPE_tf: 1.1504\n",
      "Epoch 5: val_loss improved from 1.21046 to 1.11446, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.1454 - sMAPE_tf: 1.1421 - val_loss: 1.1145 - val_sMAPE_tf: 1.1145\n",
      "Epoch 6/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0843 - sMAPE_tf: 1.0843\n",
      "Epoch 6: val_loss improved from 1.11446 to 1.02306, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 1.0752 - sMAPE_tf: 1.0753 - val_loss: 1.0231 - val_sMAPE_tf: 1.0231\n",
      "Epoch 7/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0260 - sMAPE_tf: 1.0260\n",
      "Epoch 7: val_loss improved from 1.02306 to 0.98454, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 1.0192 - sMAPE_tf: 1.0177 - val_loss: 0.9845 - val_sMAPE_tf: 0.9845\n",
      "Epoch 8/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9672 - sMAPE_tf: 0.9672\n",
      "Epoch 8: val_loss improved from 0.98454 to 0.94018, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.9671 - sMAPE_tf: 0.9691 - val_loss: 0.9402 - val_sMAPE_tf: 0.9402\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9247 - sMAPE_tf: 0.9241\n",
      "Epoch 9: val_loss improved from 0.94018 to 0.92864, saving model to ../checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.9247 - sMAPE_tf: 0.9241 - val_loss: 0.9286 - val_sMAPE_tf: 0.9286\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8889 - sMAPE_tf: 0.8873\n",
      "Epoch 10: val_loss did not improve from 0.92864\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.8889 - sMAPE_tf: 0.8873 - val_loss: 0.9435 - val_sMAPE_tf: 0.9435\n",
      "Epoch 11/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8564 - sMAPE_tf: 0.8564\n",
      "Epoch 11: val_loss did not improve from 0.92864\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.8505 - sMAPE_tf: 0.8494 - val_loss: 0.9361 - val_sMAPE_tf: 0.9361\n",
      "Epoch 12/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8095 - sMAPE_tf: 0.8095\n",
      "Epoch 12: val_loss did not improve from 0.92864\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.8132 - sMAPE_tf: 0.8150 - val_loss: 0.9598 - val_sMAPE_tf: 0.9598\n",
      "Epoch 13/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.7925 - sMAPE_tf: 0.7925\n",
      "Epoch 13: val_loss did not improve from 0.92864\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.7906 - sMAPE_tf: 0.7891 - val_loss: 0.9540 - val_sMAPE_tf: 0.9540\n",
      "Epoch 14/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.7699 - sMAPE_tf: 0.7699\n",
      "Epoch 14: val_loss did not improve from 0.92864\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.7746 - sMAPE_tf: 0.7791 - val_loss: 0.9304 - val_sMAPE_tf: 0.9304\n",
      "Training finished in 8.8233060836792 secconds\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.0727 - sMAPE_tf: 1.0727\n",
      "1.072745680809021\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "mean_SMAPE:0.2581009545581074\n",
      "mean_MASE:1.0535034250718285\n",
      "sim_101_222_nl_he\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4387 - sMAPE_tf: 1.4374\n",
      "Epoch 1: val_loss improved from inf to 1.39688, saving model to ../checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 4s 145ms/step - loss: 1.4387 - sMAPE_tf: 1.4374 - val_loss: 1.3969 - val_sMAPE_tf: 1.3969\n",
      "Epoch 2/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3960 - sMAPE_tf: 1.3960\n",
      "Epoch 2: val_loss improved from 1.39688 to 1.35781, saving model to ../checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.3894 - sMAPE_tf: 1.3878 - val_loss: 1.3578 - val_sMAPE_tf: 1.3578\n",
      "Epoch 3/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3438 - sMAPE_tf: 1.3438\n",
      "Epoch 3: val_loss improved from 1.35781 to 1.33050, saving model to ../checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.3382 - sMAPE_tf: 1.3373 - val_loss: 1.3305 - val_sMAPE_tf: 1.3305\n",
      "Epoch 4/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.2875 - sMAPE_tf: 1.2875\n",
      "Epoch 4: val_loss improved from 1.33050 to 1.31914, saving model to ../checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 1.2803 - sMAPE_tf: 1.2793 - val_loss: 1.3191 - val_sMAPE_tf: 1.3191\n",
      "Epoch 5/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.2260 - sMAPE_tf: 1.2260\n",
      "Epoch 5: val_loss improved from 1.31914 to 1.31297, saving model to ../checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.2162 - sMAPE_tf: 1.2145 - val_loss: 1.3130 - val_sMAPE_tf: 1.3130\n",
      "Epoch 6/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1714 - sMAPE_tf: 1.1714\n",
      "Epoch 6: val_loss improved from 1.31297 to 1.30504, saving model to ../checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.1631 - sMAPE_tf: 1.1609 - val_loss: 1.3050 - val_sMAPE_tf: 1.3050\n",
      "Epoch 7/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1097 - sMAPE_tf: 1.1097\n",
      "Epoch 7: val_loss did not improve from 1.30504\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.1056 - sMAPE_tf: 1.1040 - val_loss: 1.3122 - val_sMAPE_tf: 1.3122\n",
      "Epoch 8/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0605 - sMAPE_tf: 1.0605\n",
      "Epoch 8: val_loss did not improve from 1.30504\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0560 - sMAPE_tf: 1.0558 - val_loss: 1.3170 - val_sMAPE_tf: 1.3170\n",
      "Epoch 9/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0166 - sMAPE_tf: 1.0166\n",
      "Epoch 9: val_loss did not improve from 1.30504\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0105 - sMAPE_tf: 1.0093 - val_loss: 1.3071 - val_sMAPE_tf: 1.3071\n",
      "Epoch 10/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9697 - sMAPE_tf: 0.9697\n",
      "Epoch 10: val_loss did not improve from 1.30504\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.9681 - sMAPE_tf: 0.9684 - val_loss: 1.3252 - val_sMAPE_tf: 1.3252\n",
      "Epoch 11/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9292 - sMAPE_tf: 0.9292\n",
      "Epoch 11: val_loss did not improve from 1.30504\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.9240 - sMAPE_tf: 0.9230 - val_loss: 1.3647 - val_sMAPE_tf: 1.3647\n",
      "Training finished in 7.259885549545288 secconds\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3311 - sMAPE_tf: 1.3311\n",
      "1.3311457633972168\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "mean_SMAPE:0.5498854603181744\n",
      "mean_MASE:1.0207070072426254\n",
      "sim_101_222_nl_ho\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4449 - sMAPE_tf: 1.4422\n",
      "Epoch 1: val_loss improved from inf to 1.44230, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 4s 144ms/step - loss: 1.4449 - sMAPE_tf: 1.4422 - val_loss: 1.4423 - val_sMAPE_tf: 1.4423\n",
      "Epoch 2/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3982 - sMAPE_tf: 1.3982\n",
      "Epoch 2: val_loss improved from 1.44230 to 1.39922, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 1.3916 - sMAPE_tf: 1.3901 - val_loss: 1.3992 - val_sMAPE_tf: 1.3992\n",
      "Epoch 3/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3401 - sMAPE_tf: 1.3401\n",
      "Epoch 3: val_loss improved from 1.39922 to 1.38539, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 1.3345 - sMAPE_tf: 1.3330 - val_loss: 1.3854 - val_sMAPE_tf: 1.3854\n",
      "Epoch 4/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.2867 - sMAPE_tf: 1.2867\n",
      "Epoch 4: val_loss improved from 1.38539 to 1.37489, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.2794 - sMAPE_tf: 1.2766 - val_loss: 1.3749 - val_sMAPE_tf: 1.3749\n",
      "Epoch 5/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.2088 - sMAPE_tf: 1.2088\n",
      "Epoch 5: val_loss did not improve from 1.37489\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.2010 - sMAPE_tf: 1.1995 - val_loss: 1.3887 - val_sMAPE_tf: 1.3887\n",
      "Epoch 6/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1486 - sMAPE_tf: 1.1486\n",
      "Epoch 6: val_loss improved from 1.37489 to 1.37464, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 1.1403 - sMAPE_tf: 1.1394 - val_loss: 1.3746 - val_sMAPE_tf: 1.3746\n",
      "Epoch 7/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0815 - sMAPE_tf: 1.0815\n",
      "Epoch 7: val_loss improved from 1.37464 to 1.32946, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.0765 - sMAPE_tf: 1.0751 - val_loss: 1.3295 - val_sMAPE_tf: 1.3295\n",
      "Epoch 8/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0270 - sMAPE_tf: 1.0270\n",
      "Epoch 8: val_loss improved from 1.32946 to 1.32382, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 1.0206 - sMAPE_tf: 1.0202 - val_loss: 1.3238 - val_sMAPE_tf: 1.3238\n",
      "Epoch 9/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9886 - sMAPE_tf: 0.9886\n",
      "Epoch 9: val_loss improved from 1.32382 to 1.32042, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.9830 - sMAPE_tf: 0.9825 - val_loss: 1.3204 - val_sMAPE_tf: 1.3204\n",
      "Epoch 10/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9348 - sMAPE_tf: 0.9348\n",
      "Epoch 10: val_loss did not improve from 1.32042\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.9294 - sMAPE_tf: 0.9281 - val_loss: 1.3456 - val_sMAPE_tf: 1.3456\n",
      "Epoch 11/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8994 - sMAPE_tf: 0.8994\n",
      "Epoch 11: val_loss did not improve from 1.32042\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.9001 - sMAPE_tf: 0.9022 - val_loss: 1.3747 - val_sMAPE_tf: 1.3747\n",
      "Epoch 12/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8715 - sMAPE_tf: 0.8715\n",
      "Epoch 12: val_loss did not improve from 1.32042\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.8705 - sMAPE_tf: 0.8713 - val_loss: 1.3441 - val_sMAPE_tf: 1.3441\n",
      "Epoch 13/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8300 - sMAPE_tf: 0.8300\n",
      "Epoch 13: val_loss did not improve from 1.32042\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.8268 - sMAPE_tf: 0.8279 - val_loss: 1.3217 - val_sMAPE_tf: 1.3217\n",
      "Epoch 14/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8003 - sMAPE_tf: 0.8003\n",
      "Epoch 14: val_loss improved from 1.32042 to 1.31791, saving model to ../checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 63ms/step - loss: 0.7958 - sMAPE_tf: 0.7956 - val_loss: 1.3179 - val_sMAPE_tf: 1.3179\n",
      "Epoch 15/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.7638 - sMAPE_tf: 0.7638\n",
      "Epoch 15: val_loss did not improve from 1.31791\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.7608 - sMAPE_tf: 0.7607 - val_loss: 1.3454 - val_sMAPE_tf: 1.3454\n",
      "Epoch 16/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.7317 - sMAPE_tf: 0.7317\n",
      "Epoch 16: val_loss did not improve from 1.31791\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.7284 - sMAPE_tf: 0.7282 - val_loss: 1.3415 - val_sMAPE_tf: 1.3415\n",
      "Epoch 17/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.7051 - sMAPE_tf: 0.7051\n",
      "Epoch 17: val_loss did not improve from 1.31791\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.7013 - sMAPE_tf: 0.7014 - val_loss: 1.3551 - val_sMAPE_tf: 1.3551\n",
      "Epoch 18/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.6945 - sMAPE_tf: 0.6945\n",
      "Epoch 18: val_loss did not improve from 1.31791\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.6876 - sMAPE_tf: 0.6873 - val_loss: 1.3740 - val_sMAPE_tf: 1.3740\n",
      "Epoch 19/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.6774 - sMAPE_tf: 0.6774\n",
      "Epoch 19: val_loss did not improve from 1.31791\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.6705 - sMAPE_tf: 0.6694 - val_loss: 1.3724 - val_sMAPE_tf: 1.3724\n",
      "Training finished in 9.828424453735352 secconds\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.3481 - sMAPE_tf: 1.3481\n",
      "1.34809410572052\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "mean_SMAPE:0.4730651714515646\n",
      "mean_MASE:0.8346718172131798\n",
      "sim_500_60_l_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4457 - sMAPE_tf: 1.4457\n",
      "Epoch 1: val_loss improved from inf to 1.48097, saving model to ../checkpoints/sim_500_60_l_he_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4457 - sMAPE_tf: 1.4457 - val_loss: 1.4810 - val_sMAPE_tf: 1.4810\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4499 - sMAPE_tf: 1.4499\n",
      "Epoch 2: val_loss did not improve from 1.48097\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.4499 - sMAPE_tf: 1.4499 - val_loss: 1.5281 - val_sMAPE_tf: 1.5281\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4837 - sMAPE_tf: 1.4837\n",
      "Epoch 3: val_loss did not improve from 1.48097\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.4837 - sMAPE_tf: 1.4837 - val_loss: 1.5727 - val_sMAPE_tf: 1.5727\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5020 - sMAPE_tf: 1.5020\n",
      "Epoch 4: val_loss did not improve from 1.48097\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.5020 - sMAPE_tf: 1.5020 - val_loss: 1.6181 - val_sMAPE_tf: 1.6181\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5191 - sMAPE_tf: 1.5191\n",
      "Epoch 5: val_loss did not improve from 1.48097\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.5191 - sMAPE_tf: 1.5191 - val_loss: 1.6330 - val_sMAPE_tf: 1.6330\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5282 - sMAPE_tf: 1.5282\n",
      "Epoch 6: val_loss did not improve from 1.48097\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.5282 - sMAPE_tf: 1.5282 - val_loss: 1.6330 - val_sMAPE_tf: 1.6330\n",
      "Training finished in 4.8454413414001465 secconds\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.4794 - sMAPE_tf: 1.4794\n",
      "1.4793779850006104\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "mean_SMAPE:0.7788049850616043\n",
      "mean_MASE:2.7807291560885408\n",
      "sim_500_60_l_ho\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4617 - sMAPE_tf: 1.4617\n",
      "Epoch 1: val_loss improved from inf to 1.50901, saving model to ../checkpoints/sim_500_60_l_ho_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4617 - sMAPE_tf: 1.4617 - val_loss: 1.5090 - val_sMAPE_tf: 1.5090\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4777 - sMAPE_tf: 1.4777\n",
      "Epoch 2: val_loss did not improve from 1.50901\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.4777 - sMAPE_tf: 1.4777 - val_loss: 1.5717 - val_sMAPE_tf: 1.5717\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5216 - sMAPE_tf: 1.5216\n",
      "Epoch 3: val_loss did not improve from 1.50901\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.5216 - sMAPE_tf: 1.5216 - val_loss: 1.5800 - val_sMAPE_tf: 1.5800\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5550 - sMAPE_tf: 1.5550\n",
      "Epoch 4: val_loss did not improve from 1.50901\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.5550 - sMAPE_tf: 1.5550 - val_loss: 1.6008 - val_sMAPE_tf: 1.6008\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5738 - sMAPE_tf: 1.5738\n",
      "Epoch 5: val_loss did not improve from 1.50901\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.5738 - sMAPE_tf: 1.5738 - val_loss: 1.6032 - val_sMAPE_tf: 1.6032\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5893 - sMAPE_tf: 1.5893\n",
      "Epoch 6: val_loss did not improve from 1.50901\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.5893 - sMAPE_tf: 1.5893 - val_loss: 1.5996 - val_sMAPE_tf: 1.5996\n",
      "Training finished in 4.832690715789795 secconds\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.5074 - sMAPE_tf: 1.5074\n",
      "1.5073801279067993\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "mean_SMAPE:0.8206884737838919\n",
      "mean_MASE:2.9686226808679748\n",
      "sim_500_60_nl_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4775 - sMAPE_tf: 1.4775\n",
      "Epoch 1: val_loss improved from inf to 1.52674, saving model to ../checkpoints/sim_500_60_nl_he_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4775 - sMAPE_tf: 1.4775 - val_loss: 1.5267 - val_sMAPE_tf: 1.5267\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5110 - sMAPE_tf: 1.5110\n",
      "Epoch 2: val_loss did not improve from 1.52674\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.5110 - sMAPE_tf: 1.5110 - val_loss: 1.5558 - val_sMAPE_tf: 1.5558\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5519 - sMAPE_tf: 1.5519\n",
      "Epoch 3: val_loss did not improve from 1.52674\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.5519 - sMAPE_tf: 1.5519 - val_loss: 1.5922 - val_sMAPE_tf: 1.5922\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5824 - sMAPE_tf: 1.5824\n",
      "Epoch 4: val_loss did not improve from 1.52674\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.5824 - sMAPE_tf: 1.5824 - val_loss: 1.6322 - val_sMAPE_tf: 1.6322\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6075 - sMAPE_tf: 1.6075\n",
      "Epoch 5: val_loss did not improve from 1.52674\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.6075 - sMAPE_tf: 1.6075 - val_loss: 1.6566 - val_sMAPE_tf: 1.6566\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6293 - sMAPE_tf: 1.6293\n",
      "Epoch 6: val_loss did not improve from 1.52674\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.6293 - sMAPE_tf: 1.6293 - val_loss: 1.6666 - val_sMAPE_tf: 1.6666\n",
      "Training finished in 4.826067686080933 secconds\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.5525 - sMAPE_tf: 1.5525\n",
      "1.5525258779525757\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "mean_SMAPE:1.0963305971425825\n",
      "mean_MASE:3.2088526427067094\n",
      "sim_500_60_nl_ho\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4450 - sMAPE_tf: 1.4450\n",
      "Epoch 1: val_loss improved from inf to 1.51649, saving model to ../checkpoints/sim_500_60_nl_ho_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4450 - sMAPE_tf: 1.4450 - val_loss: 1.5165 - val_sMAPE_tf: 1.5165\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4911 - sMAPE_tf: 1.4911\n",
      "Epoch 2: val_loss did not improve from 1.51649\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.4911 - sMAPE_tf: 1.4911 - val_loss: 1.5907 - val_sMAPE_tf: 1.5907\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5254 - sMAPE_tf: 1.5254\n",
      "Epoch 3: val_loss did not improve from 1.51649\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.5254 - sMAPE_tf: 1.5254 - val_loss: 1.6278 - val_sMAPE_tf: 1.6278\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5556 - sMAPE_tf: 1.5556\n",
      "Epoch 4: val_loss did not improve from 1.51649\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.5556 - sMAPE_tf: 1.5556 - val_loss: 1.6534 - val_sMAPE_tf: 1.6534\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5703 - sMAPE_tf: 1.5703\n",
      "Epoch 5: val_loss did not improve from 1.51649\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.5703 - sMAPE_tf: 1.5703 - val_loss: 1.6690 - val_sMAPE_tf: 1.6690\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5835 - sMAPE_tf: 1.5835\n",
      "Epoch 6: val_loss did not improve from 1.51649\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.5835 - sMAPE_tf: 1.5835 - val_loss: 1.6653 - val_sMAPE_tf: 1.6653\n",
      "Training finished in 5.752298593521118 secconds\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.5386 - sMAPE_tf: 1.5386\n",
      "1.5385990142822266\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "mean_SMAPE:1.1428619046718134\n",
      "mean_MASE:3.2738379929385983\n",
      "sim_500_222_l_he\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4904 - sMAPE_tf: 1.4914\n",
      "Epoch 1: val_loss improved from inf to 1.65805, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 4s 191ms/step - loss: 1.4904 - sMAPE_tf: 1.4914 - val_loss: 1.6581 - val_sMAPE_tf: 1.6581\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.5018 - sMAPE_tf: 1.5018\n",
      "Epoch 2: val_loss improved from 1.65805 to 1.64980, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 1.5021 - sMAPE_tf: 1.5022 - val_loss: 1.6498 - val_sMAPE_tf: 1.6498\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4834 - sMAPE_tf: 1.4834\n",
      "Epoch 3: val_loss did not improve from 1.64980\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 1.4816 - sMAPE_tf: 1.4803 - val_loss: 1.6610 - val_sMAPE_tf: 1.6610\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4618 - sMAPE_tf: 1.4605\n",
      "Epoch 4: val_loss improved from 1.64980 to 1.55097, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 1.4618 - sMAPE_tf: 1.4605 - val_loss: 1.5510 - val_sMAPE_tf: 1.5510\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4222 - sMAPE_tf: 1.4211\n",
      "Epoch 5: val_loss improved from 1.55097 to 1.47744, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 1.4222 - sMAPE_tf: 1.4211 - val_loss: 1.4774 - val_sMAPE_tf: 1.4774\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3820 - sMAPE_tf: 1.3820\n",
      "Epoch 6: val_loss improved from 1.47744 to 1.43109, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 1.3810 - sMAPE_tf: 1.3802 - val_loss: 1.4311 - val_sMAPE_tf: 1.4311\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3377 - sMAPE_tf: 1.3377\n",
      "Epoch 7: val_loss improved from 1.43109 to 1.34756, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 1.3345 - sMAPE_tf: 1.3323 - val_loss: 1.3476 - val_sMAPE_tf: 1.3476\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2893 - sMAPE_tf: 1.2893\n",
      "Epoch 8: val_loss improved from 1.34756 to 1.17379, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 117ms/step - loss: 1.2862 - sMAPE_tf: 1.2840 - val_loss: 1.1738 - val_sMAPE_tf: 1.1738\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2205 - sMAPE_tf: 1.2189\n",
      "Epoch 9: val_loss improved from 1.17379 to 1.09050, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 1.2205 - sMAPE_tf: 1.2189 - val_loss: 1.0905 - val_sMAPE_tf: 1.0905\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1681 - sMAPE_tf: 1.1681\n",
      "Epoch 10: val_loss improved from 1.09050 to 1.05950, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 1.1672 - sMAPE_tf: 1.1666 - val_loss: 1.0595 - val_sMAPE_tf: 1.0595\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1187 - sMAPE_tf: 1.1187\n",
      "Epoch 11: val_loss improved from 1.05950 to 1.02049, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 1.1192 - sMAPE_tf: 1.1195 - val_loss: 1.0205 - val_sMAPE_tf: 1.0205\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0670 - sMAPE_tf: 1.0670\n",
      "Epoch 12: val_loss improved from 1.02049 to 1.01902, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 1.0655 - sMAPE_tf: 1.0644 - val_loss: 1.0190 - val_sMAPE_tf: 1.0190\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0097 - sMAPE_tf: 1.0071\n",
      "Epoch 13: val_loss did not improve from 1.01902\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 1.0097 - sMAPE_tf: 1.0071 - val_loss: 1.0195 - val_sMAPE_tf: 1.0195\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9422 - sMAPE_tf: 0.9422\n",
      "Epoch 14: val_loss did not improve from 1.01902\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.9425 - sMAPE_tf: 0.9427 - val_loss: 1.0545 - val_sMAPE_tf: 1.0545\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8810 - sMAPE_tf: 0.8775\n",
      "Epoch 15: val_loss did not improve from 1.01902\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.8810 - sMAPE_tf: 0.8775 - val_loss: 1.0315 - val_sMAPE_tf: 1.0315\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8114 - sMAPE_tf: 0.8114\n",
      "Epoch 16: val_loss did not improve from 1.01902\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.8144 - sMAPE_tf: 0.8165 - val_loss: 1.1166 - val_sMAPE_tf: 1.1166\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7624 - sMAPE_tf: 0.7624\n",
      "Epoch 17: val_loss improved from 1.01902 to 0.99011, saving model to ../checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 0.7612 - sMAPE_tf: 0.7604 - val_loss: 0.9901 - val_sMAPE_tf: 0.9901\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7066 - sMAPE_tf: 0.7066\n",
      "Epoch 18: val_loss did not improve from 0.99011\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.7041 - sMAPE_tf: 0.7023 - val_loss: 1.1007 - val_sMAPE_tf: 1.1007\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6764 - sMAPE_tf: 0.6764\n",
      "Epoch 19: val_loss did not improve from 0.99011\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.6793 - sMAPE_tf: 0.6812 - val_loss: 1.0765 - val_sMAPE_tf: 1.0765\n",
      "Epoch 20/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6482 - sMAPE_tf: 0.6482\n",
      "Epoch 20: val_loss did not improve from 0.99011\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.6462 - sMAPE_tf: 0.6448 - val_loss: 1.0970 - val_sMAPE_tf: 1.0970\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6125 - sMAPE_tf: 0.6119\n",
      "Epoch 21: val_loss did not improve from 0.99011\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.6125 - sMAPE_tf: 0.6119 - val_loss: 1.0943 - val_sMAPE_tf: 1.0943\n",
      "Epoch 22/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5956 - sMAPE_tf: 0.5956\n",
      "Epoch 22: val_loss did not improve from 0.99011\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.5987 - sMAPE_tf: 0.6008 - val_loss: 1.0675 - val_sMAPE_tf: 1.0675\n",
      "Training finished in 16.053797721862793 secconds\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.0697 - sMAPE_tf: 1.0697\n",
      "1.0697261095046997\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "mean_SMAPE:0.27928656837225707\n",
      "mean_MASE:1.0877729739022655\n",
      "sim_500_222_l_ho\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.5153 - sMAPE_tf: 1.5153\n",
      "Epoch 1: val_loss improved from inf to 1.67012, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 4s 184ms/step - loss: 1.5169 - sMAPE_tf: 1.5179 - val_loss: 1.6701 - val_sMAPE_tf: 1.6701\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4924 - sMAPE_tf: 1.4924\n",
      "Epoch 2: val_loss improved from 1.67012 to 1.64685, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 1.4933 - sMAPE_tf: 1.4940 - val_loss: 1.6469 - val_sMAPE_tf: 1.6469\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4742 - sMAPE_tf: 1.4742\n",
      "Epoch 3: val_loss improved from 1.64685 to 1.48136, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 1.4719 - sMAPE_tf: 1.4704 - val_loss: 1.4814 - val_sMAPE_tf: 1.4814\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4182 - sMAPE_tf: 1.4194\n",
      "Epoch 4: val_loss improved from 1.48136 to 1.40976, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 1.4182 - sMAPE_tf: 1.4194 - val_loss: 1.4098 - val_sMAPE_tf: 1.4098\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3547 - sMAPE_tf: 1.3547\n",
      "Epoch 5: val_loss improved from 1.40976 to 1.28110, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 1.3486 - sMAPE_tf: 1.3444 - val_loss: 1.2811 - val_sMAPE_tf: 1.2811\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2803 - sMAPE_tf: 1.2803\n",
      "Epoch 6: val_loss improved from 1.28110 to 1.13005, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 1.2736 - sMAPE_tf: 1.2690 - val_loss: 1.1300 - val_sMAPE_tf: 1.1300\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2161 - sMAPE_tf: 1.2161\n",
      "Epoch 7: val_loss improved from 1.13005 to 1.09059, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 1.2180 - sMAPE_tf: 1.2193 - val_loss: 1.0906 - val_sMAPE_tf: 1.0906\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1691 - sMAPE_tf: 1.1691\n",
      "Epoch 8: val_loss improved from 1.09059 to 1.03828, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 1.1644 - sMAPE_tf: 1.1612 - val_loss: 1.0383 - val_sMAPE_tf: 1.0383\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1285 - sMAPE_tf: 1.1285\n",
      "Epoch 9: val_loss did not improve from 1.03828\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 1.1251 - sMAPE_tf: 1.1227 - val_loss: 1.1013 - val_sMAPE_tf: 1.1013\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1078 - sMAPE_tf: 1.1119\n",
      "Epoch 10: val_loss improved from 1.03828 to 1.01899, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 1.1078 - sMAPE_tf: 1.1119 - val_loss: 1.0190 - val_sMAPE_tf: 1.0190\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0636 - sMAPE_tf: 1.0636\n",
      "Epoch 11: val_loss did not improve from 1.01899\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 1.0700 - sMAPE_tf: 1.0743 - val_loss: 1.0218 - val_sMAPE_tf: 1.0218\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0332 - sMAPE_tf: 1.0332\n",
      "Epoch 12: val_loss improved from 1.01899 to 0.99301, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 1.0270 - sMAPE_tf: 1.0228 - val_loss: 0.9930 - val_sMAPE_tf: 0.9930\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9891 - sMAPE_tf: 0.9891\n",
      "Epoch 13: val_loss improved from 0.99301 to 0.97700, saving model to ../checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 0.9900 - sMAPE_tf: 0.9906 - val_loss: 0.9770 - val_sMAPE_tf: 0.9770\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9428 - sMAPE_tf: 0.9428\n",
      "Epoch 14: val_loss did not improve from 0.97700\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.9523 - sMAPE_tf: 0.9588 - val_loss: 1.0045 - val_sMAPE_tf: 1.0045\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9268 - sMAPE_tf: 0.9268\n",
      "Epoch 15: val_loss did not improve from 0.97700\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.9361 - sMAPE_tf: 0.9426 - val_loss: 1.0044 - val_sMAPE_tf: 1.0044\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9159 - sMAPE_tf: 0.9159\n",
      "Epoch 16: val_loss did not improve from 0.97700\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.9314 - sMAPE_tf: 0.9421 - val_loss: 1.0284 - val_sMAPE_tf: 1.0284\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8847 - sMAPE_tf: 0.8847\n",
      "Epoch 17: val_loss did not improve from 0.97700\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.8829 - sMAPE_tf: 0.8817 - val_loss: 1.0095 - val_sMAPE_tf: 1.0095\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8389 - sMAPE_tf: 0.8389\n",
      "Epoch 18: val_loss did not improve from 0.97700\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.8362 - sMAPE_tf: 0.8343 - val_loss: 1.0035 - val_sMAPE_tf: 1.0035\n",
      "Training finished in 13.477753162384033 secconds\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9877 - sMAPE_tf: 0.9877\n",
      "0.9877340793609619\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "mean_SMAPE:0.2898841047013128\n",
      "mean_MASE:1.1347781980187546\n",
      "sim_500_222_nl_he\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4985 - sMAPE_tf: 1.4985\n",
      "Epoch 1: val_loss improved from inf to 1.55351, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 4s 194ms/step - loss: 1.4992 - sMAPE_tf: 1.4996 - val_loss: 1.5535 - val_sMAPE_tf: 1.5535\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.5191 - sMAPE_tf: 1.5191\n",
      "Epoch 2: val_loss improved from 1.55351 to 1.51658, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 1.5167 - sMAPE_tf: 1.5151 - val_loss: 1.5166 - val_sMAPE_tf: 1.5166\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4731 - sMAPE_tf: 1.4731\n",
      "Epoch 3: val_loss did not improve from 1.51658\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 1.4735 - sMAPE_tf: 1.4738 - val_loss: 1.5317 - val_sMAPE_tf: 1.5317\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4594 - sMAPE_tf: 1.4594\n",
      "Epoch 4: val_loss improved from 1.51658 to 1.49094, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 1.4572 - sMAPE_tf: 1.4556 - val_loss: 1.4909 - val_sMAPE_tf: 1.4909\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4356 - sMAPE_tf: 1.4356\n",
      "Epoch 5: val_loss did not improve from 1.49094\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 1.4367 - sMAPE_tf: 1.4375 - val_loss: 1.4959 - val_sMAPE_tf: 1.4959\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4098 - sMAPE_tf: 1.4098\n",
      "Epoch 6: val_loss did not improve from 1.49094\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 1.4092 - sMAPE_tf: 1.4087 - val_loss: 1.5310 - val_sMAPE_tf: 1.5310\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3793 - sMAPE_tf: 1.3793\n",
      "Epoch 7: val_loss improved from 1.49094 to 1.48913, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 111ms/step - loss: 1.3755 - sMAPE_tf: 1.3729 - val_loss: 1.4891 - val_sMAPE_tf: 1.4891\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3353 - sMAPE_tf: 1.3353\n",
      "Epoch 8: val_loss improved from 1.48913 to 1.42958, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 1.3335 - sMAPE_tf: 1.3323 - val_loss: 1.4296 - val_sMAPE_tf: 1.4296\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2914 - sMAPE_tf: 1.2914\n",
      "Epoch 9: val_loss improved from 1.42958 to 1.39610, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 105ms/step - loss: 1.2937 - sMAPE_tf: 1.2954 - val_loss: 1.3961 - val_sMAPE_tf: 1.3961\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2537 - sMAPE_tf: 1.2537\n",
      "Epoch 10: val_loss improved from 1.39610 to 1.39054, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 1.2471 - sMAPE_tf: 1.2425 - val_loss: 1.3905 - val_sMAPE_tf: 1.3905\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2028 - sMAPE_tf: 1.2028\n",
      "Epoch 11: val_loss did not improve from 1.39054\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 1.2021 - sMAPE_tf: 1.2016 - val_loss: 1.3938 - val_sMAPE_tf: 1.3938\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1429 - sMAPE_tf: 1.1429\n",
      "Epoch 12: val_loss improved from 1.39054 to 1.38636, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 1.1448 - sMAPE_tf: 1.1460 - val_loss: 1.3864 - val_sMAPE_tf: 1.3864\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0960 - sMAPE_tf: 1.0960\n",
      "Epoch 13: val_loss did not improve from 1.38636\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 1.0944 - sMAPE_tf: 1.0934 - val_loss: 1.3886 - val_sMAPE_tf: 1.3886\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0500 - sMAPE_tf: 1.0500\n",
      "Epoch 14: val_loss improved from 1.38636 to 1.38261, saving model to ../checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 1.0462 - sMAPE_tf: 1.0435 - val_loss: 1.3826 - val_sMAPE_tf: 1.3826\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9961 - sMAPE_tf: 0.9961\n",
      "Epoch 15: val_loss did not improve from 1.38261\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.9905 - sMAPE_tf: 0.9867 - val_loss: 1.4058 - val_sMAPE_tf: 1.4058\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9365 - sMAPE_tf: 0.9365\n",
      "Epoch 16: val_loss did not improve from 1.38261\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.9334 - sMAPE_tf: 0.9312 - val_loss: 1.4252 - val_sMAPE_tf: 1.4252\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8966 - sMAPE_tf: 0.8966\n",
      "Epoch 17: val_loss did not improve from 1.38261\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.8934 - sMAPE_tf: 0.8911 - val_loss: 1.4768 - val_sMAPE_tf: 1.4768\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8314 - sMAPE_tf: 0.8314\n",
      "Epoch 18: val_loss did not improve from 1.38261\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.8291 - sMAPE_tf: 0.8275 - val_loss: 1.4890 - val_sMAPE_tf: 1.4890\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7927 - sMAPE_tf: 0.7927\n",
      "Epoch 19: val_loss did not improve from 1.38261\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.7910 - sMAPE_tf: 0.7899 - val_loss: 1.5175 - val_sMAPE_tf: 1.5175\n",
      "Training finished in 13.584057331085205 secconds\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.4030 - sMAPE_tf: 1.4030\n",
      "1.4030402898788452\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "mean_SMAPE:0.47015388845422545\n",
      "mean_MASE:0.8759045958093282\n",
      "sim_500_222_nl_ho\n",
      "198 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4592 - sMAPE_tf: 1.4604\n",
      "Epoch 1: val_loss improved from inf to 1.49576, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 4s 182ms/step - loss: 1.4592 - sMAPE_tf: 1.4604 - val_loss: 1.4958 - val_sMAPE_tf: 1.4958\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4775 - sMAPE_tf: 1.4779\n",
      "Epoch 2: val_loss improved from 1.49576 to 1.48123, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 1.4775 - sMAPE_tf: 1.4779 - val_loss: 1.4812 - val_sMAPE_tf: 1.4812\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4623 - sMAPE_tf: 1.4623\n",
      "Epoch 3: val_loss improved from 1.48123 to 1.44216, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 1.4615 - sMAPE_tf: 1.4609 - val_loss: 1.4422 - val_sMAPE_tf: 1.4422\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4408 - sMAPE_tf: 1.4408\n",
      "Epoch 4: val_loss improved from 1.44216 to 1.44020, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 1.4388 - sMAPE_tf: 1.4375 - val_loss: 1.4402 - val_sMAPE_tf: 1.4402\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3955 - sMAPE_tf: 1.3955\n",
      "Epoch 5: val_loss did not improve from 1.44020\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 1.3940 - sMAPE_tf: 1.3929 - val_loss: 1.4626 - val_sMAPE_tf: 1.4626\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3464 - sMAPE_tf: 1.3464\n",
      "Epoch 6: val_loss did not improve from 1.44020\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 1.3438 - sMAPE_tf: 1.3421 - val_loss: 1.4408 - val_sMAPE_tf: 1.4408\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2946 - sMAPE_tf: 1.2946\n",
      "Epoch 7: val_loss improved from 1.44020 to 1.42588, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 1.2925 - sMAPE_tf: 1.2911 - val_loss: 1.4259 - val_sMAPE_tf: 1.4259\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2392 - sMAPE_tf: 1.2392\n",
      "Epoch 8: val_loss improved from 1.42588 to 1.41198, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 110ms/step - loss: 1.2384 - sMAPE_tf: 1.2379 - val_loss: 1.4120 - val_sMAPE_tf: 1.4120\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1822 - sMAPE_tf: 1.1822\n",
      "Epoch 9: val_loss did not improve from 1.41198\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 1.1809 - sMAPE_tf: 1.1800 - val_loss: 1.4137 - val_sMAPE_tf: 1.4137\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1309 - sMAPE_tf: 1.1309\n",
      "Epoch 10: val_loss improved from 1.41198 to 1.41012, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 1.1300 - sMAPE_tf: 1.1294 - val_loss: 1.4101 - val_sMAPE_tf: 1.4101\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0630 - sMAPE_tf: 1.0630\n",
      "Epoch 11: val_loss improved from 1.41012 to 1.40902, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 1.0602 - sMAPE_tf: 1.0582 - val_loss: 1.4090 - val_sMAPE_tf: 1.4090\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9897 - sMAPE_tf: 0.9897\n",
      "Epoch 12: val_loss improved from 1.40902 to 1.40657, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.9873 - sMAPE_tf: 0.9857 - val_loss: 1.4066 - val_sMAPE_tf: 1.4066\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9080 - sMAPE_tf: 0.9080\n",
      "Epoch 13: val_loss improved from 1.40657 to 1.40635, saving model to ../checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 108ms/step - loss: 0.9116 - sMAPE_tf: 0.9141 - val_loss: 1.4063 - val_sMAPE_tf: 1.4063\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8494 - sMAPE_tf: 0.8494\n",
      "Epoch 14: val_loss did not improve from 1.40635\n",
      "6/6 [==============================] - 0s 65ms/step - loss: 0.8481 - sMAPE_tf: 0.8471 - val_loss: 1.4272 - val_sMAPE_tf: 1.4272\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8000 - sMAPE_tf: 0.8000\n",
      "Epoch 15: val_loss did not improve from 1.40635\n",
      "6/6 [==============================] - 0s 66ms/step - loss: 0.7991 - sMAPE_tf: 0.7985 - val_loss: 1.4737 - val_sMAPE_tf: 1.4737\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7541 - sMAPE_tf: 0.7541\n",
      "Epoch 16: val_loss did not improve from 1.40635\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.7526 - sMAPE_tf: 0.7515 - val_loss: 1.4806 - val_sMAPE_tf: 1.4806\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7098 - sMAPE_tf: 0.7098\n",
      "Epoch 17: val_loss did not improve from 1.40635\n",
      "6/6 [==============================] - 0s 67ms/step - loss: 0.7098 - sMAPE_tf: 0.7099 - val_loss: 1.4814 - val_sMAPE_tf: 1.4814\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6808 - sMAPE_tf: 0.6808\n",
      "Epoch 18: val_loss did not improve from 1.40635\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.6803 - sMAPE_tf: 0.6800 - val_loss: 1.5097 - val_sMAPE_tf: 1.5097\n",
      "Training finished in 13.235023260116577 secconds\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.3737 - sMAPE_tf: 1.3737\n",
      "1.3737075328826904\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "mean_SMAPE:0.4282756899940149\n",
      "mean_MASE:0.8231093579506571\n"
     ]
    }
   ],
   "source": [
    "dataset_name_test = ['sim_10_60_l_he', 'sim_10_60_l_ho',\\\n",
    "                     'sim_10_60_nl_he', 'sim_10_60_nl_ho',\\\n",
    "                     'sim_10_222_l_he', 'sim_10_222_l_ho',\\\n",
    "                     'sim_10_222_nl_he', 'sim_10_222_nl_ho',\\\n",
    "                     'sim_101_60_l_he', 'sim_101_60_l_ho',\\\n",
    "                     'sim_101_60_nl_he', 'sim_101_60_nl_ho',\\\n",
    "                     'sim_101_222_l_he', 'sim_101_222_l_ho',\\\n",
    "                     'sim_101_222_nl_he', 'sim_101_222_nl_ho',\\\n",
    "                     'sim_500_60_l_he', 'sim_500_60_l_ho',\\\n",
    "                     'sim_500_60_nl_he', 'sim_500_60_nl_ho',\\\n",
    "                     'sim_500_222_l_he', 'sim_500_222_l_ho',\\\n",
    "                     'sim_500_222_nl_he', 'sim_500_222_nl_ho']\n",
    "dataset_type = 'sim'\n",
    "forecast_horizon=12\n",
    "\n",
    "for i in dataset_name_test:\n",
    "    print(i)\n",
    "    tsmixer_eval(i,dataset_type,forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
