{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 10:10:24.642517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 10:10:24.642593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 10:10:24.644545: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 10:10:27.329293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "############ tsmixer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')  # Assuming the module is in the parent directory\n",
    "import benchmarks\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from preprocess_scripts.data_loader import DataLoader\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# first sort, then do placebo test\n",
    "def custom_sort_key(s):\n",
    "    parts = s.split('_')\n",
    "    return int(parts[1])\n",
    "\n",
    "def sMAPE_tf(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "    smape_values = tf.abs(y_pred - y_true) / (tf.abs(y_pred) + tf.abs(y_true)) * 2\n",
    "    smape_per_series = tf.reduce_mean(smape_values, axis=1)\n",
    "    mean_smape = tf.reduce_mean(smape_per_series)\n",
    "\n",
    "    return mean_smape  # Convert TensorFlow tensor to NumPy array for compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tsmixer_eval(dataset_name,dataset_type, forecast_horizon):\n",
    "    if dataset_type == \"sim\":\n",
    "        y_true_df_A = pd.read_csv(\"../datasets/text_data/\" + dataset_type +  \\\n",
    "                \"/\" + dataset_name + \"_test_actual.csv\")\n",
    "        # Reading the original data to calculate the MASE errors\n",
    "        y_true_df_B = pd.read_csv(\"../datasets/text_data/\" + dataset_type +  \\\n",
    "                \"/\" + dataset_name + \"_train.csv\")\n",
    "        data_row_A = y_true_df_A.pivot(index='time', columns='series_id', values='value')\n",
    "        data_row_B = y_true_df_B.pivot(index='time', columns='series_id', values='value')\n",
    "        data_row_A = data_row_A.loc[:,sorted(data_row_A.columns, key=custom_sort_key)]\n",
    "        data_row_B = data_row_B.loc[:,sorted(data_row_B.columns, key=custom_sort_key)]\n",
    "        data_row = pd.concat([data_row_B, data_row_A],ignore_index=True)\n",
    "        data_row.to_csv(\"../datasets/text_data/sim/\"+dataset_name+\".csv\")\n",
    "        length_of_series = len(data_row.index)\n",
    "\n",
    "        # The columns of data_row need to be rename\n",
    "        # Define the pattern to replace\n",
    "        linear_to_l = r'_linear'\n",
    "        nonlinear_to_nl = r'_nonlinear'\n",
    "        heterogeneous_to_he = r'_heterogeneous'\n",
    "        homogeneous_to_ho = r'_homogeneous'\n",
    "\n",
    "        # Use regular expression to replace the part in column names\n",
    "        data_row.columns = data_row.columns.str.replace(linear_to_l, '_l')\n",
    "        data_row.columns = data_row.columns.str.replace(nonlinear_to_nl, '_nl')\n",
    "        data_row.columns = data_row.columns.str.replace(heterogeneous_to_he, '_he')\n",
    "        data_row.columns = data_row.columns.str.replace(homogeneous_to_ho, '_ho')\n",
    "\n",
    "        data_true_counterfactual = pd.read_csv(\"../datasets/text_data/sim/\"+dataset_name+'_true_counterfactual.csv')\n",
    "        data_true_counterfactual['time'] = data_true_counterfactual['time']+length_of_series-forecast_horizon-1\n",
    "        data_true_counterfactual = data_true_counterfactual.pivot(index='time', columns='series_id')['value']\n",
    "        data_true_counterfactual = data_true_counterfactual.loc[:,sorted(data_true_counterfactual.columns, key=custom_sort_key)]\n",
    "        # Replace values in data_row using the mapping\n",
    "        data_row_for_errors = data_row.copy()\n",
    "        data_row_for_errors.loc[data_true_counterfactual.index, data_true_counterfactual.columns] = data_true_counterfactual\n",
    "        data_row_for_errors.to_csv(\"../datasets/text_data/sim/\"+dataset_name+\"_for_errors.csv\")\n",
    "\n",
    "        data_row_A = data_row_for_errors.iloc[length_of_series-forecast_horizon:, :].T\n",
    "        data_row_B = data_row_for_errors.iloc[:length_of_series-forecast_horizon, :].T\n",
    "        \n",
    "        \n",
    "    if dataset_type == \"calls911\":\n",
    "        control = [\"BRIDGEPORT\", \"BRYN ATHYN\", \"DOUGLASS\", \"HATBORO\", \"HATFIELD BORO\",\n",
    "                      \"LOWER FREDERICK\", \"NEW HANOVER\", \"NORRISTOWN\", \"NORTH WALES\", \"SALFORD\",\n",
    "                      \"SPRINGFIELD\", \"TRAPPE\"]\n",
    "        data_row = pd.read_csv('../datasets/text_data/' + dataset_type\\\n",
    "                            + '/'+dataset_name+'.csv').iloc[:, 1:]\n",
    "        data_row_cols = data_row.columns\n",
    "        data_row_for_errors = data_row.loc[:,control]\n",
    "        length_of_series = len(data_row.index)\n",
    "        y_true_df_A = data_row_for_errors.iloc[length_of_series-forecast_horizon:, :].T\n",
    "        y_true_df_B = data_row_for_errors.iloc[:length_of_series-forecast_horizon, :].T\n",
    "        data_row_A = y_true_df_A\n",
    "        # print(data_row_A)\n",
    "        data_row_B = y_true_df_B\n",
    "    \n",
    "    feature_type='M'\n",
    "    norm_type = 'B'\n",
    "    activation = 'relu'\n",
    "    dropout = 0.05\n",
    "    n_block=2\n",
    "    batch_size=31\n",
    "    no_of_series = len(data_row_B.index) \n",
    "    patience = 5\n",
    "    train_epochs = 100\n",
    "    learning_rate = 0.01\n",
    "    seasonality_period = 12\n",
    "    \n",
    "    input_size = int(seasonality_period * 1.25)\n",
    "    checkpoint_dir = '../checkpoints/'\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        data=dataset_name,\n",
    "        batch_size=batch_size,\n",
    "        seq_len=input_size,\n",
    "        pred_len=forecast_horizon,\n",
    "        feature_type=feature_type,\n",
    "        dt_type=dataset_type\n",
    "    )\n",
    "    train_data = data_loader.get_train()\n",
    "    val_data = data_loader.get_val()\n",
    "    test_data = data_loader.get_test()\n",
    "\n",
    "    build_model = getattr(benchmarks, 'tsmixer').build_model\n",
    "    model = build_model(\n",
    "        input_shape=(input_size, data_loader.n_feature),\n",
    "        pred_len=forecast_horizon,\n",
    "        norm_type=norm_type,\n",
    "        activation=activation,\n",
    "        dropout=dropout,\n",
    "        n_block=n_block,\n",
    "        ff_dim=no_of_series,\n",
    "        target_slice=data_loader.target_slice,\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=sMAPE_tf, metrics=[sMAPE_tf])\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'{dataset_name}_best')\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience\n",
    "    )\n",
    "    start_training_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        epochs=train_epochs,\n",
    "        validation_data=val_data,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "    )\n",
    "    end_training_time = time.time()\n",
    "    elasped_training_time = end_training_time - start_training_time\n",
    "    print(f'Training finished in {elasped_training_time} secconds')\n",
    "\n",
    "    # evaluate best model\n",
    "    best_epoch = np.argmin(history.history['val_loss'])\n",
    "    model.load_weights(checkpoint_path)\n",
    "    test_result = model.evaluate(test_data)\n",
    "    test_smape = test_result[1]\n",
    "    print(test_smape)\n",
    "\n",
    "    for f in glob.glob(checkpoint_path + '*'):\n",
    "        os.remove(f)\n",
    "    \n",
    "    prediction = model.predict(test_data)\n",
    "    y_pred = data_loader.inverse_transform(prediction[0])\n",
    "\n",
    "    output = '../results/benchmarks/predicted/' + dataset_name +\\\n",
    "            '_tsmixer.csv'\n",
    "    y_pred_df = pd.DataFrame(y_pred.T)\n",
    "    y_pred_df.to_csv(output, index=False, header=False)\n",
    "    y_pred_for_errors = y_pred_df.copy()\n",
    "    if dataset_type == \"calls911\":\n",
    "        y_pred_for_errors['names'] = data_row_cols\n",
    "        y_pred_for_errors.set_index('names', inplace=True)\n",
    "        y_pred_for_errors = y_pred_for_errors.loc[control,:]\n",
    "\n",
    "    errors_directory = '../results/benchmarks/errors/'\n",
    "\n",
    "    errors_file_name_mean_median = 'mean_median_' + dataset_name + '_tsmixer'\n",
    "    SMAPE_file_name_all_errors = 'all_smape_errors_' + dataset_name + '_tsmixer'\n",
    "    MASE_file_name_all_errors = 'all_mase_errors_' + dataset_name + '_tsmixer'\n",
    "\n",
    "    errors_file_full_name_mean_median = errors_directory + errors_file_name_mean_median+'.txt'\n",
    "    SMAPE_file_full_name_all_errors = errors_directory + SMAPE_file_name_all_errors\n",
    "    MASE_file_full_name_all_errors = errors_directory + MASE_file_name_all_errors\n",
    "\n",
    "    # SMAPE\n",
    "    print(np.array(y_pred_for_errors))\n",
    "    print(np.array(data_row_A))\n",
    "    try:\n",
    "        time_series_wise_SMAPE = 2 * np.abs(np.array(y_pred_for_errors) - np.array(data_row_A)) /\\\n",
    "            (np.abs(np.array(y_pred_for_errors)) + np.abs(np.array(data_row_A)))\n",
    "        SMAPEPerSeries = np.mean(time_series_wise_SMAPE, axis=1)\n",
    "        mean_SMAPE = np.mean(SMAPEPerSeries)\n",
    "        mean_SMAPE_str = f\"mean_SMAPE:{mean_SMAPE}\"\n",
    "        print(mean_SMAPE_str)\n",
    "        np.savetxt(SMAPE_file_full_name_all_errors+'.txt', SMAPEPerSeries, delimiter=\",\", fmt='%f')\n",
    "    except:\n",
    "        print(np.array(y_pred_for_errors))\n",
    "        print(np.array(data_row_A))\n",
    "    mase_vector = []\n",
    "    for i in range(no_of_series):\n",
    "        lagged_diff = [data_row_B.iloc[i,j] - \\\n",
    "                   data_row_B.iloc[i,j - forecast_horizon]\\\n",
    "                      for j in range(forecast_horizon,\\\n",
    "                        len(data_row_B.columns))]\n",
    "        mase_vector.append(np.mean(np.abs(np.array(np.array(data_row_A.iloc[i]))\\\n",
    "                 - np.array(y_pred_for_errors.iloc[i])) / np.mean(np.abs(lagged_diff))))\n",
    "\n",
    "    mean_MASE = np.mean(mase_vector)\n",
    "    mean_MASE_str = f\"mean_MASE:{mean_MASE}\"\n",
    "    print(mean_MASE_str)\n",
    "\n",
    "    np.savetxt(MASE_file_full_name_all_errors+'.txt', mase_vector, delimiter=\",\", fmt='%f')\n",
    "\n",
    "    # Writing the SMAPE results to file\n",
    "    with open(errors_file_full_name_mean_median, 'w') as f:\n",
    "        # f.write('\\n'.join([mean_SMAPE_str, median_SMAPE_str, std_SMAPE_str]))\n",
    "        f.write('\\n'.join([mean_SMAPE_str]))\n",
    "\n",
    "    # Writing the MASE results to file\n",
    "    with open(errors_file_full_name_mean_median, 'a') as f:\n",
    "        # f.write('\\n'.join([mean_MASE_str, median_MASE_str, std_MASE_str]))\n",
    "        f.write('\\n'.join([mean_MASE_str]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 22 22\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4638 - sMAPE_tf: 1.4638\n",
      "Epoch 1: val_loss improved from inf to 1.49645, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.4638 - sMAPE_tf: 1.4638 - val_loss: 1.4965 - val_sMAPE_tf: 1.4965\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4514 - sMAPE_tf: 1.4514\n",
      "Epoch 2: val_loss improved from 1.49645 to 1.47420, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.4514 - sMAPE_tf: 1.4514 - val_loss: 1.4742 - val_sMAPE_tf: 1.4742\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4395 - sMAPE_tf: 1.4395\n",
      "Epoch 3: val_loss improved from 1.47420 to 1.46167, saving model to ../checkpoints/calls911_benchmarks_best\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.4395 - sMAPE_tf: 1.4395 - val_loss: 1.4617 - val_sMAPE_tf: 1.4617\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4314 - sMAPE_tf: 1.4314\n",
      "Epoch 4: val_loss did not improve from 1.46167\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.4314 - sMAPE_tf: 1.4314 - val_loss: 1.4726 - val_sMAPE_tf: 1.4726\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4226 - sMAPE_tf: 1.4226\n",
      "Epoch 5: val_loss did not improve from 1.46167\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.4226 - sMAPE_tf: 1.4226 - val_loss: 1.4712 - val_sMAPE_tf: 1.4712\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4184 - sMAPE_tf: 1.4184\n",
      "Epoch 6: val_loss did not improve from 1.46167\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.4184 - sMAPE_tf: 1.4184 - val_loss: 1.4690 - val_sMAPE_tf: 1.4690\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4106 - sMAPE_tf: 1.4106\n",
      "Epoch 7: val_loss did not improve from 1.46167\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.4106 - sMAPE_tf: 1.4106 - val_loss: 1.4750 - val_sMAPE_tf: 1.4750\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4059 - sMAPE_tf: 1.4059\n",
      "Epoch 8: val_loss did not improve from 1.46167\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.4059 - sMAPE_tf: 1.4059 - val_loss: 1.4797 - val_sMAPE_tf: 1.4797\n",
      "Training finished in 4.89879035949707 secconds\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5481 - sMAPE_tf: 1.5481\n",
      "1.5481141805648804\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "mean_SMAPE:0.3975023346196262\n",
      "mean_MASE:1.727581121510269\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'calls911_benchmarks'\n",
    "dataset_type = 'calls911'\n",
    "forecast_horizon=7\n",
    "\n",
    "tsmixer_eval(dataset_name,dataset_type,forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_10_60_l_he\n",
      "36 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4197 - sMAPE_tf: 1.4197\n",
      "Epoch 1: val_loss improved from inf to 1.33398, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4197 - sMAPE_tf: 1.4197 - val_loss: 1.3340 - val_sMAPE_tf: 1.3340\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3928 - sMAPE_tf: 1.3928\n",
      "Epoch 2: val_loss improved from 1.33398 to 1.32964, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.3928 - sMAPE_tf: 1.3928 - val_loss: 1.3296 - val_sMAPE_tf: 1.3296\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3522 - sMAPE_tf: 1.3522\n",
      "Epoch 3: val_loss improved from 1.32964 to 1.32318, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 1.3522 - sMAPE_tf: 1.3522 - val_loss: 1.3232 - val_sMAPE_tf: 1.3232\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3447 - sMAPE_tf: 1.3447\n",
      "Epoch 4: val_loss did not improve from 1.32318\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.3447 - sMAPE_tf: 1.3447 - val_loss: 1.3385 - val_sMAPE_tf: 1.3385\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3230 - sMAPE_tf: 1.3230\n",
      "Epoch 5: val_loss did not improve from 1.32318\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.3230 - sMAPE_tf: 1.3230 - val_loss: 1.3322 - val_sMAPE_tf: 1.3322\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3040 - sMAPE_tf: 1.3040\n",
      "Epoch 6: val_loss did not improve from 1.32318\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.3040 - sMAPE_tf: 1.3040 - val_loss: 1.3255 - val_sMAPE_tf: 1.3255\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3090 - sMAPE_tf: 1.3090\n",
      "Epoch 7: val_loss improved from 1.32318 to 1.31699, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.3090 - sMAPE_tf: 1.3090 - val_loss: 1.3170 - val_sMAPE_tf: 1.3170\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2784 - sMAPE_tf: 1.2784\n",
      "Epoch 8: val_loss improved from 1.31699 to 1.30442, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.2784 - sMAPE_tf: 1.2784 - val_loss: 1.3044 - val_sMAPE_tf: 1.3044\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2823 - sMAPE_tf: 1.2823\n",
      "Epoch 9: val_loss improved from 1.30442 to 1.30388, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.2823 - sMAPE_tf: 1.2823 - val_loss: 1.3039 - val_sMAPE_tf: 1.3039\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2678 - sMAPE_tf: 1.2678\n",
      "Epoch 10: val_loss improved from 1.30388 to 1.29993, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 1.2678 - sMAPE_tf: 1.2678 - val_loss: 1.2999 - val_sMAPE_tf: 1.2999\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2474 - sMAPE_tf: 1.2474\n",
      "Epoch 11: val_loss improved from 1.29993 to 1.29453, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.2474 - sMAPE_tf: 1.2474 - val_loss: 1.2945 - val_sMAPE_tf: 1.2945\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2417 - sMAPE_tf: 1.2417\n",
      "Epoch 12: val_loss improved from 1.29453 to 1.28965, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.2417 - sMAPE_tf: 1.2417 - val_loss: 1.2896 - val_sMAPE_tf: 1.2896\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2038 - sMAPE_tf: 1.2038\n",
      "Epoch 13: val_loss improved from 1.28965 to 1.28109, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 1.2038 - sMAPE_tf: 1.2038 - val_loss: 1.2811 - val_sMAPE_tf: 1.2811\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2281 - sMAPE_tf: 1.2281\n",
      "Epoch 14: val_loss improved from 1.28109 to 1.27101, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 1.2281 - sMAPE_tf: 1.2281 - val_loss: 1.2710 - val_sMAPE_tf: 1.2710\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1848 - sMAPE_tf: 1.1848\n",
      "Epoch 15: val_loss improved from 1.27101 to 1.25928, saving model to ../checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.1848 - sMAPE_tf: 1.1848 - val_loss: 1.2593 - val_sMAPE_tf: 1.2593\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1815 - sMAPE_tf: 1.1815\n",
      "Epoch 16: val_loss did not improve from 1.25928\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.1815 - sMAPE_tf: 1.1815 - val_loss: 1.2762 - val_sMAPE_tf: 1.2762\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1667 - sMAPE_tf: 1.1667\n",
      "Epoch 17: val_loss did not improve from 1.25928\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1667 - sMAPE_tf: 1.1667 - val_loss: 1.2893 - val_sMAPE_tf: 1.2893\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1483 - sMAPE_tf: 1.1483\n",
      "Epoch 18: val_loss did not improve from 1.25928\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.1483 - sMAPE_tf: 1.1483 - val_loss: 1.3011 - val_sMAPE_tf: 1.3011\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1229 - sMAPE_tf: 1.1229\n",
      "Epoch 19: val_loss did not improve from 1.25928\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.1229 - sMAPE_tf: 1.1229 - val_loss: 1.3074 - val_sMAPE_tf: 1.3074\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1118 - sMAPE_tf: 1.1118\n",
      "Epoch 20: val_loss did not improve from 1.25928\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.1118 - sMAPE_tf: 1.1118 - val_loss: 1.2979 - val_sMAPE_tf: 1.2979\n",
      "Training finished in 8.218063831329346 secconds\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2525 - sMAPE_tf: 1.2525\n",
      "1.2524592876434326\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7eff04366560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "           0          1          2          3          4          5   \\\n",
      "0   29.311710  37.572735  44.480255  29.380169  34.446129  35.477898   \n",
      "1   13.731095  11.415406  12.160273  12.911877  14.727546  11.113670   \n",
      "2    4.286549   4.842784   7.135606   3.967993   4.737858   4.056058   \n",
      "3    0.979063   2.454531   5.497456  -1.466623  -0.236608   2.638812   \n",
      "4    3.915179   6.972877   9.156419   5.477858   6.781596   2.054317   \n",
      "5    8.779105   8.970652   9.851833   8.101028  12.155007  10.495613   \n",
      "6    8.099402   7.021158   6.309575   7.086833   8.076440   9.626135   \n",
      "7    5.985796   5.263784   6.964610   6.307484   6.051149   3.726101   \n",
      "8    3.216229   3.837462   3.569867   3.455271   2.737226   1.820890   \n",
      "9    5.239026   6.401469   6.663173   5.536385   7.226707   5.969759   \n",
      "10   8.867777   5.494412   9.681346   7.705470   6.816436   7.188708   \n",
      "\n",
      "           6          7          8          9          10         11  \n",
      "0  -72.711258  60.441860  87.291428  91.856995  73.573502  36.999573  \n",
      "1   -7.300541  19.464104  19.679270  20.560499  18.461145  15.774854  \n",
      "2    0.687862   5.679420   7.457186   9.115099   8.099867   5.144258  \n",
      "3    0.389728   1.576558   2.900148   6.171309   4.739391   0.721228  \n",
      "4   -5.083095   8.427971  11.582470  10.708432   9.513260   5.692927  \n",
      "5   -7.262421  13.725671  17.157757  16.727642  16.406590   8.419142  \n",
      "6    9.434299   7.629346   6.967162   6.965675   5.766154   6.806308  \n",
      "7    0.309819   7.855420   8.464575   8.232437   9.080275   6.006727  \n",
      "8   -0.348604   4.700612   5.121955   4.945112   4.179625   4.681252  \n",
      "9    2.584289   6.726536   8.272809   8.689962   8.551641   5.663832  \n",
      "10   4.387596   9.495449   9.419768   8.268939   9.128100   4.985839  \n",
      "                      48         49         50         51         52  \\\n",
      "series_id                                                              \n",
      "10_1_60_l_he   12.006340  11.352994  10.521353   9.932367   9.618276   \n",
      "10_2_60_l_he    3.382012   2.912003   2.796320   3.139358   3.321410   \n",
      "10_3_60_l_he    0.626192   0.357929   0.995632   1.628923   1.687715   \n",
      "10_4_60_l_he    3.136506   4.040734   4.813821   5.289915   5.769288   \n",
      "10_5_60_l_he   10.469705  10.904679  11.034896  11.380023  11.665631   \n",
      "10_6_60_l_he   10.045824  10.474335  11.037738  12.191687  12.241512   \n",
      "10_7_60_l_he    4.716362   4.668726   5.555587   5.809702   6.591233   \n",
      "10_8_60_l_he    2.660300   2.928474   3.460979   3.625597   3.661427   \n",
      "10_9_60_l_he    3.595302   3.159808   2.624959   2.232378   2.434349   \n",
      "10_10_60_l_he   8.744379   8.757151   8.630161   7.758971   7.046636   \n",
      "\n",
      "                      53         54         55         56         57  \\\n",
      "series_id                                                              \n",
      "10_1_60_l_he    9.157620   8.431965   7.863224   7.168486   6.816528   \n",
      "10_2_60_l_he    3.636600   4.257041   4.986303   5.608776   5.934012   \n",
      "10_3_60_l_he    1.665791   1.282760   0.751531   0.586765   1.204006   \n",
      "10_4_60_l_he    5.543466   5.850550   5.857287   6.318393   6.622824   \n",
      "10_5_60_l_he   12.218192  12.982504  12.412732  12.196045  11.620668   \n",
      "10_6_60_l_he   11.864322  10.841802   9.884272   8.905381   8.821635   \n",
      "10_7_60_l_he    7.431840   8.314910   8.209514   8.084530   7.371814   \n",
      "10_8_60_l_he    3.843137   3.023671   3.261911   3.419651   3.803328   \n",
      "10_9_60_l_he    2.066310   1.777573   2.325928   2.243930   2.433413   \n",
      "10_10_60_l_he   6.901060   7.583591   8.411397   9.248885   9.575036   \n",
      "\n",
      "                      58         59  \n",
      "series_id                            \n",
      "10_1_60_l_he    6.943441   7.049501  \n",
      "10_2_60_l_he    5.797252   5.528619  \n",
      "10_3_60_l_he    1.265299   1.525902  \n",
      "10_4_60_l_he    6.783515   6.830923  \n",
      "10_5_60_l_he   11.124350  10.431952  \n",
      "10_6_60_l_he    8.784199   8.549681  \n",
      "10_7_60_l_he    7.089837   7.169530  \n",
      "10_8_60_l_he    3.640497   3.147761  \n",
      "10_9_60_l_he    2.889462   2.774834  \n",
      "10_10_60_l_he   9.939161  10.275756  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (11, 12): given (10, 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dataset_name_test:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mtsmixer_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 156\u001b[0m, in \u001b[0;36mtsmixer_eval\u001b[0;34m(dataset_name, dataset_type, forecast_horizon)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred_for_errors)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_row_A)\n\u001b[0;32m--> 156\u001b[0m time_series_wise_SMAPE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43my_pred_for_errors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_row_A\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m    157\u001b[0m     (np\u001b[38;5;241m.\u001b[39mabs(y_pred_for_errors) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39marray(data_row_A)))\n\u001b[1;32m    158\u001b[0m SMAPEPerSeries \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(time_series_wise_SMAPE, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m mean_SMAPE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(SMAPEPerSeries)\n",
      "File \u001b[0;32m/usr/local/anaconda3-2023.03/lib/python3.10/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3-2023.03/lib/python3.10/site-packages/pandas/core/arraylike.py:110\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3-2023.03/lib/python3.10/site-packages/pandas/core/frame.py:7592\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7589\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m   7590\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m-> 7592\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_method_FRAME\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7594\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   7595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m/usr/local/anaconda3-2023.03/lib/python3.10/site-packages/pandas/core/ops/__init__.py:264\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    261\u001b[0m         right \u001b[38;5;241m=\u001b[39m to_series(right[\u001b[38;5;241m0\u001b[39m, :])\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to coerce to DataFrame, shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: given \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mright\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m right\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to coerce to Series/DataFrame, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension must be <= 2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mright\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to DataFrame, shape must be (11, 12): given (10, 12)"
     ]
    }
   ],
   "source": [
    "dataset_name_test = ['sim_10_60_l_he', 'sim_10_60_l_ho',\\\n",
    "                     'sim_10_60_nl_he', 'sim_10_60_nl_ho',\\\n",
    "                     'sim_10_222_l_he', 'sim_10_222_l_ho',\\\n",
    "                     'sim_10_222_nl_he', 'sim_10_222_nl_ho',\\\n",
    "                     'sim_101_60_l_he', 'sim_101_60_l_ho',\\\n",
    "                     'sim_101_60_nl_he', 'sim_101_60_nl_ho',\\\n",
    "                     'sim_101_222_l_he', 'sim_101_222_l_ho',\\\n",
    "                     'sim_101_222_nl_he', 'sim_101_222_nl_ho',\\\n",
    "                     'sim_500_60_l_he', 'sim_500_60_l_ho',\\\n",
    "                     'sim_500_60_nl_he', 'sim_500_60_nl_ho',\\\n",
    "                     'sim_500_222_l_he', 'sim_500_222_l_ho',\\\n",
    "                     'sim_500_222_nl_he', 'sim_500_222_nl_ho']\n",
    "dataset_type = 'sim'\n",
    "forecast_horizon=12\n",
    "\n",
    "for i in dataset_name_test:\n",
    "    print(i)\n",
    "    tsmixer_eval(i,dataset_type,forecast_horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_10_60_l_he\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5557 - sMAPE_tf: 1.5557\n",
      "Epoch 1: val_loss improved from inf to 1.42770, saving model to ./checkpoints/sim_10_60_l_he_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.5557 - sMAPE_tf: 1.5557 - val_loss: 1.4277 - val_sMAPE_tf: 1.4277\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5246 - sMAPE_tf: 1.5246\n",
      "Epoch 2: val_loss did not improve from 1.42770\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.5246 - sMAPE_tf: 1.5246 - val_loss: 1.4536 - val_sMAPE_tf: 1.4536\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5050 - sMAPE_tf: 1.5050\n",
      "Epoch 3: val_loss did not improve from 1.42770\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 1.5050 - sMAPE_tf: 1.5050 - val_loss: 1.4632 - val_sMAPE_tf: 1.4632\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4967 - sMAPE_tf: 1.4967\n",
      "Epoch 4: val_loss did not improve from 1.42770\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.4967 - sMAPE_tf: 1.4967 - val_loss: 1.4742 - val_sMAPE_tf: 1.4742\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4727 - sMAPE_tf: 1.4727\n",
      "Epoch 5: val_loss did not improve from 1.42770\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 1.4727 - sMAPE_tf: 1.4727 - val_loss: 1.4791 - val_sMAPE_tf: 1.4791\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4628 - sMAPE_tf: 1.4628\n",
      "Epoch 6: val_loss did not improve from 1.42770\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.4628 - sMAPE_tf: 1.4628 - val_loss: 1.4834 - val_sMAPE_tf: 1.4834\n",
      "Training finished in 7.042247533798218 secconds\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.4715 - sMAPE_tf: 1.4715\n",
      "1.4715226888656616\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "mean_SMAPE:0.6854110822168675\n",
      "mean_MASE:3.2533837455736916\n",
      "sim_10_60_l_ho\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4202 - sMAPE_tf: 1.4202\n",
      "Epoch 1: val_loss improved from inf to 1.35567, saving model to ./checkpoints/sim_10_60_l_ho_best\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.4202 - sMAPE_tf: 1.4202 - val_loss: 1.3557 - val_sMAPE_tf: 1.3557\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3789 - sMAPE_tf: 1.3789\n",
      "Epoch 2: val_loss did not improve from 1.35567\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.3789 - sMAPE_tf: 1.3789 - val_loss: 1.3721 - val_sMAPE_tf: 1.3721\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3658 - sMAPE_tf: 1.3658\n",
      "Epoch 3: val_loss did not improve from 1.35567\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.3658 - sMAPE_tf: 1.3658 - val_loss: 1.3813 - val_sMAPE_tf: 1.3813\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3313 - sMAPE_tf: 1.3313\n",
      "Epoch 4: val_loss did not improve from 1.35567\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 1.3313 - sMAPE_tf: 1.3313 - val_loss: 1.3780 - val_sMAPE_tf: 1.3780\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2984 - sMAPE_tf: 1.2984\n",
      "Epoch 5: val_loss did not improve from 1.35567\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.2984 - sMAPE_tf: 1.2984 - val_loss: 1.3826 - val_sMAPE_tf: 1.3826\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3095 - sMAPE_tf: 1.3095\n",
      "Epoch 6: val_loss did not improve from 1.35567\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.3095 - sMAPE_tf: 1.3095 - val_loss: 1.3818 - val_sMAPE_tf: 1.3818\n",
      "Training finished in 9.980454444885254 secconds\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.3628 - sMAPE_tf: 1.3628\n",
      "1.3628411293029785\n",
      "1/1 [==============================] - 1s 572ms/step\n",
      "mean_SMAPE:0.8122283295695116\n",
      "mean_MASE:2.877804015584885\n",
      "sim_10_60_nl_he\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4471 - sMAPE_tf: 1.4471\n",
      "Epoch 1: val_loss improved from inf to 1.40001, saving model to ./checkpoints/sim_10_60_nl_he_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4471 - sMAPE_tf: 1.4471 - val_loss: 1.4000 - val_sMAPE_tf: 1.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4545 - sMAPE_tf: 1.4545\n",
      "Epoch 2: val_loss improved from 1.40001 to 1.39276, saving model to ./checkpoints/sim_10_60_nl_he_best\n",
      "1/1 [==============================] - 0s 417ms/step - loss: 1.4545 - sMAPE_tf: 1.4545 - val_loss: 1.3928 - val_sMAPE_tf: 1.3928\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3934 - sMAPE_tf: 1.3934\n",
      "Epoch 3: val_loss did not improve from 1.39276\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.3934 - sMAPE_tf: 1.3934 - val_loss: 1.3982 - val_sMAPE_tf: 1.3982\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3796 - sMAPE_tf: 1.3796\n",
      "Epoch 4: val_loss did not improve from 1.39276\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.3796 - sMAPE_tf: 1.3796 - val_loss: 1.3995 - val_sMAPE_tf: 1.3995\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3647 - sMAPE_tf: 1.3647\n",
      "Epoch 5: val_loss did not improve from 1.39276\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 1.3647 - sMAPE_tf: 1.3647 - val_loss: 1.4009 - val_sMAPE_tf: 1.4009\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3637 - sMAPE_tf: 1.3637\n",
      "Epoch 6: val_loss did not improve from 1.39276\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.3637 - sMAPE_tf: 1.3637 - val_loss: 1.4020 - val_sMAPE_tf: 1.4020\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3487 - sMAPE_tf: 1.3487\n",
      "Epoch 7: val_loss did not improve from 1.39276\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.3487 - sMAPE_tf: 1.3487 - val_loss: 1.4046 - val_sMAPE_tf: 1.4046\n",
      "Training finished in 6.725042819976807 secconds\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.4797 - sMAPE_tf: 1.4797\n",
      "1.4797124862670898\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "mean_SMAPE:0.6721124127817468\n",
      "mean_MASE:2.3636726181939998\n",
      "sim_10_60_nl_ho\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4871 - sMAPE_tf: 1.4871\n",
      "Epoch 1: val_loss improved from inf to 1.51675, saving model to ./checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4871 - sMAPE_tf: 1.4871 - val_loss: 1.5167 - val_sMAPE_tf: 1.5167\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4617 - sMAPE_tf: 1.4617\n",
      "Epoch 2: val_loss improved from 1.51675 to 1.51164, saving model to ./checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 1.4617 - sMAPE_tf: 1.4617 - val_loss: 1.5116 - val_sMAPE_tf: 1.5116\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4636 - sMAPE_tf: 1.4636\n",
      "Epoch 3: val_loss improved from 1.51164 to 1.49927, saving model to ./checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.4636 - sMAPE_tf: 1.4636 - val_loss: 1.4993 - val_sMAPE_tf: 1.4993\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4317 - sMAPE_tf: 1.4317\n",
      "Epoch 4: val_loss improved from 1.49927 to 1.48372, saving model to ./checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 373ms/step - loss: 1.4317 - sMAPE_tf: 1.4317 - val_loss: 1.4837 - val_sMAPE_tf: 1.4837\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4216 - sMAPE_tf: 1.4216\n",
      "Epoch 5: val_loss improved from 1.48372 to 1.47257, saving model to ./checkpoints/sim_10_60_nl_ho_best\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.4216 - sMAPE_tf: 1.4216 - val_loss: 1.4726 - val_sMAPE_tf: 1.4726\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4047 - sMAPE_tf: 1.4047\n",
      "Epoch 6: val_loss did not improve from 1.47257\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.4047 - sMAPE_tf: 1.4047 - val_loss: 1.4880 - val_sMAPE_tf: 1.4880\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3767 - sMAPE_tf: 1.3767\n",
      "Epoch 7: val_loss did not improve from 1.47257\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.3767 - sMAPE_tf: 1.3767 - val_loss: 1.4931 - val_sMAPE_tf: 1.4931\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3773 - sMAPE_tf: 1.3773\n",
      "Epoch 8: val_loss did not improve from 1.47257\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.3773 - sMAPE_tf: 1.3773 - val_loss: 1.4974 - val_sMAPE_tf: 1.4974\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3746 - sMAPE_tf: 1.3746\n",
      "Epoch 9: val_loss did not improve from 1.47257\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.3746 - sMAPE_tf: 1.3746 - val_loss: 1.4983 - val_sMAPE_tf: 1.4983\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3549 - sMAPE_tf: 1.3549\n",
      "Epoch 10: val_loss did not improve from 1.47257\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 1.3549 - sMAPE_tf: 1.3549 - val_loss: 1.5006 - val_sMAPE_tf: 1.5006\n",
      "Training finished in 8.036254644393921 secconds\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.5820 - sMAPE_tf: 1.5820\n",
      "1.5819876194000244\n",
      "1/1 [==============================] - 1s 524ms/step\n",
      "mean_SMAPE:0.8921816553450246\n",
      "mean_MASE:3.0164671746649194\n",
      "sim_10_222_l_he\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4236 - sMAPE_tf: 1.4236 \n",
      "Epoch 1: val_loss improved from inf to 1.33763, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 8s 282ms/step - loss: 1.4170 - sMAPE_tf: 1.4119 - val_loss: 1.3376 - val_sMAPE_tf: 1.3376\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3426 - sMAPE_tf: 1.3403\n",
      "Epoch 2: val_loss improved from 1.33763 to 1.21414, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.3426 - sMAPE_tf: 1.3403 - val_loss: 1.2141 - val_sMAPE_tf: 1.2141\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2875 - sMAPE_tf: 1.2813\n",
      "Epoch 3: val_loss improved from 1.21414 to 1.20093, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 1.2875 - sMAPE_tf: 1.2813 - val_loss: 1.2009 - val_sMAPE_tf: 1.2009\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2378 - sMAPE_tf: 1.2347\n",
      "Epoch 4: val_loss improved from 1.20093 to 1.11907, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 1.2378 - sMAPE_tf: 1.2347 - val_loss: 1.1191 - val_sMAPE_tf: 1.1191\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1939 - sMAPE_tf: 1.1932\n",
      "Epoch 5: val_loss improved from 1.11907 to 1.02246, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 1.1939 - sMAPE_tf: 1.1932 - val_loss: 1.0225 - val_sMAPE_tf: 1.0225\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1428 - sMAPE_tf: 1.1428\n",
      "Epoch 6: val_loss improved from 1.02246 to 0.98483, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 1.1453 - sMAPE_tf: 1.1472 - val_loss: 0.9848 - val_sMAPE_tf: 0.9848\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1077 - sMAPE_tf: 1.1077\n",
      "Epoch 7: val_loss improved from 0.98483 to 0.96528, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 1.1101 - sMAPE_tf: 1.1120 - val_loss: 0.9653 - val_sMAPE_tf: 0.9653\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0810 - sMAPE_tf: 1.0810\n",
      "Epoch 8: val_loss improved from 0.96528 to 0.95470, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.0849 - sMAPE_tf: 1.0879 - val_loss: 0.9547 - val_sMAPE_tf: 0.9547\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0640 - sMAPE_tf: 1.0649\n",
      "Epoch 9: val_loss improved from 0.95470 to 0.94386, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 1.0640 - sMAPE_tf: 1.0649 - val_loss: 0.9439 - val_sMAPE_tf: 0.9439\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0457 - sMAPE_tf: 1.0457\n",
      "Epoch 10: val_loss did not improve from 0.94386\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0470 - sMAPE_tf: 1.0479 - val_loss: 0.9503 - val_sMAPE_tf: 0.9503\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0249 - sMAPE_tf: 1.0249\n",
      "Epoch 11: val_loss improved from 0.94386 to 0.91982, saving model to ./checkpoints/sim_10_222_l_he_best\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 1.0210 - sMAPE_tf: 1.0179 - val_loss: 0.9198 - val_sMAPE_tf: 0.9198\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0039 - sMAPE_tf: 1.0039\n",
      "Epoch 12: val_loss did not improve from 0.91982\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.0112 - sMAPE_tf: 1.0169 - val_loss: 0.9411 - val_sMAPE_tf: 0.9411\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9871 - sMAPE_tf: 0.9871\n",
      "Epoch 13: val_loss did not improve from 0.91982\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9917 - sMAPE_tf: 0.9953 - val_loss: 0.9802 - val_sMAPE_tf: 0.9802\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9726 - sMAPE_tf: 0.9726\n",
      "Epoch 14: val_loss did not improve from 0.91982\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9769 - sMAPE_tf: 0.9803 - val_loss: 0.9994 - val_sMAPE_tf: 0.9994\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9688 - sMAPE_tf: 0.9688\n",
      "Epoch 15: val_loss did not improve from 0.91982\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9645 - sMAPE_tf: 0.9612 - val_loss: 1.0497 - val_sMAPE_tf: 1.0497\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9571 - sMAPE_tf: 0.9571\n",
      "Epoch 16: val_loss did not improve from 0.91982\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9508 - sMAPE_tf: 0.9459 - val_loss: 1.0462 - val_sMAPE_tf: 1.0462\n",
      "Training finished in 14.307444095611572 secconds\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.1594 - sMAPE_tf: 1.1594\n",
      "1.1594440937042236\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16a0122950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "mean_SMAPE:0.6226642929277452\n",
      "mean_MASE:2.4266994264975157\n",
      "sim_10_222_l_ho\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4699 - sMAPE_tf: 1.4699 \n",
      "Epoch 1: val_loss improved from inf to 1.44914, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 5s 163ms/step - loss: 1.4675 - sMAPE_tf: 1.4656 - val_loss: 1.4491 - val_sMAPE_tf: 1.4491\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3958 - sMAPE_tf: 1.3933\n",
      "Epoch 2: val_loss improved from 1.44914 to 1.30107, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 1.3958 - sMAPE_tf: 1.3933 - val_loss: 1.3011 - val_sMAPE_tf: 1.3011\n",
      "Epoch 3/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.3751 - sMAPE_tf: 1.3751\n",
      "Epoch 3: val_loss improved from 1.30107 to 1.22483, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 1.3542 - sMAPE_tf: 1.3521 - val_loss: 1.2248 - val_sMAPE_tf: 1.2248\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3057 - sMAPE_tf: 1.3057\n",
      "Epoch 4: val_loss improved from 1.22483 to 1.16695, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 1.3034 - sMAPE_tf: 1.3015 - val_loss: 1.1670 - val_sMAPE_tf: 1.1670\n",
      "Epoch 5/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2634 - sMAPE_tf: 1.2634\n",
      "Epoch 5: val_loss improved from 1.16695 to 1.14822, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 1.2438 - sMAPE_tf: 1.2446 - val_loss: 1.1482 - val_sMAPE_tf: 1.1482\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1942 - sMAPE_tf: 1.1889\n",
      "Epoch 6: val_loss improved from 1.14822 to 1.04789, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 1.1942 - sMAPE_tf: 1.1889 - val_loss: 1.0479 - val_sMAPE_tf: 1.0479\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1405 - sMAPE_tf: 1.1333\n",
      "Epoch 7: val_loss improved from 1.04789 to 1.01228, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 1.1405 - sMAPE_tf: 1.1333 - val_loss: 1.0123 - val_sMAPE_tf: 1.0123\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0921 - sMAPE_tf: 1.0941\n",
      "Epoch 8: val_loss improved from 1.01228 to 0.94799, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 1.0921 - sMAPE_tf: 1.0941 - val_loss: 0.9480 - val_sMAPE_tf: 0.9480\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0572 - sMAPE_tf: 1.0489\n",
      "Epoch 9: val_loss improved from 0.94799 to 0.88597, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 1.0572 - sMAPE_tf: 1.0489 - val_loss: 0.8860 - val_sMAPE_tf: 0.8860\n",
      "Epoch 10/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0256 - sMAPE_tf: 1.0256\n",
      "Epoch 10: val_loss improved from 0.88597 to 0.85060, saving model to ./checkpoints/sim_10_222_l_ho_best\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 1.0204 - sMAPE_tf: 1.0186 - val_loss: 0.8506 - val_sMAPE_tf: 0.8506\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9911 - sMAPE_tf: 0.9956\n",
      "Epoch 11: val_loss did not improve from 0.85060\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.9911 - sMAPE_tf: 0.9956 - val_loss: 0.8620 - val_sMAPE_tf: 0.8620\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9766 - sMAPE_tf: 0.9746\n",
      "Epoch 12: val_loss did not improve from 0.85060\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.9766 - sMAPE_tf: 0.9746 - val_loss: 0.8864 - val_sMAPE_tf: 0.8864\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9492 - sMAPE_tf: 0.9502\n",
      "Epoch 13: val_loss did not improve from 0.85060\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9492 - sMAPE_tf: 0.9502 - val_loss: 0.9522 - val_sMAPE_tf: 0.9522\n",
      "Epoch 14/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9718 - sMAPE_tf: 0.9718\n",
      "Epoch 14: val_loss did not improve from 0.85060\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9278 - sMAPE_tf: 0.9283 - val_loss: 0.9461 - val_sMAPE_tf: 0.9461\n",
      "Epoch 15/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9039 - sMAPE_tf: 0.9039\n",
      "Epoch 15: val_loss did not improve from 0.85060\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.9173 - sMAPE_tf: 0.9207 - val_loss: 0.9298 - val_sMAPE_tf: 0.9298\n",
      "Training finished in 11.1047523021698 secconds\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.0539 - sMAPE_tf: 1.0539\n",
      "1.0538551807403564\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f16a0122440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 493ms/step\n",
      "mean_SMAPE:0.84215414687173\n",
      "mean_MASE:2.8815773287812343\n",
      "sim_10_222_nl_he\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4532 - sMAPE_tf: 1.4500 \n",
      "Epoch 1: val_loss improved from inf to 1.35656, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 5s 212ms/step - loss: 1.4532 - sMAPE_tf: 1.4500 - val_loss: 1.3566 - val_sMAPE_tf: 1.3566\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3682 - sMAPE_tf: 1.3682\n",
      "Epoch 2: val_loss improved from 1.35656 to 1.28556, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 1.3695 - sMAPE_tf: 1.3705 - val_loss: 1.2856 - val_sMAPE_tf: 1.2856\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3389 - sMAPE_tf: 1.3365\n",
      "Epoch 3: val_loss improved from 1.28556 to 1.20426, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.3389 - sMAPE_tf: 1.3365 - val_loss: 1.2043 - val_sMAPE_tf: 1.2043\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2974 - sMAPE_tf: 1.2974\n",
      "Epoch 4: val_loss did not improve from 1.20426\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.2968 - sMAPE_tf: 1.2963 - val_loss: 1.2099 - val_sMAPE_tf: 1.2099\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2648 - sMAPE_tf: 1.2648\n",
      "Epoch 5: val_loss improved from 1.20426 to 1.18878, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 1.2672 - sMAPE_tf: 1.2690 - val_loss: 1.1888 - val_sMAPE_tf: 1.1888\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2286 - sMAPE_tf: 1.2286\n",
      "Epoch 6: val_loss improved from 1.18878 to 1.16844, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 1.2318 - sMAPE_tf: 1.2343 - val_loss: 1.1684 - val_sMAPE_tf: 1.1684\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2070 - sMAPE_tf: 1.2070\n",
      "Epoch 7: val_loss improved from 1.16844 to 1.14157, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 1.2027 - sMAPE_tf: 1.1994 - val_loss: 1.1416 - val_sMAPE_tf: 1.1416\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1799 - sMAPE_tf: 1.1799\n",
      "Epoch 8: val_loss improved from 1.14157 to 1.07604, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 1.1797 - sMAPE_tf: 1.1796 - val_loss: 1.0760 - val_sMAPE_tf: 1.0760\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1399 - sMAPE_tf: 1.1399\n",
      "Epoch 9: val_loss improved from 1.07604 to 1.05832, saving model to ./checkpoints/sim_10_222_nl_he_best\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.1416 - sMAPE_tf: 1.1430 - val_loss: 1.0583 - val_sMAPE_tf: 1.0583\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1147 - sMAPE_tf: 1.1147\n",
      "Epoch 10: val_loss did not improve from 1.05832\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.1077 - sMAPE_tf: 1.1022 - val_loss: 1.0765 - val_sMAPE_tf: 1.0765\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0841 - sMAPE_tf: 1.0841\n",
      "Epoch 11: val_loss did not improve from 1.05832\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.0846 - sMAPE_tf: 1.0851 - val_loss: 1.1489 - val_sMAPE_tf: 1.1489\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0671 - sMAPE_tf: 1.0671\n",
      "Epoch 12: val_loss did not improve from 1.05832\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0702 - sMAPE_tf: 1.0726 - val_loss: 1.1411 - val_sMAPE_tf: 1.1411\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0476 - sMAPE_tf: 1.0476\n",
      "Epoch 13: val_loss did not improve from 1.05832\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 1.0511 - sMAPE_tf: 1.0539 - val_loss: 1.1531 - val_sMAPE_tf: 1.1531\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0355 - sMAPE_tf: 1.0355\n",
      "Epoch 14: val_loss did not improve from 1.05832\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 1.0347 - sMAPE_tf: 1.0341 - val_loss: 1.1611 - val_sMAPE_tf: 1.1611\n",
      "Training finished in 10.291881084442139 secconds\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.0204 - sMAPE_tf: 1.0204\n",
      "1.0204492807388306\n",
      "1/1 [==============================] - 0s 485ms/step\n",
      "mean_SMAPE:0.5298340442987806\n",
      "mean_MASE:1.4203011743664837\n",
      "sim_10_222_nl_ho\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4180 - sMAPE_tf: 1.4180 \n",
      "Epoch 1: val_loss improved from inf to 1.44198, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 5s 164ms/step - loss: 1.4124 - sMAPE_tf: 1.4081 - val_loss: 1.4420 - val_sMAPE_tf: 1.4420\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3371 - sMAPE_tf: 1.3347\n",
      "Epoch 2: val_loss improved from 1.44198 to 1.30909, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.3371 - sMAPE_tf: 1.3347 - val_loss: 1.3091 - val_sMAPE_tf: 1.3091\n",
      "Epoch 3/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2887 - sMAPE_tf: 1.2887\n",
      "Epoch 3: val_loss did not improve from 1.30909\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 1.2660 - sMAPE_tf: 1.2710 - val_loss: 1.4140 - val_sMAPE_tf: 1.4140\n",
      "Epoch 4/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.2484 - sMAPE_tf: 1.2484\n",
      "Epoch 4: val_loss did not improve from 1.30909\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.2226 - sMAPE_tf: 1.2154 - val_loss: 1.3795 - val_sMAPE_tf: 1.3795\n",
      "Epoch 5/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1860 - sMAPE_tf: 1.1860\n",
      "Epoch 5: val_loss did not improve from 1.30909\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 1.1568 - sMAPE_tf: 1.1512 - val_loss: 1.3153 - val_sMAPE_tf: 1.3153\n",
      "Epoch 6/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.1127 - sMAPE_tf: 1.1127\n",
      "Epoch 6: val_loss improved from 1.30909 to 1.21512, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 1.0996 - sMAPE_tf: 1.0990 - val_loss: 1.2151 - val_sMAPE_tf: 1.2151\n",
      "Epoch 7/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.0554 - sMAPE_tf: 1.0554\n",
      "Epoch 7: val_loss improved from 1.21512 to 1.16008, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 84ms/step - loss: 1.0699 - sMAPE_tf: 1.0682 - val_loss: 1.1601 - val_sMAPE_tf: 1.1601\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0315 - sMAPE_tf: 1.0315\n",
      "Epoch 8: val_loss improved from 1.16008 to 1.15952, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 1.0320 - sMAPE_tf: 1.0324 - val_loss: 1.1595 - val_sMAPE_tf: 1.1595\n",
      "Epoch 9/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9807 - sMAPE_tf: 0.9807\n",
      "Epoch 9: val_loss did not improve from 1.15952\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.9992 - sMAPE_tf: 0.9971 - val_loss: 1.1709 - val_sMAPE_tf: 1.1709\n",
      "Epoch 10/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9782 - sMAPE_tf: 0.9782\n",
      "Epoch 10: val_loss improved from 1.15952 to 1.13860, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 69ms/step - loss: 0.9771 - sMAPE_tf: 0.9818 - val_loss: 1.1386 - val_sMAPE_tf: 1.1386\n",
      "Epoch 11/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9115 - sMAPE_tf: 0.9115\n",
      "Epoch 11: val_loss improved from 1.13860 to 1.10401, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.9567 - sMAPE_tf: 0.9553 - val_loss: 1.1040 - val_sMAPE_tf: 1.1040\n",
      "Epoch 12/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9450 - sMAPE_tf: 0.9450\n",
      "Epoch 12: val_loss improved from 1.10401 to 1.07246, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.9291 - sMAPE_tf: 0.9249 - val_loss: 1.0725 - val_sMAPE_tf: 1.0725\n",
      "Epoch 13/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9100 - sMAPE_tf: 0.9100\n",
      "Epoch 13: val_loss improved from 1.07246 to 1.06886, saving model to ./checkpoints/sim_10_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.9165 - sMAPE_tf: 0.9127 - val_loss: 1.0689 - val_sMAPE_tf: 1.0689\n",
      "Epoch 14/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.9121 - sMAPE_tf: 0.9121\n",
      "Epoch 14: val_loss did not improve from 1.06886\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.9048 - sMAPE_tf: 0.9074 - val_loss: 1.0836 - val_sMAPE_tf: 1.0836\n",
      "Epoch 15/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8805 - sMAPE_tf: 0.8805\n",
      "Epoch 15: val_loss did not improve from 1.06886\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.8896 - sMAPE_tf: 0.8902 - val_loss: 1.0738 - val_sMAPE_tf: 1.0738\n",
      "Epoch 16/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8989 - sMAPE_tf: 0.8989\n",
      "Epoch 16: val_loss did not improve from 1.06886\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.8702 - sMAPE_tf: 0.8704 - val_loss: 1.0959 - val_sMAPE_tf: 1.0959\n",
      "Epoch 17/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8227 - sMAPE_tf: 0.8227\n",
      "Epoch 17: val_loss did not improve from 1.06886\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.8738 - sMAPE_tf: 0.8767 - val_loss: 1.0839 - val_sMAPE_tf: 1.0839\n",
      "Epoch 18/100\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.8536 - sMAPE_tf: 0.8536\n",
      "Epoch 18: val_loss did not improve from 1.06886\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.8491 - sMAPE_tf: 0.8503 - val_loss: 1.0807 - val_sMAPE_tf: 1.0807\n",
      "Training finished in 11.120441913604736 secconds\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.9960 - sMAPE_tf: 0.9960\n",
      "0.996035099029541\n",
      "1/1 [==============================] - 0s 471ms/step\n",
      "mean_SMAPE:0.6321478416439625\n",
      "mean_MASE:1.9400904878296903\n",
      "sim_101_60_l_he\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4855 - sMAPE_tf: 1.4855\n",
      "Epoch 1: val_loss improved from inf to 1.45798, saving model to ./checkpoints/sim_101_60_l_he_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4855 - sMAPE_tf: 1.4855 - val_loss: 1.4580 - val_sMAPE_tf: 1.4580\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4590 - sMAPE_tf: 1.4590\n",
      "Epoch 2: val_loss improved from 1.45798 to 1.44302, saving model to ./checkpoints/sim_101_60_l_he_best\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.4590 - sMAPE_tf: 1.4590 - val_loss: 1.4430 - val_sMAPE_tf: 1.4430\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4476 - sMAPE_tf: 1.4476\n",
      "Epoch 3: val_loss did not improve from 1.44302\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.4476 - sMAPE_tf: 1.4476 - val_loss: 1.4511 - val_sMAPE_tf: 1.4511\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4209 - sMAPE_tf: 1.4209\n",
      "Epoch 4: val_loss did not improve from 1.44302\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.4209 - sMAPE_tf: 1.4209 - val_loss: 1.4638 - val_sMAPE_tf: 1.4638\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4160 - sMAPE_tf: 1.4160\n",
      "Epoch 5: val_loss did not improve from 1.44302\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4160 - sMAPE_tf: 1.4160 - val_loss: 1.4745 - val_sMAPE_tf: 1.4745\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4105 - sMAPE_tf: 1.4105\n",
      "Epoch 6: val_loss did not improve from 1.44302\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.4105 - sMAPE_tf: 1.4105 - val_loss: 1.4836 - val_sMAPE_tf: 1.4836\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3990 - sMAPE_tf: 1.3990\n",
      "Epoch 7: val_loss did not improve from 1.44302\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.3990 - sMAPE_tf: 1.3990 - val_loss: 1.4914 - val_sMAPE_tf: 1.4914\n",
      "Training finished in 6.87804913520813 secconds\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.4794 - sMAPE_tf: 1.4794\n",
      "1.4794002771377563\n",
      "1/1 [==============================] - 1s 545ms/step\n",
      "mean_SMAPE:0.8412116937320018\n",
      "mean_MASE:3.4291749529081863\n",
      "sim_101_60_l_ho\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4270 - sMAPE_tf: 1.4270\n",
      "Epoch 1: val_loss improved from inf to 1.46999, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4270 - sMAPE_tf: 1.4270 - val_loss: 1.4700 - val_sMAPE_tf: 1.4700\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3905 - sMAPE_tf: 1.3905\n",
      "Epoch 2: val_loss improved from 1.46999 to 1.44513, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 1.3905 - sMAPE_tf: 1.3905 - val_loss: 1.4451 - val_sMAPE_tf: 1.4451\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3590 - sMAPE_tf: 1.3590\n",
      "Epoch 3: val_loss improved from 1.44513 to 1.43710, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 1.3590 - sMAPE_tf: 1.3590 - val_loss: 1.4371 - val_sMAPE_tf: 1.4371\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3442 - sMAPE_tf: 1.3442\n",
      "Epoch 4: val_loss did not improve from 1.43710\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.3442 - sMAPE_tf: 1.3442 - val_loss: 1.4486 - val_sMAPE_tf: 1.4486\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3255 - sMAPE_tf: 1.3255\n",
      "Epoch 5: val_loss did not improve from 1.43710\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.3255 - sMAPE_tf: 1.3255 - val_loss: 1.4468 - val_sMAPE_tf: 1.4468\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3086 - sMAPE_tf: 1.3086\n",
      "Epoch 6: val_loss did not improve from 1.43710\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.3086 - sMAPE_tf: 1.3086 - val_loss: 1.4371 - val_sMAPE_tf: 1.4371\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2768 - sMAPE_tf: 1.2768\n",
      "Epoch 7: val_loss improved from 1.43710 to 1.42493, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 1.2768 - sMAPE_tf: 1.2768 - val_loss: 1.4249 - val_sMAPE_tf: 1.4249\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2602 - sMAPE_tf: 1.2602\n",
      "Epoch 8: val_loss improved from 1.42493 to 1.41117, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 1.2602 - sMAPE_tf: 1.2602 - val_loss: 1.4112 - val_sMAPE_tf: 1.4112\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2488 - sMAPE_tf: 1.2488\n",
      "Epoch 9: val_loss did not improve from 1.41117\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2488 - sMAPE_tf: 1.2488 - val_loss: 1.4131 - val_sMAPE_tf: 1.4131\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2345 - sMAPE_tf: 1.2345\n",
      "Epoch 10: val_loss did not improve from 1.41117\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.2345 - sMAPE_tf: 1.2345 - val_loss: 1.4113 - val_sMAPE_tf: 1.4113\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2274 - sMAPE_tf: 1.2274\n",
      "Epoch 11: val_loss improved from 1.41117 to 1.40594, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 1.2274 - sMAPE_tf: 1.2274 - val_loss: 1.4059 - val_sMAPE_tf: 1.4059\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2169 - sMAPE_tf: 1.2169\n",
      "Epoch 12: val_loss improved from 1.40594 to 1.40195, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 1.2169 - sMAPE_tf: 1.2169 - val_loss: 1.4020 - val_sMAPE_tf: 1.4020\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1952 - sMAPE_tf: 1.1952\n",
      "Epoch 13: val_loss improved from 1.40195 to 1.39393, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 1.1952 - sMAPE_tf: 1.1952 - val_loss: 1.3939 - val_sMAPE_tf: 1.3939\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1803 - sMAPE_tf: 1.1803\n",
      "Epoch 14: val_loss improved from 1.39393 to 1.39320, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.1803 - sMAPE_tf: 1.1803 - val_loss: 1.3932 - val_sMAPE_tf: 1.3932\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1750 - sMAPE_tf: 1.1750\n",
      "Epoch 15: val_loss improved from 1.39320 to 1.38902, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.1750 - sMAPE_tf: 1.1750 - val_loss: 1.3890 - val_sMAPE_tf: 1.3890\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1586 - sMAPE_tf: 1.1586\n",
      "Epoch 16: val_loss improved from 1.38902 to 1.38358, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 1.1586 - sMAPE_tf: 1.1586 - val_loss: 1.3836 - val_sMAPE_tf: 1.3836\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1345 - sMAPE_tf: 1.1345\n",
      "Epoch 17: val_loss improved from 1.38358 to 1.38016, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.1345 - sMAPE_tf: 1.1345 - val_loss: 1.3802 - val_sMAPE_tf: 1.3802\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1305 - sMAPE_tf: 1.1305\n",
      "Epoch 18: val_loss improved from 1.38016 to 1.37362, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 1.1305 - sMAPE_tf: 1.1305 - val_loss: 1.3736 - val_sMAPE_tf: 1.3736\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1134 - sMAPE_tf: 1.1134\n",
      "Epoch 19: val_loss improved from 1.37362 to 1.37256, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.1134 - sMAPE_tf: 1.1134 - val_loss: 1.3726 - val_sMAPE_tf: 1.3726\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0954 - sMAPE_tf: 1.0954\n",
      "Epoch 20: val_loss improved from 1.37256 to 1.37104, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.0954 - sMAPE_tf: 1.0954 - val_loss: 1.3710 - val_sMAPE_tf: 1.3710\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0954 - sMAPE_tf: 1.0954\n",
      "Epoch 21: val_loss improved from 1.37104 to 1.36452, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.0954 - sMAPE_tf: 1.0954 - val_loss: 1.3645 - val_sMAPE_tf: 1.3645\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0763 - sMAPE_tf: 1.0763\n",
      "Epoch 22: val_loss improved from 1.36452 to 1.36381, saving model to ./checkpoints/sim_101_60_l_ho_best\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.0763 - sMAPE_tf: 1.0763 - val_loss: 1.3638 - val_sMAPE_tf: 1.3638\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0640 - sMAPE_tf: 1.0640\n",
      "Epoch 23: val_loss did not improve from 1.36381\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.0640 - sMAPE_tf: 1.0640 - val_loss: 1.3695 - val_sMAPE_tf: 1.3695\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0406 - sMAPE_tf: 1.0406\n",
      "Epoch 24: val_loss did not improve from 1.36381\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 1.0406 - sMAPE_tf: 1.0406 - val_loss: 1.3710 - val_sMAPE_tf: 1.3710\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0337 - sMAPE_tf: 1.0337\n",
      "Epoch 25: val_loss did not improve from 1.36381\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.0337 - sMAPE_tf: 1.0337 - val_loss: 1.3714 - val_sMAPE_tf: 1.3714\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0141 - sMAPE_tf: 1.0141\n",
      "Epoch 26: val_loss did not improve from 1.36381\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 1.0141 - sMAPE_tf: 1.0141 - val_loss: 1.3666 - val_sMAPE_tf: 1.3666\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0007 - sMAPE_tf: 1.0007\n",
      "Epoch 27: val_loss did not improve from 1.36381\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.0007 - sMAPE_tf: 1.0007 - val_loss: 1.3669 - val_sMAPE_tf: 1.3669\n",
      "Training finished in 14.14473295211792 secconds\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.5325 - sMAPE_tf: 1.5325\n",
      "1.5324898958206177\n",
      "1/1 [==============================] - 0s 446ms/step\n",
      "mean_SMAPE:0.702899894265084\n",
      "mean_MASE:2.327708007733965\n",
      "sim_101_60_nl_he\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4954 - sMAPE_tf: 1.4954\n",
      "Epoch 1: val_loss improved from inf to 1.52755, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4954 - sMAPE_tf: 1.4954 - val_loss: 1.5275 - val_sMAPE_tf: 1.5275\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4690 - sMAPE_tf: 1.4690\n",
      "Epoch 2: val_loss improved from 1.52755 to 1.51604, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.4690 - sMAPE_tf: 1.4690 - val_loss: 1.5160 - val_sMAPE_tf: 1.5160\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4552 - sMAPE_tf: 1.4552\n",
      "Epoch 3: val_loss improved from 1.51604 to 1.50166, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 1.4552 - sMAPE_tf: 1.4552 - val_loss: 1.5017 - val_sMAPE_tf: 1.5017\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4415 - sMAPE_tf: 1.4415\n",
      "Epoch 4: val_loss improved from 1.50166 to 1.49938, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 1.4415 - sMAPE_tf: 1.4415 - val_loss: 1.4994 - val_sMAPE_tf: 1.4994\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4292 - sMAPE_tf: 1.4292\n",
      "Epoch 5: val_loss improved from 1.49938 to 1.48822, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 1.4292 - sMAPE_tf: 1.4292 - val_loss: 1.4882 - val_sMAPE_tf: 1.4882\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4221 - sMAPE_tf: 1.4221\n",
      "Epoch 6: val_loss did not improve from 1.48822\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1.4221 - sMAPE_tf: 1.4221 - val_loss: 1.4916 - val_sMAPE_tf: 1.4916\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4192 - sMAPE_tf: 1.4192\n",
      "Epoch 7: val_loss improved from 1.48822 to 1.48674, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.4192 - sMAPE_tf: 1.4192 - val_loss: 1.4867 - val_sMAPE_tf: 1.4867\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4128 - sMAPE_tf: 1.4128\n",
      "Epoch 8: val_loss improved from 1.48674 to 1.47456, saving model to ./checkpoints/sim_101_60_nl_he_best\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 1.4128 - sMAPE_tf: 1.4128 - val_loss: 1.4746 - val_sMAPE_tf: 1.4746\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3931 - sMAPE_tf: 1.3931\n",
      "Epoch 9: val_loss did not improve from 1.47456\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.3931 - sMAPE_tf: 1.3931 - val_loss: 1.4787 - val_sMAPE_tf: 1.4787\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3782 - sMAPE_tf: 1.3782\n",
      "Epoch 10: val_loss did not improve from 1.47456\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.3782 - sMAPE_tf: 1.3782 - val_loss: 1.4774 - val_sMAPE_tf: 1.4774\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3687 - sMAPE_tf: 1.3687\n",
      "Epoch 11: val_loss did not improve from 1.47456\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.3687 - sMAPE_tf: 1.3687 - val_loss: 1.4827 - val_sMAPE_tf: 1.4827\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3522 - sMAPE_tf: 1.3522\n",
      "Epoch 12: val_loss did not improve from 1.47456\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.3522 - sMAPE_tf: 1.3522 - val_loss: 1.4873 - val_sMAPE_tf: 1.4873\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3442 - sMAPE_tf: 1.3442\n",
      "Epoch 13: val_loss did not improve from 1.47456\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 1.3442 - sMAPE_tf: 1.3442 - val_loss: 1.4945 - val_sMAPE_tf: 1.4945\n",
      "Training finished in 8.165749549865723 secconds\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 1.5284 - sMAPE_tf: 1.5284\n",
      "1.5283660888671875\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "mean_SMAPE:0.9489899012341311\n",
      "mean_MASE:3.1831638091632444\n",
      "sim_101_60_nl_ho\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4447 - sMAPE_tf: 1.4447\n",
      "Epoch 1: val_loss improved from inf to 1.44901, saving model to ./checkpoints/sim_101_60_nl_ho_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4447 - sMAPE_tf: 1.4447 - val_loss: 1.4490 - val_sMAPE_tf: 1.4490\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4205 - sMAPE_tf: 1.4205\n",
      "Epoch 2: val_loss did not improve from 1.44901\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 1.4205 - sMAPE_tf: 1.4205 - val_loss: 1.4575 - val_sMAPE_tf: 1.4575\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4091 - sMAPE_tf: 1.4091\n",
      "Epoch 3: val_loss did not improve from 1.44901\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.4091 - sMAPE_tf: 1.4091 - val_loss: 1.4557 - val_sMAPE_tf: 1.4557\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3944 - sMAPE_tf: 1.3944\n",
      "Epoch 4: val_loss did not improve from 1.44901\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.3944 - sMAPE_tf: 1.3944 - val_loss: 1.4710 - val_sMAPE_tf: 1.4710\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3785 - sMAPE_tf: 1.3785\n",
      "Epoch 5: val_loss did not improve from 1.44901\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 1.3785 - sMAPE_tf: 1.3785 - val_loss: 1.4797 - val_sMAPE_tf: 1.4797\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3747 - sMAPE_tf: 1.3747\n",
      "Epoch 6: val_loss did not improve from 1.44901\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.3747 - sMAPE_tf: 1.3747 - val_loss: 1.4886 - val_sMAPE_tf: 1.4886\n",
      "Training finished in 5.583810091018677 secconds\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.4662 - sMAPE_tf: 1.4662\n",
      "1.4661592245101929\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "mean_SMAPE:0.8543002343954683\n",
      "mean_MASE:2.8631611985745837\n",
      "sim_101_222_l_he\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4154 - sMAPE_tf: 1.4154\n",
      "Epoch 1: val_loss improved from inf to 1.40899, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 5s 172ms/step - loss: 1.4106 - sMAPE_tf: 1.4068 - val_loss: 1.4090 - val_sMAPE_tf: 1.4090\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3317 - sMAPE_tf: 1.3317\n",
      "Epoch 2: val_loss improved from 1.40899 to 1.35365, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 1.3288 - sMAPE_tf: 1.3266 - val_loss: 1.3537 - val_sMAPE_tf: 1.3537\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2254 - sMAPE_tf: 1.2210\n",
      "Epoch 3: val_loss improved from 1.35365 to 1.19758, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 1.2254 - sMAPE_tf: 1.2210 - val_loss: 1.1976 - val_sMAPE_tf: 1.1976\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1406 - sMAPE_tf: 1.1406\n",
      "Epoch 4: val_loss did not improve from 1.19758\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 1.1379 - sMAPE_tf: 1.1358 - val_loss: 1.2232 - val_sMAPE_tf: 1.2232\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0751 - sMAPE_tf: 1.0751\n",
      "Epoch 5: val_loss did not improve from 1.19758\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 1.0766 - sMAPE_tf: 1.0778 - val_loss: 1.2016 - val_sMAPE_tf: 1.2016\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0190 - sMAPE_tf: 1.0190\n",
      "Epoch 6: val_loss improved from 1.19758 to 1.14895, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 1.0168 - sMAPE_tf: 1.0151 - val_loss: 1.1490 - val_sMAPE_tf: 1.1490\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9533 - sMAPE_tf: 0.9533\n",
      "Epoch 7: val_loss did not improve from 1.14895\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.9519 - sMAPE_tf: 0.9508 - val_loss: 1.1551 - val_sMAPE_tf: 1.1551\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9074 - sMAPE_tf: 0.9086\n",
      "Epoch 8: val_loss improved from 1.14895 to 1.12811, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.9074 - sMAPE_tf: 0.9086 - val_loss: 1.1281 - val_sMAPE_tf: 1.1281\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8705 - sMAPE_tf: 0.8705\n",
      "Epoch 9: val_loss improved from 1.12811 to 1.09479, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.8688 - sMAPE_tf: 0.8674 - val_loss: 1.0948 - val_sMAPE_tf: 1.0948\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8186 - sMAPE_tf: 0.8186\n",
      "Epoch 10: val_loss did not improve from 1.09479\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.8149 - sMAPE_tf: 0.8120 - val_loss: 1.0958 - val_sMAPE_tf: 1.0958\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7737 - sMAPE_tf: 0.7737\n",
      "Epoch 11: val_loss improved from 1.09479 to 1.07489, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.7732 - sMAPE_tf: 0.7729 - val_loss: 1.0749 - val_sMAPE_tf: 1.0749\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7391 - sMAPE_tf: 0.7391\n",
      "Epoch 12: val_loss improved from 1.07489 to 1.06996, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 0s 85ms/step - loss: 0.7396 - sMAPE_tf: 0.7401 - val_loss: 1.0700 - val_sMAPE_tf: 1.0700\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7125 - sMAPE_tf: 0.7125\n",
      "Epoch 13: val_loss did not improve from 1.06996\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.7116 - sMAPE_tf: 0.7110 - val_loss: 1.0765 - val_sMAPE_tf: 1.0765\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6942 - sMAPE_tf: 0.6942\n",
      "Epoch 14: val_loss did not improve from 1.06996\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.6945 - sMAPE_tf: 0.6947 - val_loss: 1.1167 - val_sMAPE_tf: 1.1167\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6768 - sMAPE_tf: 0.6768\n",
      "Epoch 15: val_loss improved from 1.06996 to 1.06331, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.6758 - sMAPE_tf: 0.6750 - val_loss: 1.0633 - val_sMAPE_tf: 1.0633\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6554 - sMAPE_tf: 0.6554\n",
      "Epoch 16: val_loss improved from 1.06331 to 1.04313, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 1s 92ms/step - loss: 0.6574 - sMAPE_tf: 0.6590 - val_loss: 1.0431 - val_sMAPE_tf: 1.0431\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6396 - sMAPE_tf: 0.6396\n",
      "Epoch 17: val_loss did not improve from 1.04313\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.6393 - sMAPE_tf: 0.6391 - val_loss: 1.0585 - val_sMAPE_tf: 1.0585\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6198 - sMAPE_tf: 0.6198\n",
      "Epoch 18: val_loss did not improve from 1.04313\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.6188 - sMAPE_tf: 0.6181 - val_loss: 1.0551 - val_sMAPE_tf: 1.0551\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5902 - sMAPE_tf: 0.5902\n",
      "Epoch 19: val_loss did not improve from 1.04313\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5892 - sMAPE_tf: 0.5884 - val_loss: 1.0640 - val_sMAPE_tf: 1.0640\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5738 - sMAPE_tf: 0.5770\n",
      "Epoch 20: val_loss improved from 1.04313 to 1.04040, saving model to ./checkpoints/sim_101_222_l_he_best\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.5738 - sMAPE_tf: 0.5770 - val_loss: 1.0404 - val_sMAPE_tf: 1.0404\n",
      "Epoch 21/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5623 - sMAPE_tf: 0.5623\n",
      "Epoch 21: val_loss did not improve from 1.04040\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.5670 - sMAPE_tf: 0.5707 - val_loss: 1.0534 - val_sMAPE_tf: 1.0534\n",
      "Epoch 22/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5499 - sMAPE_tf: 0.5499\n",
      "Epoch 22: val_loss did not improve from 1.04040\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.5508 - sMAPE_tf: 0.5514 - val_loss: 1.0424 - val_sMAPE_tf: 1.0424\n",
      "Epoch 23/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5451 - sMAPE_tf: 0.5451\n",
      "Epoch 23: val_loss did not improve from 1.04040\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.5438 - sMAPE_tf: 0.5428 - val_loss: 1.0510 - val_sMAPE_tf: 1.0510\n",
      "Epoch 24/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5352 - sMAPE_tf: 0.5352\n",
      "Epoch 24: val_loss did not improve from 1.04040\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.5359 - sMAPE_tf: 0.5364 - val_loss: 1.0504 - val_sMAPE_tf: 1.0504\n",
      "Epoch 25/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5320 - sMAPE_tf: 0.5320\n",
      "Epoch 25: val_loss did not improve from 1.04040\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.5322 - sMAPE_tf: 0.5324 - val_loss: 1.0533 - val_sMAPE_tf: 1.0533\n",
      "Training finished in 15.254820585250854 secconds\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.0599 - sMAPE_tf: 1.0599\n",
      "1.0599292516708374\n",
      "1/1 [==============================] - 1s 601ms/step\n",
      "mean_SMAPE:0.46323023057475105\n",
      "mean_MASE:2.2195035320356316\n",
      "sim_101_222_l_ho\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4765 - sMAPE_tf: 1.4765\n",
      "Epoch 1: val_loss improved from inf to 1.39039, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 5s 169ms/step - loss: 1.4732 - sMAPE_tf: 1.4706 - val_loss: 1.3904 - val_sMAPE_tf: 1.3904\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4117 - sMAPE_tf: 1.4102\n",
      "Epoch 2: val_loss improved from 1.39039 to 1.32978, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 1.4117 - sMAPE_tf: 1.4102 - val_loss: 1.3298 - val_sMAPE_tf: 1.3298\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3276 - sMAPE_tf: 1.3276\n",
      "Epoch 3: val_loss improved from 1.32978 to 1.24627, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 1.3245 - sMAPE_tf: 1.3222 - val_loss: 1.2463 - val_sMAPE_tf: 1.2463\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2081 - sMAPE_tf: 1.2056\n",
      "Epoch 4: val_loss did not improve from 1.24627\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 1.2081 - sMAPE_tf: 1.2056 - val_loss: 1.2752 - val_sMAPE_tf: 1.2752\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1357 - sMAPE_tf: 1.1357\n",
      "Epoch 5: val_loss improved from 1.24627 to 1.18752, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 1.1329 - sMAPE_tf: 1.1307 - val_loss: 1.1875 - val_sMAPE_tf: 1.1875\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0661 - sMAPE_tf: 1.0661\n",
      "Epoch 6: val_loss improved from 1.18752 to 1.14677, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 1.0635 - sMAPE_tf: 1.0614 - val_loss: 1.1468 - val_sMAPE_tf: 1.1468\n",
      "Epoch 7/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9924 - sMAPE_tf: 0.9924\n",
      "Epoch 7: val_loss improved from 1.14677 to 1.12754, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.9866 - sMAPE_tf: 0.9852 - val_loss: 1.1275 - val_sMAPE_tf: 1.1275\n",
      "Epoch 8/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9439 - sMAPE_tf: 0.9439\n",
      "Epoch 8: val_loss improved from 1.12754 to 1.10816, saving model to ./checkpoints/sim_101_222_l_ho_best\n",
      "6/6 [==============================] - 1s 95ms/step - loss: 0.9422 - sMAPE_tf: 0.9440 - val_loss: 1.1082 - val_sMAPE_tf: 1.1082\n",
      "Epoch 9/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8852 - sMAPE_tf: 0.8852\n",
      "Epoch 9: val_loss did not improve from 1.10816\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.8830 - sMAPE_tf: 0.8829 - val_loss: 1.1168 - val_sMAPE_tf: 1.1168\n",
      "Epoch 10/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8459 - sMAPE_tf: 0.8459\n",
      "Epoch 10: val_loss did not improve from 1.10816\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.8429 - sMAPE_tf: 0.8415 - val_loss: 1.1094 - val_sMAPE_tf: 1.1094\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8126 - sMAPE_tf: 0.8126\n",
      "Epoch 11: val_loss did not improve from 1.10816\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.8113 - sMAPE_tf: 0.8103 - val_loss: 1.1298 - val_sMAPE_tf: 1.1298\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7741 - sMAPE_tf: 0.7741\n",
      "Epoch 12: val_loss did not improve from 1.10816\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.7759 - sMAPE_tf: 0.7773 - val_loss: 1.1110 - val_sMAPE_tf: 1.1110\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7481 - sMAPE_tf: 0.7481\n",
      "Epoch 13: val_loss did not improve from 1.10816\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.7490 - sMAPE_tf: 0.7496 - val_loss: 1.1375 - val_sMAPE_tf: 1.1375\n",
      "Training finished in 10.259819746017456 secconds\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.0708 - sMAPE_tf: 1.0708\n",
      "1.0708324909210205\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "mean_SMAPE:0.5596313251733036\n",
      "mean_MASE:2.389375374656288\n",
      "sim_101_222_nl_he\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4129 - sMAPE_tf: 1.4084\n",
      "Epoch 1: val_loss improved from inf to 1.43349, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 5s 161ms/step - loss: 1.4129 - sMAPE_tf: 1.4084 - val_loss: 1.4335 - val_sMAPE_tf: 1.4335\n",
      "Epoch 2/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.3127 - sMAPE_tf: 1.3127\n",
      "Epoch 2: val_loss improved from 1.43349 to 1.36582, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 89ms/step - loss: 1.2940 - sMAPE_tf: 1.2879 - val_loss: 1.3658 - val_sMAPE_tf: 1.3658\n",
      "Epoch 3/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1959 - sMAPE_tf: 1.1959\n",
      "Epoch 3: val_loss improved from 1.36582 to 1.35859, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 1s 97ms/step - loss: 1.1880 - sMAPE_tf: 1.1859 - val_loss: 1.3586 - val_sMAPE_tf: 1.3586\n",
      "Epoch 4/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.1222 - sMAPE_tf: 1.1222\n",
      "Epoch 4: val_loss improved from 1.35859 to 1.29209, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 1.1181 - sMAPE_tf: 1.1183 - val_loss: 1.2921 - val_sMAPE_tf: 1.2921\n",
      "Epoch 5/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 1.0637 - sMAPE_tf: 1.0637\n",
      "Epoch 5: val_loss improved from 1.29209 to 1.24112, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 1s 101ms/step - loss: 1.0553 - sMAPE_tf: 1.0536 - val_loss: 1.2411 - val_sMAPE_tf: 1.2411\n",
      "Epoch 6/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.9923 - sMAPE_tf: 0.9923\n",
      "Epoch 6: val_loss improved from 1.24112 to 1.17296, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.9920 - sMAPE_tf: 0.9897 - val_loss: 1.1730 - val_sMAPE_tf: 1.1730\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9510 - sMAPE_tf: 0.9510\n",
      "Epoch 7: val_loss did not improve from 1.17296\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.9483 - sMAPE_tf: 0.9461 - val_loss: 1.1785 - val_sMAPE_tf: 1.1785\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9015 - sMAPE_tf: 0.9015\n",
      "Epoch 8: val_loss did not improve from 1.17296\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.9004 - sMAPE_tf: 0.8995 - val_loss: 1.1809 - val_sMAPE_tf: 1.1809\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8589 - sMAPE_tf: 0.8589\n",
      "Epoch 9: val_loss improved from 1.17296 to 1.15527, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.8618 - sMAPE_tf: 0.8641 - val_loss: 1.1553 - val_sMAPE_tf: 1.1553\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8242 - sMAPE_tf: 0.8242\n",
      "Epoch 10: val_loss did not improve from 1.15527\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.8230 - sMAPE_tf: 0.8221 - val_loss: 1.1709 - val_sMAPE_tf: 1.1709\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8136 - sMAPE_tf: 0.8136\n",
      "Epoch 11: val_loss did not improve from 1.15527\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.8123 - sMAPE_tf: 0.8112 - val_loss: 1.1663 - val_sMAPE_tf: 1.1663\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7918 - sMAPE_tf: 0.7918\n",
      "Epoch 12: val_loss improved from 1.15527 to 1.15485, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 88ms/step - loss: 0.7931 - sMAPE_tf: 0.7940 - val_loss: 1.1548 - val_sMAPE_tf: 1.1548\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7742 - sMAPE_tf: 0.7742\n",
      "Epoch 13: val_loss improved from 1.15485 to 1.11208, saving model to ./checkpoints/sim_101_222_nl_he_best\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.7727 - sMAPE_tf: 0.7714 - val_loss: 1.1121 - val_sMAPE_tf: 1.1121\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7489 - sMAPE_tf: 0.7489\n",
      "Epoch 14: val_loss did not improve from 1.11208\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.7496 - sMAPE_tf: 0.7502 - val_loss: 1.1398 - val_sMAPE_tf: 1.1398\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7269 - sMAPE_tf: 0.7269\n",
      "Epoch 15: val_loss did not improve from 1.11208\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.7265 - sMAPE_tf: 0.7261 - val_loss: 1.1309 - val_sMAPE_tf: 1.1309\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7141 - sMAPE_tf: 0.7141\n",
      "Epoch 16: val_loss did not improve from 1.11208\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.7159 - sMAPE_tf: 0.7174 - val_loss: 1.1363 - val_sMAPE_tf: 1.1363\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7076 - sMAPE_tf: 0.7076\n",
      "Epoch 17: val_loss did not improve from 1.11208\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.7098 - sMAPE_tf: 0.7114 - val_loss: 1.1380 - val_sMAPE_tf: 1.1380\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6913 - sMAPE_tf: 0.6913\n",
      "Epoch 18: val_loss did not improve from 1.11208\n",
      "6/6 [==============================] - 0s 54ms/step - loss: 0.6940 - sMAPE_tf: 0.6961 - val_loss: 1.1290 - val_sMAPE_tf: 1.1290\n",
      "Training finished in 13.183302402496338 secconds\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.2363 - sMAPE_tf: 1.2363\n",
      "1.2362751960754395\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "mean_SMAPE:0.4850011059481722\n",
      "mean_MASE:1.4687104383662315\n",
      "sim_101_222_nl_ho\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4115 - sMAPE_tf: 1.4096\n",
      "Epoch 1: val_loss improved from inf to 1.42292, saving model to ./checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 5s 223ms/step - loss: 1.4115 - sMAPE_tf: 1.4096 - val_loss: 1.4229 - val_sMAPE_tf: 1.4229\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3334 - sMAPE_tf: 1.3334\n",
      "Epoch 2: val_loss improved from 1.42292 to 1.33135, saving model to ./checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 1.3300 - sMAPE_tf: 1.3274 - val_loss: 1.3313 - val_sMAPE_tf: 1.3313\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2366 - sMAPE_tf: 1.2366\n",
      "Epoch 3: val_loss improved from 1.33135 to 1.32713, saving model to ./checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 1.2329 - sMAPE_tf: 1.2300 - val_loss: 1.3271 - val_sMAPE_tf: 1.3271\n",
      "Epoch 4/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1494 - sMAPE_tf: 1.1494\n",
      "Epoch 4: val_loss improved from 1.32713 to 1.22773, saving model to ./checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 1.1459 - sMAPE_tf: 1.1432 - val_loss: 1.2277 - val_sMAPE_tf: 1.2277\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0694 - sMAPE_tf: 1.0666\n",
      "Epoch 5: val_loss improved from 1.22773 to 1.16459, saving model to ./checkpoints/sim_101_222_nl_ho_best\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 1.0694 - sMAPE_tf: 1.0666 - val_loss: 1.1646 - val_sMAPE_tf: 1.1646\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0032 - sMAPE_tf: 1.0032\n",
      "Epoch 6: val_loss did not improve from 1.16459\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 1.0018 - sMAPE_tf: 1.0008 - val_loss: 1.1758 - val_sMAPE_tf: 1.1758\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9478 - sMAPE_tf: 0.9475\n",
      "Epoch 7: val_loss did not improve from 1.16459\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.9478 - sMAPE_tf: 0.9475 - val_loss: 1.1772 - val_sMAPE_tf: 1.1772\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9022 - sMAPE_tf: 0.9022\n",
      "Epoch 8: val_loss did not improve from 1.16459\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.8993 - sMAPE_tf: 0.8970 - val_loss: 1.1683 - val_sMAPE_tf: 1.1683\n",
      "Epoch 9/100\n",
      "4/6 [===================>..........] - ETA: 0s - loss: 0.8563 - sMAPE_tf: 0.8563\n",
      "Epoch 9: val_loss did not improve from 1.16459\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.8513 - sMAPE_tf: 0.8499 - val_loss: 1.1666 - val_sMAPE_tf: 1.1666\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8156 - sMAPE_tf: 0.8171\n",
      "Epoch 10: val_loss did not improve from 1.16459\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.8156 - sMAPE_tf: 0.8171 - val_loss: 1.1966 - val_sMAPE_tf: 1.1966\n",
      "Training finished in 8.711570501327515 secconds\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 1.2127 - sMAPE_tf: 1.2127\n",
      "1.2127224206924438\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "mean_SMAPE:0.5384780092645773\n",
      "mean_MASE:1.5164022147348672\n",
      "sim_500_60_l_he\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4649 - sMAPE_tf: 1.4649\n",
      "Epoch 1: val_loss improved from inf to 1.54050, saving model to ./checkpoints/sim_500_60_l_he_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4649 - sMAPE_tf: 1.4649 - val_loss: 1.5405 - val_sMAPE_tf: 1.5405\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4976 - sMAPE_tf: 1.4976\n",
      "Epoch 2: val_loss did not improve from 1.54050\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 1.4976 - sMAPE_tf: 1.4976 - val_loss: 1.6227 - val_sMAPE_tf: 1.6227\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5437 - sMAPE_tf: 1.5437\n",
      "Epoch 3: val_loss did not improve from 1.54050\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.5437 - sMAPE_tf: 1.5437 - val_loss: 1.6790 - val_sMAPE_tf: 1.6790\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5740 - sMAPE_tf: 1.5740\n",
      "Epoch 4: val_loss did not improve from 1.54050\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 1.5740 - sMAPE_tf: 1.5740 - val_loss: 1.7145 - val_sMAPE_tf: 1.7145\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5959 - sMAPE_tf: 1.5959\n",
      "Epoch 5: val_loss did not improve from 1.54050\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 1.5959 - sMAPE_tf: 1.5959 - val_loss: 1.7404 - val_sMAPE_tf: 1.7404\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6145 - sMAPE_tf: 1.6145\n",
      "Epoch 6: val_loss did not improve from 1.54050\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.6145 - sMAPE_tf: 1.6145 - val_loss: 1.7389 - val_sMAPE_tf: 1.7389\n",
      "Training finished in 6.485039472579956 secconds\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.5492 - sMAPE_tf: 1.5492\n",
      "1.549169898033142\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "mean_SMAPE:0.9686294707487045\n",
      "mean_MASE:4.986849535240777\n",
      "sim_500_60_l_ho\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4417 - sMAPE_tf: 1.4417\n",
      "Epoch 1: val_loss improved from inf to 1.50092, saving model to ./checkpoints/sim_500_60_l_ho_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4417 - sMAPE_tf: 1.4417 - val_loss: 1.5009 - val_sMAPE_tf: 1.5009\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4511 - sMAPE_tf: 1.4511\n",
      "Epoch 2: val_loss did not improve from 1.50092\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.4511 - sMAPE_tf: 1.4511 - val_loss: 1.5315 - val_sMAPE_tf: 1.5315\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4683 - sMAPE_tf: 1.4683\n",
      "Epoch 3: val_loss did not improve from 1.50092\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.4683 - sMAPE_tf: 1.4683 - val_loss: 1.5566 - val_sMAPE_tf: 1.5566\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4897 - sMAPE_tf: 1.4897\n",
      "Epoch 4: val_loss did not improve from 1.50092\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.4897 - sMAPE_tf: 1.4897 - val_loss: 1.5922 - val_sMAPE_tf: 1.5922\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5051 - sMAPE_tf: 1.5051\n",
      "Epoch 5: val_loss did not improve from 1.50092\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.5051 - sMAPE_tf: 1.5051 - val_loss: 1.6169 - val_sMAPE_tf: 1.6169\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5163 - sMAPE_tf: 1.5163\n",
      "Epoch 6: val_loss did not improve from 1.50092\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.5163 - sMAPE_tf: 1.5163 - val_loss: 1.6252 - val_sMAPE_tf: 1.6252\n",
      "Training finished in 5.868607759475708 secconds\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.5162 - sMAPE_tf: 1.5162\n",
      "1.5162246227264404\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "mean_SMAPE:0.8197388600236383\n",
      "mean_MASE:3.1084114782214\n",
      "sim_500_60_nl_he\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4587 - sMAPE_tf: 1.4587\n",
      "Epoch 1: val_loss improved from inf to 1.51402, saving model to ./checkpoints/sim_500_60_nl_he_best\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.4587 - sMAPE_tf: 1.4587 - val_loss: 1.5140 - val_sMAPE_tf: 1.5140\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4863 - sMAPE_tf: 1.4863\n",
      "Epoch 2: val_loss did not improve from 1.51402\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.4863 - sMAPE_tf: 1.4863 - val_loss: 1.5682 - val_sMAPE_tf: 1.5682\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5208 - sMAPE_tf: 1.5208\n",
      "Epoch 3: val_loss did not improve from 1.51402\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 1.5208 - sMAPE_tf: 1.5208 - val_loss: 1.6043 - val_sMAPE_tf: 1.6043\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5472 - sMAPE_tf: 1.5472\n",
      "Epoch 4: val_loss did not improve from 1.51402\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.5472 - sMAPE_tf: 1.5472 - val_loss: 1.6307 - val_sMAPE_tf: 1.6307\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5622 - sMAPE_tf: 1.5622\n",
      "Epoch 5: val_loss did not improve from 1.51402\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 1.5622 - sMAPE_tf: 1.5622 - val_loss: 1.6318 - val_sMAPE_tf: 1.6318\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5765 - sMAPE_tf: 1.5765\n",
      "Epoch 6: val_loss did not improve from 1.51402\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.5765 - sMAPE_tf: 1.5765 - val_loss: 1.6395 - val_sMAPE_tf: 1.6395\n",
      "Training finished in 5.485483169555664 secconds\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.5273 - sMAPE_tf: 1.5273\n",
      "1.5272643566131592\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "mean_SMAPE:1.0369361597202724\n",
      "mean_MASE:4.164063294006862\n",
      "sim_500_60_nl_ho\n",
      "35 27 27\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4664 - sMAPE_tf: 1.4664\n",
      "Epoch 1: val_loss improved from inf to 1.49416, saving model to ./checkpoints/sim_500_60_nl_ho_best\n",
      "1/1 [==============================] - 5s 5s/step - loss: 1.4664 - sMAPE_tf: 1.4664 - val_loss: 1.4942 - val_sMAPE_tf: 1.4942\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4572 - sMAPE_tf: 1.4572\n",
      "Epoch 2: val_loss improved from 1.49416 to 1.49192, saving model to ./checkpoints/sim_500_60_nl_ho_best\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 1.4572 - sMAPE_tf: 1.4572 - val_loss: 1.4919 - val_sMAPE_tf: 1.4919\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4667 - sMAPE_tf: 1.4667\n",
      "Epoch 3: val_loss did not improve from 1.49192\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.4667 - sMAPE_tf: 1.4667 - val_loss: 1.5151 - val_sMAPE_tf: 1.5151\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4829 - sMAPE_tf: 1.4829\n",
      "Epoch 4: val_loss did not improve from 1.49192\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.4829 - sMAPE_tf: 1.4829 - val_loss: 1.5629 - val_sMAPE_tf: 1.5629\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4965 - sMAPE_tf: 1.4965\n",
      "Epoch 5: val_loss did not improve from 1.49192\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 1.4965 - sMAPE_tf: 1.4965 - val_loss: 1.6160 - val_sMAPE_tf: 1.6160\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5112 - sMAPE_tf: 1.5112\n",
      "Epoch 6: val_loss did not improve from 1.49192\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 1.5112 - sMAPE_tf: 1.5112 - val_loss: 1.6498 - val_sMAPE_tf: 1.6498\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5240 - sMAPE_tf: 1.5240\n",
      "Epoch 7: val_loss did not improve from 1.49192\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.5240 - sMAPE_tf: 1.5240 - val_loss: 1.6726 - val_sMAPE_tf: 1.6726\n",
      "Training finished in 6.785083293914795 secconds\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.5663 - sMAPE_tf: 1.5663\n",
      "1.5662966966629028\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "mean_SMAPE:0.9866999450090704\n",
      "mean_MASE:3.5196685566611903\n",
      "sim_500_222_l_he\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4975 - sMAPE_tf: 1.4984\n",
      "Epoch 1: val_loss improved from inf to 1.67283, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 4s 220ms/step - loss: 1.4975 - sMAPE_tf: 1.4984 - val_loss: 1.6728 - val_sMAPE_tf: 1.6728\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4949 - sMAPE_tf: 1.4934\n",
      "Epoch 2: val_loss did not improve from 1.67283\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 1.4949 - sMAPE_tf: 1.4934 - val_loss: 1.7171 - val_sMAPE_tf: 1.7171\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4719 - sMAPE_tf: 1.4696\n",
      "Epoch 3: val_loss did not improve from 1.67283\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 1.4719 - sMAPE_tf: 1.4696 - val_loss: 1.6870 - val_sMAPE_tf: 1.6870\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4299 - sMAPE_tf: 1.4276\n",
      "Epoch 4: val_loss improved from 1.67283 to 1.66542, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 1.4299 - sMAPE_tf: 1.4276 - val_loss: 1.6654 - val_sMAPE_tf: 1.6654\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3704 - sMAPE_tf: 1.3693\n",
      "Epoch 5: val_loss improved from 1.66542 to 1.56142, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 1.3704 - sMAPE_tf: 1.3693 - val_loss: 1.5614 - val_sMAPE_tf: 1.5614\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3158 - sMAPE_tf: 1.3150\n",
      "Epoch 6: val_loss improved from 1.56142 to 1.52763, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 1.3158 - sMAPE_tf: 1.3150 - val_loss: 1.5276 - val_sMAPE_tf: 1.5276\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2579 - sMAPE_tf: 1.2579\n",
      "Epoch 7: val_loss improved from 1.52763 to 1.47045, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 1.2521 - sMAPE_tf: 1.2475 - val_loss: 1.4705 - val_sMAPE_tf: 1.4705\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.1935 - sMAPE_tf: 1.1916\n",
      "Epoch 8: val_loss improved from 1.47045 to 1.44463, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 1.1935 - sMAPE_tf: 1.1916 - val_loss: 1.4446 - val_sMAPE_tf: 1.4446\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1466 - sMAPE_tf: 1.1466\n",
      "Epoch 9: val_loss improved from 1.44463 to 1.40228, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 1.1434 - sMAPE_tf: 1.1410 - val_loss: 1.4023 - val_sMAPE_tf: 1.4023\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0920 - sMAPE_tf: 1.0920\n",
      "Epoch 10: val_loss improved from 1.40228 to 1.35338, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 1.0894 - sMAPE_tf: 1.0874 - val_loss: 1.3534 - val_sMAPE_tf: 1.3534\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0390 - sMAPE_tf: 1.0399\n",
      "Epoch 11: val_loss improved from 1.35338 to 1.33807, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 143ms/step - loss: 1.0390 - sMAPE_tf: 1.0399 - val_loss: 1.3381 - val_sMAPE_tf: 1.3381\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9957 - sMAPE_tf: 0.9918\n",
      "Epoch 12: val_loss improved from 1.33807 to 1.32342, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 0.9957 - sMAPE_tf: 0.9918 - val_loss: 1.3234 - val_sMAPE_tf: 1.3234\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9347 - sMAPE_tf: 0.9358\n",
      "Epoch 13: val_loss did not improve from 1.32342\n",
      "6/6 [==============================] - 0s 82ms/step - loss: 0.9347 - sMAPE_tf: 0.9358 - val_loss: 1.3669 - val_sMAPE_tf: 1.3669\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8978 - sMAPE_tf: 0.8978\n",
      "Epoch 14: val_loss improved from 1.32342 to 1.24250, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 0.8960 - sMAPE_tf: 0.8947 - val_loss: 1.2425 - val_sMAPE_tf: 1.2425\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8349 - sMAPE_tf: 0.8334\n",
      "Epoch 15: val_loss did not improve from 1.24250\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.8349 - sMAPE_tf: 0.8334 - val_loss: 1.3284 - val_sMAPE_tf: 1.3284\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7650 - sMAPE_tf: 0.7650\n",
      "Epoch 16: val_loss improved from 1.24250 to 1.19672, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.7643 - sMAPE_tf: 0.7638 - val_loss: 1.1967 - val_sMAPE_tf: 1.1967\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7206 - sMAPE_tf: 0.7205\n",
      "Epoch 17: val_loss improved from 1.19672 to 1.15614, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.7206 - sMAPE_tf: 0.7205 - val_loss: 1.1561 - val_sMAPE_tf: 1.1561\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6746 - sMAPE_tf: 0.6746\n",
      "Epoch 18: val_loss improved from 1.15614 to 1.09339, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 132ms/step - loss: 0.6765 - sMAPE_tf: 0.6780 - val_loss: 1.0934 - val_sMAPE_tf: 1.0934\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6324 - sMAPE_tf: 0.6324\n",
      "Epoch 19: val_loss improved from 1.09339 to 1.08639, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 0.6323 - sMAPE_tf: 0.6322 - val_loss: 1.0864 - val_sMAPE_tf: 1.0864\n",
      "Epoch 20/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6070 - sMAPE_tf: 0.6070\n",
      "Epoch 20: val_loss did not improve from 1.08639\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.6052 - sMAPE_tf: 0.6038 - val_loss: 1.0993 - val_sMAPE_tf: 1.0993\n",
      "Epoch 21/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5718 - sMAPE_tf: 0.5718\n",
      "Epoch 21: val_loss did not improve from 1.08639\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.5708 - sMAPE_tf: 0.5701 - val_loss: 1.0878 - val_sMAPE_tf: 1.0878\n",
      "Epoch 22/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5509 - sMAPE_tf: 0.5509\n",
      "Epoch 22: val_loss did not improve from 1.08639\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.5505 - sMAPE_tf: 0.5502 - val_loss: 1.1549 - val_sMAPE_tf: 1.1549\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5474 - sMAPE_tf: 0.5484\n",
      "Epoch 23: val_loss improved from 1.08639 to 1.02462, saving model to ./checkpoints/sim_500_222_l_he_best\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 0.5474 - sMAPE_tf: 0.5484 - val_loss: 1.0246 - val_sMAPE_tf: 1.0246\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5413 - sMAPE_tf: 0.5424\n",
      "Epoch 24: val_loss did not improve from 1.02462\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.5413 - sMAPE_tf: 0.5424 - val_loss: 1.0392 - val_sMAPE_tf: 1.0392\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5355 - sMAPE_tf: 0.5350\n",
      "Epoch 25: val_loss did not improve from 1.02462\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.5355 - sMAPE_tf: 0.5350 - val_loss: 1.2029 - val_sMAPE_tf: 1.2029\n",
      "Epoch 26/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5162 - sMAPE_tf: 0.5162\n",
      "Epoch 26: val_loss did not improve from 1.02462\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.5156 - sMAPE_tf: 0.5152 - val_loss: 1.0307 - val_sMAPE_tf: 1.0307\n",
      "Epoch 27/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5016 - sMAPE_tf: 0.5016\n",
      "Epoch 27: val_loss did not improve from 1.02462\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.5032 - sMAPE_tf: 0.5046 - val_loss: 1.0638 - val_sMAPE_tf: 1.0638\n",
      "Epoch 28/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.4927 - sMAPE_tf: 0.4927\n",
      "Epoch 28: val_loss did not improve from 1.02462\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.4929 - sMAPE_tf: 0.4930 - val_loss: 1.0405 - val_sMAPE_tf: 1.0405\n",
      "Training finished in 21.90941047668457 secconds\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.1016 - sMAPE_tf: 1.1016\n",
      "1.1015836000442505\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "mean_SMAPE:0.5213437796035771\n",
      "mean_MASE:2.3730076583377095\n",
      "sim_500_222_l_ho\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4721 - sMAPE_tf: 1.4722\n",
      "Epoch 1: val_loss improved from inf to 1.70634, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 5s 217ms/step - loss: 1.4721 - sMAPE_tf: 1.4722 - val_loss: 1.7063 - val_sMAPE_tf: 1.7063\n",
      "Epoch 2/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4556 - sMAPE_tf: 1.4556\n",
      "Epoch 2: val_loss improved from 1.70634 to 1.66767, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 1.4551 - sMAPE_tf: 1.4547 - val_loss: 1.6677 - val_sMAPE_tf: 1.6677\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4239 - sMAPE_tf: 1.4239\n",
      "Epoch 3: val_loss improved from 1.66767 to 1.65902, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 1.4210 - sMAPE_tf: 1.4188 - val_loss: 1.6590 - val_sMAPE_tf: 1.6590\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3627 - sMAPE_tf: 1.3609\n",
      "Epoch 4: val_loss improved from 1.65902 to 1.58500, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 1.3627 - sMAPE_tf: 1.3609 - val_loss: 1.5850 - val_sMAPE_tf: 1.5850\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2989 - sMAPE_tf: 1.2989\n",
      "Epoch 5: val_loss improved from 1.58500 to 1.57096, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 1.2955 - sMAPE_tf: 1.2928 - val_loss: 1.5710 - val_sMAPE_tf: 1.5710\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2427 - sMAPE_tf: 1.2427\n",
      "Epoch 6: val_loss did not improve from 1.57096\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 1.2390 - sMAPE_tf: 1.2362 - val_loss: 1.5961 - val_sMAPE_tf: 1.5961\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2043 - sMAPE_tf: 1.2043\n",
      "Epoch 7: val_loss did not improve from 1.57096\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 1.2029 - sMAPE_tf: 1.2018 - val_loss: 1.6034 - val_sMAPE_tf: 1.6034\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1538 - sMAPE_tf: 1.1538\n",
      "Epoch 8: val_loss did not improve from 1.57096\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 1.1557 - sMAPE_tf: 1.1572 - val_loss: 1.5952 - val_sMAPE_tf: 1.5952\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0936 - sMAPE_tf: 1.0936\n",
      "Epoch 9: val_loss improved from 1.57096 to 1.55882, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 1.0906 - sMAPE_tf: 1.0883 - val_loss: 1.5588 - val_sMAPE_tf: 1.5588\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0385 - sMAPE_tf: 1.0385\n",
      "Epoch 10: val_loss did not improve from 1.55882\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 1.0398 - sMAPE_tf: 1.0408 - val_loss: 1.5739 - val_sMAPE_tf: 1.5739\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9892 - sMAPE_tf: 0.9930\n",
      "Epoch 11: val_loss improved from 1.55882 to 1.48828, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.9892 - sMAPE_tf: 0.9930 - val_loss: 1.4883 - val_sMAPE_tf: 1.4883\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9511 - sMAPE_tf: 0.9511\n",
      "Epoch 12: val_loss improved from 1.48828 to 1.40707, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 0.9533 - sMAPE_tf: 0.9550 - val_loss: 1.4071 - val_sMAPE_tf: 1.4071\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.9124 - sMAPE_tf: 0.9110\n",
      "Epoch 13: val_loss improved from 1.40707 to 1.37067, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 0.9124 - sMAPE_tf: 0.9110 - val_loss: 1.3707 - val_sMAPE_tf: 1.3707\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8684 - sMAPE_tf: 0.8684\n",
      "Epoch 14: val_loss improved from 1.37067 to 1.29466, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.8687 - sMAPE_tf: 0.8689 - val_loss: 1.2947 - val_sMAPE_tf: 1.2947\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8501 - sMAPE_tf: 0.8484\n",
      "Epoch 15: val_loss improved from 1.29466 to 1.28300, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 0.8501 - sMAPE_tf: 0.8484 - val_loss: 1.2830 - val_sMAPE_tf: 1.2830\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8055 - sMAPE_tf: 0.8055\n",
      "Epoch 16: val_loss improved from 1.28300 to 1.19675, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.8047 - sMAPE_tf: 0.8040 - val_loss: 1.1968 - val_sMAPE_tf: 1.1968\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7589 - sMAPE_tf: 0.7601\n",
      "Epoch 17: val_loss improved from 1.19675 to 1.11071, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.7589 - sMAPE_tf: 0.7601 - val_loss: 1.1107 - val_sMAPE_tf: 1.1107\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7184 - sMAPE_tf: 0.7173\n",
      "Epoch 18: val_loss did not improve from 1.11071\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.7184 - sMAPE_tf: 0.7173 - val_loss: 1.1187 - val_sMAPE_tf: 1.1187\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6771 - sMAPE_tf: 0.6771\n",
      "Epoch 19: val_loss did not improve from 1.11071\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.6776 - sMAPE_tf: 0.6781 - val_loss: 1.1187 - val_sMAPE_tf: 1.1187\n",
      "Epoch 20/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6459 - sMAPE_tf: 0.6459\n",
      "Epoch 20: val_loss improved from 1.11071 to 1.09003, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 0.6468 - sMAPE_tf: 0.6476 - val_loss: 1.0900 - val_sMAPE_tf: 1.0900\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6188 - sMAPE_tf: 0.6185\n",
      "Epoch 21: val_loss did not improve from 1.09003\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.6188 - sMAPE_tf: 0.6185 - val_loss: 1.1654 - val_sMAPE_tf: 1.1654\n",
      "Epoch 22/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5886 - sMAPE_tf: 0.5886\n",
      "Epoch 22: val_loss improved from 1.09003 to 1.06861, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.5914 - sMAPE_tf: 0.5936 - val_loss: 1.0686 - val_sMAPE_tf: 1.0686\n",
      "Epoch 23/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5911 - sMAPE_tf: 0.5911\n",
      "Epoch 23: val_loss did not improve from 1.06861\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.5898 - sMAPE_tf: 0.5889 - val_loss: 1.1006 - val_sMAPE_tf: 1.1006\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5685 - sMAPE_tf: 0.5714\n",
      "Epoch 24: val_loss improved from 1.06861 to 1.06509, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 135ms/step - loss: 0.5685 - sMAPE_tf: 0.5714 - val_loss: 1.0651 - val_sMAPE_tf: 1.0651\n",
      "Epoch 25/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5612 - sMAPE_tf: 0.5612\n",
      "Epoch 25: val_loss did not improve from 1.06509\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.5610 - sMAPE_tf: 0.5608 - val_loss: 1.0832 - val_sMAPE_tf: 1.0832\n",
      "Epoch 26/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5481 - sMAPE_tf: 0.5481\n",
      "Epoch 26: val_loss did not improve from 1.06509\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.5470 - sMAPE_tf: 0.5461 - val_loss: 1.1274 - val_sMAPE_tf: 1.1274\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5372 - sMAPE_tf: 0.5388\n",
      "Epoch 27: val_loss did not improve from 1.06509\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.5372 - sMAPE_tf: 0.5388 - val_loss: 1.0759 - val_sMAPE_tf: 1.0759\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5239 - sMAPE_tf: 0.5254\n",
      "Epoch 28: val_loss improved from 1.06509 to 1.04438, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.5239 - sMAPE_tf: 0.5254 - val_loss: 1.0444 - val_sMAPE_tf: 1.0444\n",
      "Epoch 29/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5220 - sMAPE_tf: 0.5220\n",
      "Epoch 29: val_loss did not improve from 1.04438\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.5224 - sMAPE_tf: 0.5227 - val_loss: 1.1097 - val_sMAPE_tf: 1.1097\n",
      "Epoch 30/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5120 - sMAPE_tf: 0.5120\n",
      "Epoch 30: val_loss improved from 1.04438 to 1.04338, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.5132 - sMAPE_tf: 0.5142 - val_loss: 1.0434 - val_sMAPE_tf: 1.0434\n",
      "Epoch 31/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5031 - sMAPE_tf: 0.5031\n",
      "Epoch 31: val_loss did not improve from 1.04338\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.5047 - sMAPE_tf: 0.5060 - val_loss: 1.1393 - val_sMAPE_tf: 1.1393\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4855 - sMAPE_tf: 0.4867\n",
      "Epoch 32: val_loss improved from 1.04338 to 1.02794, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 0.4855 - sMAPE_tf: 0.4867 - val_loss: 1.0279 - val_sMAPE_tf: 1.0279\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4813 - sMAPE_tf: 0.4839\n",
      "Epoch 33: val_loss did not improve from 1.02794\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.4813 - sMAPE_tf: 0.4839 - val_loss: 1.1515 - val_sMAPE_tf: 1.1515\n",
      "Epoch 34/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.4774 - sMAPE_tf: 0.4774\n",
      "Epoch 34: val_loss improved from 1.02794 to 1.02081, saving model to ./checkpoints/sim_500_222_l_ho_best\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.4793 - sMAPE_tf: 0.4807 - val_loss: 1.0208 - val_sMAPE_tf: 1.0208\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4761 - sMAPE_tf: 0.4749\n",
      "Epoch 35: val_loss did not improve from 1.02081\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.4761 - sMAPE_tf: 0.4749 - val_loss: 1.0717 - val_sMAPE_tf: 1.0717\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4692 - sMAPE_tf: 0.4705\n",
      "Epoch 36: val_loss did not improve from 1.02081\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.4692 - sMAPE_tf: 0.4705 - val_loss: 1.0433 - val_sMAPE_tf: 1.0433\n",
      "Epoch 37/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.4629 - sMAPE_tf: 0.4629\n",
      "Epoch 37: val_loss did not improve from 1.02081\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.4629 - sMAPE_tf: 0.4629 - val_loss: 1.0638 - val_sMAPE_tf: 1.0638\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4587 - sMAPE_tf: 0.4630\n",
      "Epoch 38: val_loss did not improve from 1.02081\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.4587 - sMAPE_tf: 0.4630 - val_loss: 1.0548 - val_sMAPE_tf: 1.0548\n",
      "Epoch 39/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.4479 - sMAPE_tf: 0.4479\n",
      "Epoch 39: val_loss did not improve from 1.02081\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.4482 - sMAPE_tf: 0.4483 - val_loss: 1.0743 - val_sMAPE_tf: 1.0743\n",
      "Training finished in 28.487102508544922 secconds\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.0743 - sMAPE_tf: 1.0743\n",
      "1.0743439197540283\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "mean_SMAPE:0.5165782768105996\n",
      "mean_MASE:2.277300524745917\n",
      "sim_500_222_nl_he\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4852 - sMAPE_tf: 1.4852\n",
      "Epoch 1: val_loss improved from inf to 1.49165, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 5s 225ms/step - loss: 1.4834 - sMAPE_tf: 1.4819 - val_loss: 1.4916 - val_sMAPE_tf: 1.4916\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4750 - sMAPE_tf: 1.4762\n",
      "Epoch 2: val_loss did not improve from 1.49165\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 1.4750 - sMAPE_tf: 1.4762 - val_loss: 1.5459 - val_sMAPE_tf: 1.5459\n",
      "Epoch 3/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4361 - sMAPE_tf: 1.4361\n",
      "Epoch 3: val_loss improved from 1.49165 to 1.48744, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 1.4370 - sMAPE_tf: 1.4377 - val_loss: 1.4874 - val_sMAPE_tf: 1.4874\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3921 - sMAPE_tf: 1.3914\n",
      "Epoch 4: val_loss improved from 1.48744 to 1.44646, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 1.3921 - sMAPE_tf: 1.3914 - val_loss: 1.4465 - val_sMAPE_tf: 1.4465\n",
      "Epoch 5/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3350 - sMAPE_tf: 1.3350\n",
      "Epoch 5: val_loss improved from 1.44646 to 1.39428, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 1.3344 - sMAPE_tf: 1.3340 - val_loss: 1.3943 - val_sMAPE_tf: 1.3943\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2889 - sMAPE_tf: 1.2889\n",
      "Epoch 6: val_loss improved from 1.39428 to 1.31504, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 1.2880 - sMAPE_tf: 1.2872 - val_loss: 1.3150 - val_sMAPE_tf: 1.3150\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.2358 - sMAPE_tf: 1.2383\n",
      "Epoch 7: val_loss improved from 1.31504 to 1.30107, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 1.2358 - sMAPE_tf: 1.2383 - val_loss: 1.3011 - val_sMAPE_tf: 1.3011\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1727 - sMAPE_tf: 1.1727\n",
      "Epoch 8: val_loss improved from 1.30107 to 1.25653, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 121ms/step - loss: 1.1787 - sMAPE_tf: 1.1833 - val_loss: 1.2565 - val_sMAPE_tf: 1.2565\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1269 - sMAPE_tf: 1.1269\n",
      "Epoch 9: val_loss improved from 1.25653 to 1.24886, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 1.1267 - sMAPE_tf: 1.1265 - val_loss: 1.2489 - val_sMAPE_tf: 1.2489\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0750 - sMAPE_tf: 1.0814\n",
      "Epoch 10: val_loss improved from 1.24886 to 1.20976, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 1.0750 - sMAPE_tf: 1.0814 - val_loss: 1.2098 - val_sMAPE_tf: 1.2098\n",
      "Epoch 11/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0220 - sMAPE_tf: 1.0220\n",
      "Epoch 11: val_loss improved from 1.20976 to 1.19671, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 1.0208 - sMAPE_tf: 1.0199 - val_loss: 1.1967 - val_sMAPE_tf: 1.1967\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9612 - sMAPE_tf: 0.9612\n",
      "Epoch 12: val_loss improved from 1.19671 to 1.19089, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.9714 - sMAPE_tf: 0.9794 - val_loss: 1.1909 - val_sMAPE_tf: 1.1909\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9282 - sMAPE_tf: 0.9282\n",
      "Epoch 13: val_loss improved from 1.19089 to 1.16017, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.9277 - sMAPE_tf: 0.9274 - val_loss: 1.1602 - val_sMAPE_tf: 1.1602\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.8705 - sMAPE_tf: 0.8731\n",
      "Epoch 14: val_loss improved from 1.16017 to 1.13873, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.8705 - sMAPE_tf: 0.8731 - val_loss: 1.1387 - val_sMAPE_tf: 1.1387\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8266 - sMAPE_tf: 0.8266\n",
      "Epoch 15: val_loss improved from 1.13873 to 1.11455, saving model to ./checkpoints/sim_500_222_nl_he_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.8311 - sMAPE_tf: 0.8347 - val_loss: 1.1145 - val_sMAPE_tf: 1.1145\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7945 - sMAPE_tf: 0.7965\n",
      "Epoch 16: val_loss did not improve from 1.11455\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.7945 - sMAPE_tf: 0.7965 - val_loss: 1.1284 - val_sMAPE_tf: 1.1284\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.7426 - sMAPE_tf: 0.7421\n",
      "Epoch 17: val_loss did not improve from 1.11455\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.7426 - sMAPE_tf: 0.7421 - val_loss: 1.1338 - val_sMAPE_tf: 1.1338\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7118 - sMAPE_tf: 0.7118\n",
      "Epoch 18: val_loss did not improve from 1.11455\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.7124 - sMAPE_tf: 0.7129 - val_loss: 1.1906 - val_sMAPE_tf: 1.1906\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6845 - sMAPE_tf: 0.6853\n",
      "Epoch 19: val_loss did not improve from 1.11455\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.6845 - sMAPE_tf: 0.6853 - val_loss: 1.1564 - val_sMAPE_tf: 1.1564\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.6559 - sMAPE_tf: 0.6562\n",
      "Epoch 20: val_loss did not improve from 1.11455\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.6559 - sMAPE_tf: 0.6562 - val_loss: 1.1379 - val_sMAPE_tf: 1.1379\n",
      "Training finished in 17.560532093048096 secconds\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 1.2600 - sMAPE_tf: 1.2600\n",
      "1.2600032091140747\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "mean_SMAPE:0.4436097320721521\n",
      "mean_MASE:1.3027454535118104\n",
      "sim_500_222_nl_ho\n",
      "197 27 27\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4893 - sMAPE_tf: 1.4895\n",
      "Epoch 1: val_loss improved from inf to 1.55093, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 7s 232ms/step - loss: 1.4893 - sMAPE_tf: 1.4895 - val_loss: 1.5509 - val_sMAPE_tf: 1.5509\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4724 - sMAPE_tf: 1.4708\n",
      "Epoch 2: val_loss improved from 1.55093 to 1.52863, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 1.4724 - sMAPE_tf: 1.4708 - val_loss: 1.5286 - val_sMAPE_tf: 1.5286\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.4286 - sMAPE_tf: 1.4273\n",
      "Epoch 3: val_loss improved from 1.52863 to 1.52775, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 1.4286 - sMAPE_tf: 1.4273 - val_loss: 1.5278 - val_sMAPE_tf: 1.5278\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3769 - sMAPE_tf: 1.3751\n",
      "Epoch 4: val_loss improved from 1.52775 to 1.47912, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 1.3769 - sMAPE_tf: 1.3751 - val_loss: 1.4791 - val_sMAPE_tf: 1.4791\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.3309 - sMAPE_tf: 1.3283\n",
      "Epoch 5: val_loss improved from 1.47912 to 1.46948, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 1.3309 - sMAPE_tf: 1.3283 - val_loss: 1.4695 - val_sMAPE_tf: 1.4695\n",
      "Epoch 6/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2798 - sMAPE_tf: 1.2798\n",
      "Epoch 6: val_loss improved from 1.46948 to 1.40218, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 1.2772 - sMAPE_tf: 1.2752 - val_loss: 1.4022 - val_sMAPE_tf: 1.4022\n",
      "Epoch 7/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2209 - sMAPE_tf: 1.2209\n",
      "Epoch 7: val_loss improved from 1.40218 to 1.33200, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 1.2199 - sMAPE_tf: 1.2191 - val_loss: 1.3320 - val_sMAPE_tf: 1.3320\n",
      "Epoch 8/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1593 - sMAPE_tf: 1.1593\n",
      "Epoch 8: val_loss improved from 1.33200 to 1.27240, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 120ms/step - loss: 1.1634 - sMAPE_tf: 1.1666 - val_loss: 1.2724 - val_sMAPE_tf: 1.2724\n",
      "Epoch 9/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1076 - sMAPE_tf: 1.1076\n",
      "Epoch 9: val_loss improved from 1.27240 to 1.22500, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 1.1088 - sMAPE_tf: 1.1097 - val_loss: 1.2250 - val_sMAPE_tf: 1.2250\n",
      "Epoch 10/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0702 - sMAPE_tf: 1.0702\n",
      "Epoch 10: val_loss improved from 1.22500 to 1.21756, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 1.0643 - sMAPE_tf: 1.0596 - val_loss: 1.2176 - val_sMAPE_tf: 1.2176\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.0102 - sMAPE_tf: 1.0108\n",
      "Epoch 11: val_loss improved from 1.21756 to 1.17435, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 117ms/step - loss: 1.0102 - sMAPE_tf: 1.0108 - val_loss: 1.1743 - val_sMAPE_tf: 1.1743\n",
      "Epoch 12/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9735 - sMAPE_tf: 0.9735\n",
      "Epoch 12: val_loss did not improve from 1.17435\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 0.9708 - sMAPE_tf: 0.9687 - val_loss: 1.2166 - val_sMAPE_tf: 1.2166\n",
      "Epoch 13/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9321 - sMAPE_tf: 0.9321\n",
      "Epoch 13: val_loss improved from 1.17435 to 1.15782, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 117ms/step - loss: 0.9297 - sMAPE_tf: 0.9277 - val_loss: 1.1578 - val_sMAPE_tf: 1.1578\n",
      "Epoch 14/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8806 - sMAPE_tf: 0.8806\n",
      "Epoch 14: val_loss improved from 1.15782 to 1.13215, saving model to ./checkpoints/sim_500_222_nl_ho_best\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.8762 - sMAPE_tf: 0.8727 - val_loss: 1.1322 - val_sMAPE_tf: 1.1322\n",
      "Epoch 15/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8260 - sMAPE_tf: 0.8260\n",
      "Epoch 15: val_loss did not improve from 1.13215\n",
      "6/6 [==============================] - 0s 57ms/step - loss: 0.8234 - sMAPE_tf: 0.8214 - val_loss: 1.1510 - val_sMAPE_tf: 1.1510\n",
      "Epoch 16/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7717 - sMAPE_tf: 0.7717\n",
      "Epoch 16: val_loss did not improve from 1.13215\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.7688 - sMAPE_tf: 0.7665 - val_loss: 1.1629 - val_sMAPE_tf: 1.1629\n",
      "Epoch 17/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7219 - sMAPE_tf: 0.7219\n",
      "Epoch 17: val_loss did not improve from 1.13215\n",
      "6/6 [==============================] - 0s 68ms/step - loss: 0.7198 - sMAPE_tf: 0.7182 - val_loss: 1.2076 - val_sMAPE_tf: 1.2076\n",
      "Epoch 18/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7073 - sMAPE_tf: 0.7073\n",
      "Epoch 18: val_loss did not improve from 1.13215\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 0.7049 - sMAPE_tf: 0.7031 - val_loss: 1.2323 - val_sMAPE_tf: 1.2323\n",
      "Epoch 19/100\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6754 - sMAPE_tf: 0.6754\n",
      "Epoch 19: val_loss did not improve from 1.13215\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.6784 - sMAPE_tf: 0.6808 - val_loss: 1.1374 - val_sMAPE_tf: 1.1374\n",
      "Training finished in 18.230535745620728 secconds\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2483 - sMAPE_tf: 1.2483\n",
      "1.2483458518981934\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "mean_SMAPE:0.4741002461730343\n",
      "mean_MASE:1.4198144737785483\n"
     ]
    }
   ],
   "source": [
    "dataset_name_test = ['sim_10_60_l_he', 'sim_10_60_l_ho',\\\n",
    "                     'sim_10_60_nl_he', 'sim_10_60_nl_ho',\\\n",
    "                     'sim_10_222_l_he', 'sim_10_222_l_ho',\\\n",
    "                     'sim_10_222_nl_he', 'sim_10_222_nl_ho',\\\n",
    "                     'sim_101_60_l_he', 'sim_101_60_l_ho',\\\n",
    "                     'sim_101_60_nl_he', 'sim_101_60_nl_ho',\\\n",
    "                     'sim_101_222_l_he', 'sim_101_222_l_ho',\\\n",
    "                     'sim_101_222_nl_he', 'sim_101_222_nl_ho',\\\n",
    "                     'sim_500_60_l_he', 'sim_500_60_l_ho',\\\n",
    "                     'sim_500_60_nl_he', 'sim_500_60_nl_ho',\\\n",
    "                     'sim_500_222_l_he', 'sim_500_222_l_ho',\\\n",
    "                     'sim_500_222_nl_he', 'sim_500_222_nl_ho']\n",
    "dataset_type = 'sim'\n",
    "forecast_horizon=12\n",
    "\n",
    "for i in dataset_name_test:\n",
    "    print(i)\n",
    "    tsmixer_eval(i,dataset_type,forecast_horizon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
